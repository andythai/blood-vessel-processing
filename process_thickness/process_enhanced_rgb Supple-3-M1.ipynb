{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Standard imports\n",
    "import glob\n",
    "\n",
    "# 3rd party imports\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from pprint import pprint\n",
    "import SimpleITK as sitk\n",
    "sitk.ProcessObject_SetGlobalWarningDisplay(False)\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_channel(filepath: str, idx: int, debug=False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load the image channels from the given filepath.\n",
    "    \n",
    "    Args:\n",
    "        filepath: str, path to the image\n",
    "        idx: int, index of the image to load\n",
    "        \n",
    "    Returns:\n",
    "        channels: np.ndarray, image channels\n",
    "    \"\"\"\n",
    "    filepaths = sorted(glob.glob(filepath))\n",
    "    \n",
    "    \n",
    "    # Load the image\n",
    "    curr_img = read_tif(filepaths[idx])\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Found {int(len(filepaths))} slices\")\n",
    "        pprint(filepaths)\n",
    "        print(\"\\nImage:\", filepaths[idx])\n",
    "\n",
    "        # Check image stats\n",
    "        print(f\"\\nChannel shape: {curr_img.shape}\")\n",
    "        print(f\"Channel dtype: {curr_img.dtype}\")\n",
    "        print(f\"Channel min: {curr_img.min()}\")\n",
    "        print(f\"Channel max: {curr_img.max()}\")\n",
    "        print(f\"Channel mean: {curr_img.mean()}\")\n",
    "        \n",
    "    return curr_img, filepaths[idx]\n",
    "\n",
    "\n",
    "### Functions for IO operations\n",
    "def load_channels(filepath: str, idx: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load the image channels from the given filepath.\n",
    "    \n",
    "    Args:\n",
    "        filepath: str, path to the image\n",
    "        idx: int, index of the image to load\n",
    "        \n",
    "    Returns:\n",
    "        channels: np.ndarray, image channels\n",
    "    \"\"\"\n",
    "    filepaths = sorted(glob.glob(filepath))\n",
    "    print(f\"Found {int(len(filepaths)/2)} slices\")\n",
    "    pprint(filepaths)\n",
    "    \n",
    "    # Load the image\n",
    "    file_idx = idx * 2  # Multiply by 2 because we have 2 channels and they're stored in pairs\n",
    "    curr_img = (read_tif(filepaths[file_idx]), read_tif(filepaths[file_idx + 1]))\n",
    "    print(\"\\nCh1:\", filepaths[file_idx])\n",
    "    print(\"Ch2:\", filepaths[file_idx + 1])\n",
    "    curr_ch1 = curr_img[0]\n",
    "    curr_ch2 = curr_img[1]\n",
    "\n",
    "    # Check image stats\n",
    "    print(f\"\\nChannel shape: {curr_ch1.shape}\")\n",
    "    print(f\"Channel dtype: {curr_ch1.dtype}\")\n",
    "    print(f\"Channel 1 min: {curr_ch1.min()}\")\n",
    "    print(f\"Channel 1 max: {curr_ch1.max()}\")\n",
    "    print(f\"Channel 1 mean: {curr_ch1.mean()}\")\n",
    "    \n",
    "    return curr_ch1, curr_ch2\n",
    "\n",
    "\n",
    "def read_tif(filepath):\n",
    "    \"\"\"\n",
    "    Read tiff files using SimpleITK\n",
    "    \n",
    "    Args:\n",
    "        filepath: str, path to tiff file\n",
    "        \n",
    "    Returns:\n",
    "        image: np.ndarray, tiff image\n",
    "    \"\"\"\n",
    "    image = sitk.ReadImage(filepath)\n",
    "    image = sitk.GetArrayFromImage(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def auto_contrast(data: np.ndarray, alpha: float = None, beta: float = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocess tiff files to automatically adjust brightness and contrast.\n",
    "    https://stackoverflow.com/questions/56905592/automatic-contrast-and-brightness-adjustment-of-a-color-photo-of-a-sheet-of-pape\n",
    "    \"\"\"\n",
    "    if not alpha:\n",
    "        alpha = np.iinfo(data.dtype).max / (np.max(data) - np.min(data))\n",
    "    if not beta:\n",
    "        beta = -np.min(data) * alpha\n",
    "    img = cv2.convertScaleAbs(data.copy(), alpha=alpha, beta=beta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def gamma_correction(image: np.ndarray, gamma: float=2.0, min_value=None, max_value=None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply gamma correction to the image.\n",
    "    \n",
    "    Args:\n",
    "        image: np.ndarray, input image\n",
    "        gamma: float, gamma value\n",
    "        \n",
    "    Returns:\n",
    "        image_enhanced: np.ndarray, gamma corrected image\n",
    "    \"\"\"\n",
    "    if min_value is not None:\n",
    "        image = image.copy()\n",
    "        image[image < min_value] = 0\n",
    "    if max_value is None:\n",
    "        max_value = image.max()\n",
    "    else:\n",
    "        image = image.copy()\n",
    "        image[image > max_value] = max_value\n",
    "    # Normalize the image to the range [0, 1]\n",
    "    image_normalized = image / max_value\n",
    "    # Apply the exponential transformation\n",
    "    image_enhanced = np.power(image_normalized, gamma)\n",
    "    # Rescale the image back to the original intensity range\n",
    "    image_enhanced = image_enhanced * max_value\n",
    "    return image_enhanced\n",
    "\n",
    "\n",
    "def save_figure(image, filename, contours=None):\n",
    "    \"\"\"\n",
    "    Save figure to disk.\n",
    "    \n",
    "    Args:\n",
    "        image: np.ndarray, input image\n",
    "        filename: str, path to save the image\n",
    "        contours: np.ndarray, contours to overlay on the image\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    if contours is not None:\n",
    "        plt.contour(contours, colors='red', linewidths=0.15, alpha=0.35)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(filename, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Saved figure to {filename}\")\n",
    "    \n",
    "    \n",
    "def show(image: np.ndarray, contour: np.ndarray = None,\n",
    "         image2: np.ndarray = None, contour2: np.ndarray = None, contour_alpha: float = 0.75,\n",
    "         title: str = \"\", title2: str = \"\", \n",
    "         xlim: tuple[int, int] = None, ylim: tuple[int, int] = None,\n",
    "         xlim2: tuple[int, int] = None, ylim2: tuple[int, int] = None,\n",
    "         axis: bool = True,\n",
    "         figsize: tuple[int, int] = (10, 10)):\n",
    "    \"\"\"\n",
    "    Display the image.\n",
    "    \n",
    "    Args:\n",
    "        image: np.ndarray, input image\n",
    "        title: str, title of the image\n",
    "    \"\"\"\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    # If there are two images, display them side by side\n",
    "    if image2 is not None:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(title)\n",
    "        if contour is not None:\n",
    "            plt.contour(contour, colors='red', linewidths=0.5, alpha=contour_alpha)\n",
    "        if xlim is not None:\n",
    "            plt.xlim(xlim)\n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim)\n",
    "        plt.axis(axis)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(image2, cmap='gray')\n",
    "        plt.title(title2)\n",
    "        if contour2 is not None:\n",
    "            plt.contour(contour2, colors='red', linewidths=0.5, alpha=contour_alpha)\n",
    "        if xlim2 is not None:\n",
    "            plt.xlim(xlim2)\n",
    "        if ylim2 is not None:\n",
    "            plt.ylim(ylim2)\n",
    "        plt.axis(axis)\n",
    "    # If there is only one image, display it\n",
    "    else:\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(title)\n",
    "        if contour is not None:\n",
    "            plt.contour(contour, colors='red', linewidths=0.5, alpha=contour_alpha)\n",
    "        if xlim is not None:\n",
    "            plt.xlim(xlim)\n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim)\n",
    "        plt.axis(axis)\n",
    "    plt.show()\n",
    "    f.clear()\n",
    "    plt.close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for vessel detection\n",
    "import itk\n",
    "import numpy as np\n",
    "from skimage.morphology import remove_small_objects, binary_closing, disk, remove_small_holes\n",
    "\n",
    "# Parameters for vessel detection\n",
    "ALPHA = 0.5  # Default 0.5\n",
    "BETA = 0.5  # Default 1\n",
    "GAMMA = 5.0  # Default 5\n",
    "\n",
    "def detect_vessels(input_image: np.ndarray, min_sigma: float=1.0, max_sigma: float=10.0, num_steps: int=10):\n",
    "    \"\"\"\n",
    "    Use the Hessian-based vesselness filter to detect vessels in the image.\n",
    "    \n",
    "    Args:\n",
    "        input_image: np.ndarray, input image\n",
    "        min_sigma: float, minimum sigma value\n",
    "        max_sigma: float, maximum sigma value\n",
    "        num_steps: int, number of steps\n",
    "        \n",
    "    Returns:\n",
    "        segmented_vessels_array: np.ndarray, segmented vessels\n",
    "    \"\"\"\n",
    "    # Run ITK\n",
    "    input_image = itk.image_from_array(input_image)\n",
    "    #input_image = itk.imread(input_image, itk.F)\n",
    "\n",
    "    ImageType = type(input_image)\n",
    "    Dimension = input_image.GetImageDimension()\n",
    "    HessianPixelType = itk.SymmetricSecondRankTensor[itk.D, Dimension]\n",
    "    HessianImageType = itk.Image[HessianPixelType, Dimension]\n",
    "\n",
    "    objectness_filter = itk.HessianToObjectnessMeasureImageFilter[\n",
    "        HessianImageType, ImageType\n",
    "    ].New()\n",
    "    objectness_filter.SetBrightObject(False)  # Set to True if the structures are bright on a dark background\n",
    "    objectness_filter.SetScaleObjectnessMeasure(False)  # Set to True to scale the objectness measure by the scale\n",
    "    objectness_filter.SetAlpha(ALPHA)  # Sensitivity to blob-like structures\n",
    "                                     # Set/Get Alpha, the weight corresponding to R_A \n",
    "                                     # (the ratio of the smallest eigenvalue that has to be large to the larger ones). \n",
    "                                     # Smaller values lead to increased sensitivity to the object dimensionality.\n",
    "    objectness_filter.SetBeta(BETA)   # Sensitivity to plate-like structures - 1.0 default\n",
    "                                     # Set/Get Beta, the weight corresponding to R_B \n",
    "                                     # (the ratio of the largest eigenvalue that has to be small to the larger ones). \n",
    "                                     # Smaller values lead to increased sensitivity to the object dimensionality.\n",
    "    objectness_filter.SetGamma(GAMMA)  # Sensitivity to noise - 5.0 default\n",
    "                                     # Set/Get Gamma, the weight corresponding to S \n",
    "                                     # (the Frobenius norm of the Hessian matrix, or second-order structureness)\n",
    "\n",
    "    multi_scale_filter = itk.MultiScaleHessianBasedMeasureImageFilter[\n",
    "        ImageType, HessianImageType, ImageType\n",
    "    ].New()\n",
    "    multi_scale_filter.SetInput(input_image)\n",
    "    multi_scale_filter.SetHessianToMeasureFilter(objectness_filter)\n",
    "    multi_scale_filter.SetSigmaStepMethodToLogarithmic()\n",
    "    multi_scale_filter.SetSigmaMinimum(min_sigma)\n",
    "    multi_scale_filter.SetSigmaMaximum(max_sigma)\n",
    "    multi_scale_filter.SetNumberOfSigmaSteps(num_steps)\n",
    "\n",
    "    OutputPixelType = itk.UC\n",
    "    OutputImageType = itk.Image[OutputPixelType, Dimension]\n",
    "\n",
    "    rescale_filter = itk.RescaleIntensityImageFilter[ImageType, OutputImageType].New()\n",
    "    rescale_filter.SetInput(multi_scale_filter)\n",
    "    rescale_filter.Update()\n",
    "\n",
    "    # Get numpy array\n",
    "    segmented_vessels = rescale_filter.GetOutput()\n",
    "    segmented_vessels_array = itk.array_view_from_image(segmented_vessels)\n",
    "    segmented_vessels_array = np.asarray(segmented_vessels_array, dtype=np.float32)\n",
    "    return segmented_vessels_array\n",
    "\n",
    "\n",
    "def process_vessels(vessel_image: np.ndarray, thresh: int, min_size: int=10, area_threshold: float=2000, smoothing: int=3):\n",
    "    \"\"\"\n",
    "    Process the thresholded vessels.\n",
    "    \n",
    "    Args:\n",
    "        vessel_image: np.ndarray, input image\n",
    "        thresh: int, threshold value\n",
    "        min_size: int, minimum size\n",
    "        area_threshold: float, area threshold\n",
    "        smoothing: int, smoothing factor\n",
    "        \n",
    "    Returns:\n",
    "        thresholded_vessels: np.ndarray, thresholded vessels\n",
    "    \"\"\"\n",
    "    # Process the thresholded vessels\n",
    "    thresholded_vessels = vessel_image > thresh\n",
    "    thresholded_vessels = np.invert(thresholded_vessels)\n",
    "\n",
    "    # Get rid of small objects\n",
    "    thresholded_vessels = remove_small_objects(thresholded_vessels, min_size=min_size)\n",
    "    thresholded_vessels = remove_small_holes(thresholded_vessels, area_threshold=area_threshold)\n",
    "\n",
    "    # Smoothen edges\n",
    "    thresholded_vessels = binary_closing(thresholded_vessels, footprint=disk(smoothing))\n",
    "    \n",
    "    return thresholded_vessels\n",
    "\n",
    "\n",
    "def get_brain_mask(brain_image, area_threshold=300000, min_size=10000):\n",
    "    \"\"\"\n",
    "    Get the mask of the brain from the image (run before contrast enhancement).\n",
    "    \n",
    "    Args:\n",
    "        brain_image: np.ndarray, input image\n",
    "        thresh: int, threshold value\n",
    "        area_threshold: int, area threshold\n",
    "        \n",
    "    Returns:\n",
    "        mask: np.ndarray, mask of the brain\n",
    "    \"\"\"\n",
    "    _, mask = cv2.threshold(brain_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_TRIANGLE)\n",
    "    mask = remove_small_holes(mask.astype(bool), area_threshold=area_threshold)\n",
    "    mask = remove_small_objects(mask, min_size=min_size)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for evaluation\n",
    "import csv\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error\n",
    "from scipy.spatial.distance import hamming\n",
    "\n",
    "def dice_coefficient(binary_image1, binary_image2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the Dice coefficient between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - dice: Dice coefficient.\n",
    "    \"\"\"\n",
    "    intersection = np.sum(binary_image1 * binary_image2)\n",
    "    size1 = np.sum(binary_image1)\n",
    "    size2 = np.sum(binary_image2)\n",
    "    \n",
    "    dice = (2. * intersection + epsilon) / (size1 + size2 + epsilon)\n",
    "    return dice\n",
    "\n",
    "\n",
    "def iou(binary_image1, binary_image2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the Intersection over Union (IoU) between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - iou: IoU.\n",
    "    \"\"\"\n",
    "    intersection = np.sum(binary_image1 * binary_image2)\n",
    "    union = np.sum(binary_image1 + binary_image2)\n",
    "    \n",
    "    if union == 0:\n",
    "        iou = 1.0\n",
    "    \n",
    "    iou = (intersection + epsilon) / (union + epsilon)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def precision(binary_image1, binary_image2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the precision between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - precision: Precision.\n",
    "    \"\"\"\n",
    "    true_positives = np.sum(binary_image1 * binary_image2)\n",
    "    false_positives = np.sum(binary_image1 * (1 - binary_image2))\n",
    "    \n",
    "    precision = (true_positives) / (true_positives + false_positives + epsilon)\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(binary_image1, binary_image2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the recall between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - recall: Recall.\n",
    "    \"\"\"\n",
    "    true_positives = np.sum(binary_image1 * binary_image2)\n",
    "    false_negatives = np.sum((1 - binary_image1) * binary_image2)\n",
    "    \n",
    "    recall = true_positives / (true_positives + false_negatives + epsilon)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def rand_index(binary_image1, binary_image2):\n",
    "    \"\"\"\n",
    "    Compute the Rand index between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - rand_index: Rand index.\n",
    "    \"\"\"\n",
    "    true_positives = np.sum(binary_image1 * binary_image2)\n",
    "    false_positives = np.sum(binary_image1 * (1 - binary_image2))\n",
    "    false_negatives = np.sum((1 - binary_image1) * binary_image2)\n",
    "    true_negatives = np.sum((1 - binary_image1) * (1 - binary_image2))\n",
    "    \n",
    "    rand_index = (true_positives + true_negatives) / (true_positives + false_positives + false_negatives + true_negatives)\n",
    "    return rand_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import scipy.ndimage\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "def n4_bias_correction(img, bg_mask, shrink_factor: float=15, show: bool=False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    N4 bias correction for the input image.\n",
    "    \n",
    "    Parameters:\n",
    "    - img: The input image to correct.\n",
    "    - alpha: The alpha value for contrast adjustment.\n",
    "    - shrink_factor: The shrink factor for downsampling the image for bias correction.\n",
    "    - show: Whether to show the intermediate results.\n",
    "    \n",
    "    Returns:\n",
    "    - corrected_image_full_resolution: The bias corrected image.\n",
    "    \"\"\"\n",
    "    # Get contrast image for mask\n",
    "    #contrast_img = auto_contrast(img, alpha=alpha)\n",
    "    \n",
    "    # Create the brain tissue mask\n",
    "    #mask_img = sitk.GetImageFromArray(contrast_img)\n",
    "    #mask_img = sitk.RescaleIntensity(mask_img, 0, 255)\n",
    "    #mask_img = sitk.LiThreshold(mask_img, 0, 1)\n",
    "    bg_mask = bg_mask.astype(np.uint8)\n",
    "    mask_img = sitk.GetImageFromArray(bg_mask)\n",
    "    mask_img = sitk.LiThreshold(mask_img, 0, 1)\n",
    "\n",
    "    # Use the raw image and convert it to float32\n",
    "    raw_img = sitk.GetImageFromArray(img.copy())\n",
    "    raw_img = sitk.Cast(raw_img, sitk.sitkFloat32)\n",
    "\n",
    "    # Downsample it for bias correction\n",
    "    inputImage = raw_img\n",
    "    if shrink_factor > 1:\n",
    "        inputImage = sitk.Shrink( raw_img, [ shrink_factor ] * raw_img.GetDimension() ) #2\n",
    "        maskImage = sitk.Shrink( mask_img, [ shrink_factor ] * inputImage.GetDimension() ) #3\n",
    "\n",
    "    # Run bias correction\n",
    "    start_time = time.time()\n",
    "    bias_corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    corrected = bias_corrector.Execute(inputImage, maskImage)\n",
    "    \n",
    "    # Apply bias correction to full resolution image\n",
    "    log_bias_field = bias_corrector.GetLogBiasFieldAsImage(raw_img)\n",
    "    corrected_image_full_resolution = raw_img / sitk.Exp(log_bias_field)\n",
    "    end_time = time.time()\n",
    "    corrected_image_full_resolution = sitk.GetArrayFromImage(corrected_image_full_resolution)\n",
    "    \n",
    "    # Show the process if True\n",
    "    if show:\n",
    "        print(f\"Time taken for bias correction: {end_time - start_time:.2f} seconds\")\n",
    "        \n",
    "        # Show the brain tissue mask\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(sitk.GetArrayFromImage(mask_img), cmap='gray')\n",
    "        plt.title(f\"Full resolution brain mask\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(sitk.GetArrayFromImage(maskImage), cmap='gray')\n",
    "        plt.title(f\"Downsampled brain mask (shrink factor={shrink_factor})\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Show the log bias field\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(sitk.GetArrayFromImage(log_bias_field))\n",
    "        plt.colorbar()\n",
    "        plt.title(f\"Log bias field\")\n",
    "        plt.show()\n",
    "\n",
    "        # Show the corrected bias field image\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f\"Original raw image\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(corrected_image_full_resolution, cmap='gray')\n",
    "        plt.title(f\"Corrected bias raw image\")\n",
    "        plt.show()\n",
    "\n",
    "        # Increase the contrast of the corrected image and show side-by-side\n",
    "        preview_alpha = 0.25\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        contrast_comparison = auto_contrast(img, alpha=preview_alpha)\n",
    "        plt.imshow(contrast_comparison, cmap='gray')\n",
    "        plt.title(f\"Original contrast image (alpha={preview_alpha})\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        corrected_bias_contrast = auto_contrast(corrected_image_full_resolution, alpha=preview_alpha)\n",
    "        plt.imshow(corrected_bias_contrast, cmap='gray')\n",
    "        plt.title(f\"Corrected bias contrast image (alpha={preview_alpha})\")\n",
    "        plt.show()\n",
    "        \n",
    "    return corrected_image_full_resolution\n",
    "\n",
    "\n",
    "def preprocess_image(img, alpha: float=1, shrink_factor: float=15, \n",
    "                     median_filter_size: int=5, gaussian_sigma: float=0.2, \n",
    "                     show: bool=False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocess the image using N4 bias correction and filtering.\n",
    "    \n",
    "    Parameters:\n",
    "    - img: The input image to preprocess.\n",
    "    - alpha: The alpha value for contrast adjustment.\n",
    "    - shrink_factor: The shrink factor for downsampling the image for bias correction.\n",
    "    - median_filter_size: The size of the median filter to apply.\n",
    "    - gaussian_sigma: The sigma value for the Gaussian filter to apply.\n",
    "    - show: Whether to show the intermediate results.\n",
    "    \n",
    "    Returns:\n",
    "    - corrected_img: The preprocessed image.\n",
    "    \"\"\"\n",
    "    corrected_bias_img = n4_bias_correction(img, alpha=alpha, shrink_factor=shrink_factor, show=show)\n",
    "\n",
    "    # Run median filter\n",
    "    median_filtered_img = median_filter(corrected_bias_img.copy(), size=median_filter_size)\n",
    "\n",
    "    # Run gaussian filter\n",
    "    gaussian_filtered_img = scipy.ndimage.gaussian_filter(median_filtered_img.copy(), sigma=gaussian_sigma)\n",
    "\n",
    "    #if show:\n",
    "    #    get_stats(img, title=\"Original image stats:\")\n",
    "    #    get_stats(corrected_bias_img, title=\"N4 bias corrected image stats:\")\n",
    "    #    get_stats(median_filtered_img, title=\"Median filtered image stats:\")\n",
    "    #    get_stats(gaussian_filtered_img, title=\"Gaussian filtered image stats:\")\n",
    "        \n",
    "    corrected_img = gaussian_filtered_img        \n",
    "    return corrected_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage.measure import regionprops, label\n",
    "from skimage.morphology import skeletonize, medial_axis\n",
    "from pprint import pprint\n",
    "import csv\n",
    "\n",
    "# IO parameters\n",
    "filepath = \"/media/data/u01/Fig2025/Supplemental Fig3 DE/M1/*.tif\"\n",
    "output_csv_path = \"/media/data/u01/Fig2025/quant-fig2025/Supple-3-DE/M1/\"\n",
    "output_image_path = \"/media/data/u01/Fig2025/quant-fig2025/Supple-3-DE/M1/segmentation/\"\n",
    "IDX = 18  # 13, 14, 16 M1\n",
    "N = 251\n",
    "FILL_HOLES = True\n",
    "\n",
    "# Load the image channels\n",
    "curr_img, fp = load_channel(filepath, IDX)\n",
    "curr_ch2 = curr_img[:, :, 1]\n",
    "curr_ch2 = curr_ch2.astype(np.float32)\n",
    "print(\"Filepath:\", fp)\n",
    "\n",
    "# Run N4 bias correction\n",
    "bg_mask = np.ones(curr_ch2.shape, dtype=bool)\n",
    "curr_ch2 = n4_bias_correction(curr_ch2, bg_mask, shrink_factor=2, show=False)\n",
    "\n",
    "# Create a threshold mask for the image\n",
    "curr_ch2_median = ndimage.median_filter(curr_ch2.copy(), size=3)  # Repeat for ch2\n",
    "_, mask = cv2.threshold(curr_ch2_median.astype(np.uint8), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_TRIANGLE)\n",
    "mask2 = cv2.adaptiveThreshold(curr_ch2_median.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, N, 1)\n",
    "mask = mask * mask2\n",
    "#mask[curr_ch2_median < thresh] = 0\n",
    "\n",
    "mask = remove_small_objects(mask.astype(bool), min_size=100)\n",
    "if FILL_HOLES:\n",
    "     mask = ndimage.binary_fill_holes(mask)\n",
    "\n",
    "# Compute the medial axis (skeleton) and the distance transform\n",
    "skeleton_ch2, distance = medial_axis(mask, return_distance=True)\n",
    "\n",
    "show(image=curr_ch2_median, title=\"CH2: Input image thresh\",\n",
    "     contour=mask,\n",
    "     image2=curr_ch2_median, title2=\"CH2: Input image skeleton\",\n",
    "     contour2=skeleton_ch2,\n",
    "     figsize=(20, 10),\n",
    "     axis=False)\n",
    "\n",
    "\n",
    "# Get the length of the skeletons\n",
    "labeled_skeleton, num_features = label(skeleton_ch2, return_num=True)\n",
    "\n",
    "# Save the skeleton info\n",
    "thickness = []\n",
    "lengths = []\n",
    "for region in range(1, num_features + 1):\n",
    "     region_mask = labeled_skeleton == region\n",
    "     region_thickness = 2 * distance[region_mask]\n",
    "     region_length = np.sum(region_mask)\n",
    "     \n",
    "     thickness.append(np.mean(region_thickness))\n",
    "     lengths.append(region_length)\n",
    "\n",
    "\n",
    "# Save segmentation to file\n",
    "sitk_ch2 = sitk.GetImageFromArray(mask.astype(np.uint8))  # Ch2\n",
    "output_ch2_file = output_image_path + os.path.basename(fp).replace(\".tif\", \"_segmentation.tif\")\n",
    "sitk.WriteImage(sitk_ch2, output_ch2_file)\n",
    "\n",
    "# Save skeleton to file\n",
    "sitk_ch2 = sitk.GetImageFromArray(skeleton_ch2.astype(np.uint8))  # Ch2\n",
    "output_ch2_file = output_image_path + os.path.basename(fp).replace(\".tif\", \"_skeleton.tif\")\n",
    "sitk.WriteImage(sitk_ch2, output_ch2_file)\n",
    "\n",
    "# Save skeleton lengths to csv\n",
    "output_csv_file = output_csv_path + os.path.basename(fp).replace(\".tif\", \".csv\")\n",
    "with open(output_csv_file, mode='w') as csv_file:\n",
    "    fieldnames = ['thickness', 'length']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(thickness)):\n",
    "        writer.writerow({'thickness': thickness[i], 'length': lengths[i]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tissuecyte",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
