{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Standard imports\n",
    "import glob\n",
    "\n",
    "# 3rd party imports\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from pprint import pprint\n",
    "import SimpleITK as sitk\n",
    "sitk.ProcessObject_SetGlobalWarningDisplay(False)\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for IO operations\n",
    "def load_channels(filepath: str, idx: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load the image channels from the given filepath.\n",
    "    \n",
    "    Args:\n",
    "        filepath: str, path to the image\n",
    "        idx: int, index of the image to load\n",
    "        \n",
    "    Returns:\n",
    "        channels: np.ndarray, image channels\n",
    "    \"\"\"\n",
    "    filepaths = sorted(glob.glob(filepath))\n",
    "    print(f\"Found {int(len(filepaths)/2)} slices\")\n",
    "    pprint(filepaths)\n",
    "    \n",
    "    # Load the image\n",
    "    file_idx = idx * 2  # Multiply by 2 because we have 2 channels and they're stored in pairs\n",
    "    curr_img = (read_tif(filepaths[file_idx]), read_tif(filepaths[file_idx + 1]))\n",
    "    print(\"\\nCh1:\", filepaths[file_idx])\n",
    "    print(\"Ch2:\", filepaths[file_idx + 1])\n",
    "    curr_ch1 = curr_img[0]\n",
    "    curr_ch2 = curr_img[1]\n",
    "\n",
    "    # Check image stats\n",
    "    print(f\"\\nChannel shape: {curr_ch1.shape}\")\n",
    "    print(f\"Channel dtype: {curr_ch1.dtype}\")\n",
    "    print(f\"Channel 1 min: {curr_ch1.min()}\")\n",
    "    print(f\"Channel 1 max: {curr_ch1.max()}\")\n",
    "    print(f\"Channel 1 mean: {curr_ch1.mean()}\")\n",
    "    \n",
    "    return curr_ch1, curr_ch2\n",
    "\n",
    "\n",
    "def read_tif(filepath):\n",
    "    \"\"\"\n",
    "    Read tiff files using SimpleITK\n",
    "    \n",
    "    Args:\n",
    "        filepath: str, path to tiff file\n",
    "        \n",
    "    Returns:\n",
    "        image: np.ndarray, tiff image\n",
    "    \"\"\"\n",
    "    image = sitk.ReadImage(filepath)\n",
    "    image = sitk.GetArrayFromImage(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def auto_contrast(data: np.ndarray, alpha: float = None, beta: float = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocess tiff files to automatically adjust brightness and contrast.\n",
    "    https://stackoverflow.com/questions/56905592/automatic-contrast-and-brightness-adjustment-of-a-color-photo-of-a-sheet-of-pape\n",
    "    \"\"\"\n",
    "    if not alpha:\n",
    "        alpha = np.iinfo(data.dtype).max / (np.max(data) - np.min(data))\n",
    "    if not beta:\n",
    "        beta = -np.min(data) * alpha\n",
    "    img = cv2.convertScaleAbs(data.copy(), alpha=alpha, beta=beta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def gamma_correction(image: np.ndarray, gamma: float=2.0, min_value=None, max_value=None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply gamma correction to the image.\n",
    "    \n",
    "    Args:\n",
    "        image: np.ndarray, input image\n",
    "        gamma: float, gamma value\n",
    "        \n",
    "    Returns:\n",
    "        image_enhanced: np.ndarray, gamma corrected image\n",
    "    \"\"\"\n",
    "    if min_value is not None:\n",
    "        image = image.copy()\n",
    "        image[image < min_value] = 0\n",
    "    if max_value is None:\n",
    "        max_value = image.max()\n",
    "    else:\n",
    "        image = image.copy()\n",
    "        image[image > max_value] = max_value\n",
    "    # Normalize the image to the range [0, 1]\n",
    "    image_normalized = image / max_value\n",
    "    # Apply the exponential transformation\n",
    "    image_enhanced = np.power(image_normalized, gamma)\n",
    "    # Rescale the image back to the original intensity range\n",
    "    image_enhanced = image_enhanced * max_value\n",
    "    return image_enhanced\n",
    "\n",
    "\n",
    "def save_figure(image, filename, contours=None):\n",
    "    \"\"\"\n",
    "    Save figure to disk.\n",
    "    \n",
    "    Args:\n",
    "        image: np.ndarray, input image\n",
    "        filename: str, path to save the image\n",
    "        contours: np.ndarray, contours to overlay on the image\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    if contours is not None:\n",
    "        plt.contour(contours, colors='red', linewidths=0.15, alpha=0.35)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(filename, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Saved figure to {filename}\")\n",
    "    \n",
    "    \n",
    "def show(image: np.ndarray, contour: np.ndarray = None,\n",
    "         image2: np.ndarray = None, contour2: np.ndarray = None, contour_alpha: float = 0.75,\n",
    "         title: str = \"\", title2: str = \"\", \n",
    "         xlim: tuple[int, int] = None, ylim: tuple[int, int] = None,\n",
    "         xlim2: tuple[int, int] = None, ylim2: tuple[int, int] = None,\n",
    "         axis: bool = True,\n",
    "         figsize: tuple[int, int] = (10, 10)):\n",
    "    \"\"\"\n",
    "    Display the image.\n",
    "    \n",
    "    Args:\n",
    "        image: np.ndarray, input image\n",
    "        title: str, title of the image\n",
    "    \"\"\"\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    # If there are two images, display them side by side\n",
    "    if image2 is not None:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(title)\n",
    "        if contour is not None:\n",
    "            plt.contour(contour, colors='red', linewidths=0.5, alpha=contour_alpha)\n",
    "        if xlim is not None:\n",
    "            plt.xlim(xlim)\n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim)\n",
    "        plt.axis(axis)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(image2, cmap='gray')\n",
    "        plt.title(title2)\n",
    "        if contour2 is not None:\n",
    "            plt.contour(contour2, colors='red', linewidths=0.5, alpha=contour_alpha)\n",
    "        if xlim2 is not None:\n",
    "            plt.xlim(xlim2)\n",
    "        if ylim2 is not None:\n",
    "            plt.ylim(ylim2)\n",
    "        plt.axis(axis)\n",
    "    # If there is only one image, display it\n",
    "    else:\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(title)\n",
    "        if contour is not None:\n",
    "            plt.contour(contour, colors='red', linewidths=0.5, alpha=contour_alpha)\n",
    "        if xlim is not None:\n",
    "            plt.xlim(xlim)\n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim)\n",
    "        plt.axis(axis)\n",
    "    plt.show()\n",
    "    f.clear()\n",
    "    plt.close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for vessel detection\n",
    "import itk\n",
    "import numpy as np\n",
    "from skimage.morphology import remove_small_objects, binary_closing, disk, remove_small_holes\n",
    "\n",
    "# Parameters for vessel detection\n",
    "ALPHA = 0.5  # Default 0.5\n",
    "BETA = 0.5  # Default 1\n",
    "GAMMA = 5.0  # Default 5\n",
    "\n",
    "def detect_vessels(input_image: np.ndarray, min_sigma: float=1.0, max_sigma: float=10.0, num_steps: int=10):\n",
    "    \"\"\"\n",
    "    Use the Hessian-based vesselness filter to detect vessels in the image.\n",
    "    \n",
    "    Args:\n",
    "        input_image: np.ndarray, input image\n",
    "        min_sigma: float, minimum sigma value\n",
    "        max_sigma: float, maximum sigma value\n",
    "        num_steps: int, number of steps\n",
    "        \n",
    "    Returns:\n",
    "        segmented_vessels_array: np.ndarray, segmented vessels\n",
    "    \"\"\"\n",
    "    # Run ITK\n",
    "    input_image = itk.image_from_array(input_image)\n",
    "    #input_image = itk.imread(input_image, itk.F)\n",
    "\n",
    "    ImageType = type(input_image)\n",
    "    Dimension = input_image.GetImageDimension()\n",
    "    HessianPixelType = itk.SymmetricSecondRankTensor[itk.D, Dimension]\n",
    "    HessianImageType = itk.Image[HessianPixelType, Dimension]\n",
    "\n",
    "    objectness_filter = itk.HessianToObjectnessMeasureImageFilter[\n",
    "        HessianImageType, ImageType\n",
    "    ].New()\n",
    "    objectness_filter.SetBrightObject(False)  # Set to True if the structures are bright on a dark background\n",
    "    objectness_filter.SetScaleObjectnessMeasure(False)  # Set to True to scale the objectness measure by the scale\n",
    "    objectness_filter.SetAlpha(ALPHA)  # Sensitivity to blob-like structures\n",
    "                                     # Set/Get Alpha, the weight corresponding to R_A \n",
    "                                     # (the ratio of the smallest eigenvalue that has to be large to the larger ones). \n",
    "                                     # Smaller values lead to increased sensitivity to the object dimensionality.\n",
    "    objectness_filter.SetBeta(BETA)   # Sensitivity to plate-like structures - 1.0 default\n",
    "                                     # Set/Get Beta, the weight corresponding to R_B \n",
    "                                     # (the ratio of the largest eigenvalue that has to be small to the larger ones). \n",
    "                                     # Smaller values lead to increased sensitivity to the object dimensionality.\n",
    "    objectness_filter.SetGamma(GAMMA)  # Sensitivity to noise - 5.0 default\n",
    "                                     # Set/Get Gamma, the weight corresponding to S \n",
    "                                     # (the Frobenius norm of the Hessian matrix, or second-order structureness)\n",
    "\n",
    "    multi_scale_filter = itk.MultiScaleHessianBasedMeasureImageFilter[\n",
    "        ImageType, HessianImageType, ImageType\n",
    "    ].New()\n",
    "    multi_scale_filter.SetInput(input_image)\n",
    "    multi_scale_filter.SetHessianToMeasureFilter(objectness_filter)\n",
    "    multi_scale_filter.SetSigmaStepMethodToLogarithmic()\n",
    "    multi_scale_filter.SetSigmaMinimum(min_sigma)\n",
    "    multi_scale_filter.SetSigmaMaximum(max_sigma)\n",
    "    multi_scale_filter.SetNumberOfSigmaSteps(num_steps)\n",
    "\n",
    "    OutputPixelType = itk.UC\n",
    "    OutputImageType = itk.Image[OutputPixelType, Dimension]\n",
    "\n",
    "    rescale_filter = itk.RescaleIntensityImageFilter[ImageType, OutputImageType].New()\n",
    "    rescale_filter.SetInput(multi_scale_filter)\n",
    "    rescale_filter.Update()\n",
    "\n",
    "    # Get numpy array\n",
    "    segmented_vessels = rescale_filter.GetOutput()\n",
    "    segmented_vessels_array = itk.array_view_from_image(segmented_vessels)\n",
    "    segmented_vessels_array = np.asarray(segmented_vessels_array, dtype=np.float32)\n",
    "    return segmented_vessels_array\n",
    "\n",
    "\n",
    "def process_vessels(vessel_image: np.ndarray, thresh: int, min_size: int=10, area_threshold: float=2000, smoothing: int=3):\n",
    "    \"\"\"\n",
    "    Process the thresholded vessels.\n",
    "    \n",
    "    Args:\n",
    "        vessel_image: np.ndarray, input image\n",
    "        thresh: int, threshold value\n",
    "        min_size: int, minimum size\n",
    "        area_threshold: float, area threshold\n",
    "        smoothing: int, smoothing factor\n",
    "        \n",
    "    Returns:\n",
    "        thresholded_vessels: np.ndarray, thresholded vessels\n",
    "    \"\"\"\n",
    "    # Process the thresholded vessels\n",
    "    thresholded_vessels = vessel_image > thresh\n",
    "    thresholded_vessels = np.invert(thresholded_vessels)\n",
    "\n",
    "    # Get rid of small objects\n",
    "    thresholded_vessels = remove_small_objects(thresholded_vessels, min_size=min_size)\n",
    "    thresholded_vessels = remove_small_holes(thresholded_vessels, area_threshold=area_threshold)\n",
    "\n",
    "    # Smoothen edges\n",
    "    thresholded_vessels = binary_closing(thresholded_vessels, footprint=disk(smoothing))\n",
    "    \n",
    "    return thresholded_vessels\n",
    "\n",
    "\n",
    "def get_brain_mask(brain_image, area_threshold=300000, min_size=10000):\n",
    "    \"\"\"\n",
    "    Get the mask of the brain from the image (run before contrast enhancement).\n",
    "    \n",
    "    Args:\n",
    "        brain_image: np.ndarray, input image\n",
    "        thresh: int, threshold value\n",
    "        area_threshold: int, area threshold\n",
    "        \n",
    "    Returns:\n",
    "        mask: np.ndarray, mask of the brain\n",
    "    \"\"\"\n",
    "    _, mask = cv2.threshold(brain_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_TRIANGLE)\n",
    "    mask = remove_small_holes(mask.astype(bool), area_threshold=area_threshold)\n",
    "    mask = remove_small_objects(mask, min_size=min_size)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for evaluation\n",
    "import csv\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error\n",
    "from scipy.spatial.distance import hamming\n",
    "\n",
    "def dice_coefficient(binary_image1, binary_image2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the Dice coefficient between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - dice: Dice coefficient.\n",
    "    \"\"\"\n",
    "    intersection = np.sum(binary_image1 * binary_image2)\n",
    "    size1 = np.sum(binary_image1)\n",
    "    size2 = np.sum(binary_image2)\n",
    "    \n",
    "    dice = (2. * intersection + epsilon) / (size1 + size2 + epsilon)\n",
    "    return dice\n",
    "\n",
    "\n",
    "def iou(binary_image1, binary_image2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the Intersection over Union (IoU) between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - iou: IoU.\n",
    "    \"\"\"\n",
    "    intersection = np.sum(binary_image1 * binary_image2)\n",
    "    union = np.sum(binary_image1 + binary_image2)\n",
    "    \n",
    "    if union == 0:\n",
    "        iou = 1.0\n",
    "    \n",
    "    iou = (intersection + epsilon) / (union + epsilon)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def precision(binary_image1, binary_image2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the precision between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - precision: Precision.\n",
    "    \"\"\"\n",
    "    true_positives = np.sum(binary_image1 * binary_image2)\n",
    "    false_positives = np.sum(binary_image1 * (1 - binary_image2))\n",
    "    \n",
    "    precision = (true_positives) / (true_positives + false_positives + epsilon)\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(binary_image1, binary_image2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the recall between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - recall: Recall.\n",
    "    \"\"\"\n",
    "    true_positives = np.sum(binary_image1 * binary_image2)\n",
    "    false_negatives = np.sum((1 - binary_image1) * binary_image2)\n",
    "    \n",
    "    recall = true_positives / (true_positives + false_negatives + epsilon)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def rand_index(binary_image1, binary_image2):\n",
    "    \"\"\"\n",
    "    Compute the Rand index between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - rand_index: Rand index.\n",
    "    \"\"\"\n",
    "    true_positives = np.sum(binary_image1 * binary_image2)\n",
    "    false_positives = np.sum(binary_image1 * (1 - binary_image2))\n",
    "    false_negatives = np.sum((1 - binary_image1) * binary_image2)\n",
    "    true_negatives = np.sum((1 - binary_image1) * (1 - binary_image2))\n",
    "    \n",
    "    rand_index = (true_positives + true_negatives) / (true_positives + false_positives + false_negatives + true_negatives)\n",
    "    return rand_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IO parameters\n",
    "filepath = \"/media/data/u01/Fig7/7b/M106/*/*.tif\"\n",
    "IDX = 3\n",
    "\n",
    "# Load the image channels\n",
    "curr_ch1, curr_ch2 = load_channels(filepath, IDX)\n",
    "curr_ch1 = curr_ch1.astype(np.float32)\n",
    "curr_ch2 = curr_ch2.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply processing on the images and retrieve background mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ch1 settings\n",
    "gamma_ch1 = 2  # You can adjust this value to control the contrast enhancement\n",
    "contrast_alpha_ch1 = 0.0225  # Try 0.15 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "# Ch1 settings\n",
    "gamma_ch2 = 2  # You can adjust this value to control the contrast enhancement\n",
    "contrast_alpha_ch2 = 0.125  # Try 0.15 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "\n",
    "# No change\n",
    "contrast_ch1 = curr_ch1\n",
    "contrast_ch2 = curr_ch2\n",
    "\n",
    "cc_ch1 = auto_contrast(contrast_ch1, alpha=contrast_alpha_ch1)\n",
    "cc_ch2 = auto_contrast(contrast_ch2, alpha=contrast_alpha_ch2)\n",
    "\n",
    "# Compute the original image contrast\n",
    "#contrast_ch0 = gamma_correction(curr_ch0, gamma=gamma_ch0)\n",
    "#contrast_ch0 = auto_contrast(contrast_ch0, alpha=contrast_alpha_ch0)\n",
    "#contrast_ch1 = gamma_correction(curr_ch1, gamma=gamma_ch1)\n",
    "#contrast_ch1 = auto_contrast(contrast_ch1, alpha=contrast_alpha_ch1)\n",
    "#contrast_ch2 = gamma_correction(curr_ch2, gamma=gamma_ch2)\n",
    "#contrast_ch2 = auto_contrast(contrast_ch2, alpha=contrast_alpha_ch2)\n",
    "\n",
    "#bg_mask = gamma_correction(curr_ch0, gamma=gamma_ch0)\n",
    "if IDX == 99999: \n",
    "    bg_alpha = 0.1\n",
    "else:\n",
    "    bg_alpha = 0.5  # 7 all but 3\n",
    "bg_mask = auto_contrast(curr_ch1, alpha=bg_alpha)  # 7\n",
    "bg_mask = get_brain_mask(bg_mask, area_threshold=25000)  # 255 default ch0, 150 for ch1\n",
    "\n",
    "show(cc_ch1, bg_mask, title=f\"Section {IDX} ch1 contrast\", axis=True)\n",
    "show(cc_ch2, bg_mask, title=f\"Section {IDX} ch2 contrast\", axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup FOVs\n",
    "fovs = [ \n",
    "    # xlim,             ylim\n",
    "    ( (4000, 5000),     (4000, 5000) ),\n",
    "    ( (2000, 3000),     (2000, 4000) ),\n",
    "    ( (2000, 4000),     (4000, 6000) ),\n",
    "    ( (5000, 6000),     (2000, 4000) ),\n",
    "    ( (5000, 6000),     (1000, 2000) ),\n",
    "    ( (5000, 6000),     (4000, 5000) ),\n",
    "]\n",
    "\n",
    "fov1_xlim, fov1_ylim = fovs[0][0], fovs[0][1][::-1]\n",
    "fov2_xlim, fov2_ylim = fovs[1][0], fovs[1][1][::-1]\n",
    "fov3_xlim, fov3_ylim = fovs[2][0], fovs[2][1][::-1]\n",
    "fov4_xlim, fov4_ylim = fovs[3][0], fovs[3][1][::-1]\n",
    "fov5_xlim, fov5_ylim = fovs[4][0], fovs[4][1][::-1]\n",
    "fov6_xlim, fov6_ylim = fovs[5][0], fovs[5][1][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold for CH1 and CH2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a threshold mask for the image\n",
    "curr_ch1_median = ndimage.median_filter(curr_ch1.copy(), size=5)\n",
    "curr_ch2_median = ndimage.median_filter(curr_ch2.copy(), size=5)  # Repeat for ch2\n",
    "\n",
    "# Create auto contrast brightened images\n",
    "auto_ch1 = auto_contrast(curr_ch1, alpha=0.0225)\n",
    "auto_ch2 = auto_contrast(curr_ch2, alpha=0.125)\n",
    "auto_ch1_median = ndimage.median_filter(auto_ch1.copy(), size=5) # 5\n",
    "auto_ch2_median = ndimage.median_filter(auto_ch2.copy(), size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gamma test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ch1 settings\n",
    "gamma_ch1 = 2  # You can adjust this value to control the contrast enhancement\n",
    "contrast_alpha_ch1 = 0.0225  # 2\n",
    "\n",
    "# Ch2 settings\n",
    "gamma_ch2 = 2  # You can adjust this value to control the contrast enhancement\n",
    "contrast_alpha_ch2 = 0.125  # Try 0.15 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "THRESH = 1750   # Default 1500\n",
    "THRESH2 = 400  # Default 400\n",
    "max_value = 2000\n",
    "\n",
    "if IDX == 0:\n",
    "     THRESH = 1400  # 1600\n",
    "     max_value = 4000  # 4000\n",
    "elif IDX == 1:\n",
    "     THRESH = 1400  # 1400\n",
    "     max_value = 4000  # 4000\n",
    "elif IDX == 2:\n",
    "     THRESH = 1000  # 1400\n",
    "     max_value = 4000  # 4000\n",
    "elif IDX == 3:\n",
    "     THRESH = 800  # 800\n",
    "     max_value = 4000\n",
    "\n",
    "# Create contrast enhanced images\n",
    "cc_ch1 = gamma_correction(curr_ch1, gamma=gamma_ch1)\n",
    "cc_ch1 = auto_contrast(cc_ch1, alpha=contrast_alpha_ch1)\n",
    "cc_ch1_alt = gamma_correction(curr_ch1_median, gamma=gamma_ch1, max_value=max_value)\n",
    "print(\"Max value:\", cc_ch1_alt.max())\n",
    "print(\"Median value:\", np.median(cc_ch1_alt))\n",
    "#cc_ch1_alt = auto_contrast(cc_ch1_alt, alpha=contrast_alpha_ch1)\n",
    "cc_ch2 = gamma_correction(curr_ch2, gamma=gamma_ch2)\n",
    "cc_ch2 = auto_contrast(cc_ch2, alpha=contrast_alpha_ch2)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Threshold for ch1: {THRESH}\")\n",
    "print(f\"Threshold for ch2: {THRESH2}\")\n",
    "curr_ch1_thresh = cc_ch1_alt.copy() > THRESH\n",
    "curr_ch1_thresh[curr_ch1_thresh != 0] = 1\n",
    "curr_ch1_thresh = curr_ch1_thresh.astype(bool)\n",
    "\n",
    "curr_ch2_thresh = curr_ch2_median.copy() > THRESH2\n",
    "curr_ch2_thresh[curr_ch2_thresh != 0] = 1\n",
    "curr_ch2_thresh = curr_ch2_thresh.astype(bool)\n",
    "\n",
    "##########################################\n",
    "# FOV 1\n",
    "##########################################\n",
    "\n",
    "\"\"\"\n",
    "show(image=cc_ch1, title=f\"Section {IDX} ch1 contrast FOV1\", \n",
    "     xlim=fov1_xlim, ylim=fov1_ylim,\n",
    "     image2=cc_ch2, title2=f\"Section {IDX} ch2 contrast FOV1\", \n",
    "     xlim2=fov1_xlim, ylim2=fov1_ylim)\n",
    "\"\"\"\n",
    "\n",
    "show(image=cc_ch1_alt, title=f\"Section {IDX} ch1 contrast alt FOV1\", \n",
    "     xlim=fov1_xlim, ylim=fov1_ylim,\n",
    "     contour=curr_ch1_thresh, \n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 contrast FOV1\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov1_xlim, ylim2=fov1_ylim)\n",
    "\n",
    "show(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV1\", \n",
    "     xlim=fov1_xlim, ylim=fov1_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV1\", \n",
    "     xlim2=fov1_xlim, ylim2=fov1_ylim)\n",
    "\n",
    "show(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV1\", \n",
    "     contour=curr_ch1_thresh, \n",
    "     xlim=fov1_xlim, ylim=fov1_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV1\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov1_xlim, ylim2=fov1_ylim)\n",
    "\n",
    "print(\"##########################################\")\n",
    "\n",
    "##########################################\n",
    "# FOV 2\n",
    "##########################################\n",
    "\n",
    "\"\"\"\n",
    "show(image=cc_ch1, title=f\"Section {IDX} ch1 contrast FOV2\", \n",
    "     contour=curr_ch1_thresh, \n",
    "     xlim=fov2_xlim, ylim=fov2_ylim,\n",
    "     image2=cc_ch2, title2=f\"Section {IDX} ch2 contrast FOV2\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov2_xlim, ylim2=fov2_ylim)\n",
    "\"\"\"\n",
    "\n",
    "show(image=cc_ch1_alt, title=f\"Section {IDX} ch1 contrast alt FOV2\", \n",
    "     contour=curr_ch1_thresh, \n",
    "     xlim=fov2_xlim, ylim=fov2_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 contrast FOV2\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov2_xlim, ylim2=fov2_ylim)\n",
    "\n",
    "show(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV2\", \n",
    "     xlim=fov2_xlim, ylim=fov2_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV2\", \n",
    "     xlim2=fov2_xlim, ylim2=fov2_ylim)\n",
    "\n",
    "show(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV2\", \n",
    "     contour=curr_ch1_thresh, \n",
    "     xlim=fov2_xlim, ylim=fov2_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV2\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov2_xlim, ylim2=fov2_ylim)\n",
    "\n",
    "print(\"##########################################\")\n",
    "\n",
    "##########################################\n",
    "# FOV 3\n",
    "##########################################\n",
    "\n",
    "show(image=cc_ch1_alt, title=f\"Section {IDX} ch1 contrast alt FOV3\", \n",
    "     contour=curr_ch1_thresh, \n",
    "     xlim=fov3_xlim, ylim=fov3_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 contrast FOV3\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov3_xlim, ylim2=fov3_ylim)\n",
    "\n",
    "show(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV3\",\n",
    "     xlim=fov3_xlim, ylim=fov3_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV3\", \n",
    "     xlim2=fov3_xlim, ylim2=fov3_ylim)\n",
    "\n",
    "show(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV3\", \n",
    "     contour=curr_ch1_thresh,\n",
    "     xlim=fov3_xlim, ylim=fov3_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV3\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov3_xlim, ylim2=fov3_ylim)\n",
    "\n",
    "print(\"##########################################\")\n",
    "\n",
    "##########################################\n",
    "# FOV 4\n",
    "##########################################\n",
    "\n",
    "show(image=cc_ch1_alt, title=f\"Section {IDX} ch1 contrast alt FOV4\", \n",
    "     contour=curr_ch1_thresh, \n",
    "     xlim=fov4_xlim, ylim=fov4_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 contrast FOV4\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov4_xlim, ylim2=fov4_ylim)\n",
    "\n",
    "show(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV4\",\n",
    "     xlim=fov4_xlim, ylim=fov4_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV4\", \n",
    "     xlim2=fov4_xlim, ylim2=fov4_ylim)\n",
    "\n",
    "show(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV4\", \n",
    "     contour=curr_ch1_thresh,\n",
    "     xlim=fov4_xlim, ylim=fov4_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV4\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov4_xlim, ylim2=fov4_ylim)\n",
    "\n",
    "print(\"##########################################\")\n",
    "\n",
    "##########################################\n",
    "# FOV 5\n",
    "##########################################\n",
    "\n",
    "show(image=cc_ch1_alt, title=f\"Section {IDX} ch1 contrast alt FOV5\", \n",
    "     contour=curr_ch1_thresh, \n",
    "     xlim=fov5_xlim, ylim=fov5_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV5\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov5_xlim, ylim2=fov5_ylim)\n",
    "\n",
    "show(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV5\",\n",
    "     xlim=fov5_xlim, ylim=fov5_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV5\", \n",
    "     xlim2=fov5_xlim, ylim2=fov5_ylim)\n",
    "\n",
    "show(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV5\", \n",
    "     contour=curr_ch1_thresh,\n",
    "     xlim=fov5_xlim, ylim=fov5_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV5\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov5_xlim, ylim2=fov5_ylim)\n",
    "\n",
    "print(\"##########################################\")\n",
    "\n",
    "##########################################\n",
    "# FOV 6\n",
    "##########################################\n",
    "\n",
    "show(image=cc_ch1_alt, title=f\"Section {IDX} ch1 contrast alt FOV6\", \n",
    "     contour=curr_ch1_thresh, \n",
    "     xlim=fov6_xlim, ylim=fov6_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 contrast FOV6\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov6_xlim, ylim2=fov6_ylim)\n",
    "\n",
    "show(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV6\",\n",
    "     xlim=fov6_xlim, ylim=fov6_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV6\", \n",
    "     xlim2=fov6_xlim, ylim2=fov6_ylim)\n",
    "\n",
    "show(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV6\", \n",
    "     contour=curr_ch1_thresh,\n",
    "     xlim=fov6_xlim, ylim=fov6_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV6\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov6_xlim, ylim2=fov6_ylim)\n",
    "\n",
    "print(\"##########################################\")\n",
    "\n",
    "##########################################################\n",
    "# FULL SECTION\n",
    "##########################################################\n",
    "\n",
    "show(image=cc_ch1, title=f\"Full section {IDX} ch1 contrast\", \n",
    "     image2=cc_ch2, title2=f\"Full section {IDX} ch2 contrast\",\n",
    "     figsize=(20, 10), axis=True)\n",
    "\n",
    "show(image=auto_ch1, title=f\"Full section {IDX} ch1 brightened\", \n",
    "     image2=auto_ch2, title2=f\"Full section {IDX} ch2 brightened\",\n",
    "     figsize=(20, 10), axis=True)\n",
    "\n",
    "show(image=curr_ch1_thresh, title=f\"Full section {IDX} ch1 thresholded\", \n",
    "     image2=curr_ch2_thresh, title2=f\"Full section {IDX} ch2 thresholded\",\n",
    "     figsize=(20, 10), axis=True)\n",
    "\n",
    "#thresholded_vessels_ch1 = curr_ch1_thresh\n",
    "#thresholded_vessels_ch2 = curr_ch2_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hessian Filter\n",
    "https://examples.itk.org/src/nonunit/review/segmentbloodvesselswithmultiscalehessianbasedmeasure/documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANNEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for vessel detection\n",
    "sigma_minimum = 1.0  # Range of scales in which MultiScaleHessianBasedMeasureImageFilter will search for vessels\n",
    "sigma_maximum = 10.0  # 10\n",
    "number_of_sigma_steps = 10  # 10 Number of scales to search for vessels\n",
    "\n",
    "# Parameters for post-processing\n",
    "thresh = 230  # Threshold for binarization, 230 and 25 and 15\n",
    "min_size = 100  # Minimum size of objects to keep 100\n",
    "area_threshold = 2000 # Minimum area of holes to keep\n",
    "smoothing = 1  # Smoothing factor for closing, 3\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# Alternative: load image in memory\n",
    "input_image = auto_ch1_median * bg_mask\n",
    "#input_image = cc_ch1_alt * bg_mask\n",
    "input_image = input_image.astype(np.float32)\n",
    "input_image *= 255.0\n",
    "\n",
    "show(input_image, title=\"CH1: Input image\", axis=False)\n",
    "\n",
    "# Print statistics\n",
    "print(\"Input image type:\", input_image.dtype)\n",
    "print(\"Input image min:\", input_image.min())\n",
    "print(\"Input image max:\", input_image.max())\n",
    "\n",
    "# Run the vessel detection\n",
    "segmented_vessels_array = detect_vessels(input_image, sigma_minimum, sigma_maximum, number_of_sigma_steps)\n",
    "\n",
    "# Process the thresholded vessels\n",
    "thresholded_vessels_ch1 = process_vessels(segmented_vessels_array, thresh=thresh, min_size=min_size, area_threshold=area_threshold, smoothing=smoothing)\n",
    "thresholded_vessels_ch1 = thresholded_vessels_ch1 * bg_mask * curr_ch1_thresh\n",
    "\n",
    "# Print statistics\n",
    "print(\"Vesselness image statistics:\")\n",
    "print(\"Shape:\", segmented_vessels_array.shape)\n",
    "print(\"Min:\", segmented_vessels_array.min())\n",
    "print(\"Max:\", segmented_vessels_array.max())\n",
    "print(\"Mean:\", segmented_vessels_array.mean())\n",
    "print(\"Median:\", np.median(segmented_vessels_array))\n",
    "#print(\"Std:\", segmented_vessels_array.std())\n",
    "\n",
    "print(\"CHANNEL 1\")\n",
    "\n",
    "# Plot the raw vesselness image\n",
    "show(image=segmented_vessels_array, title=f\"CH1: Vesselness image\",\n",
    "     image2=thresholded_vessels_ch1, title2=f\"CH1: Vessel mask\",\n",
    "     axis=False)\n",
    "\n",
    "# Show the results\n",
    "show(image=input_image, title=\"CH1: Input image\",\n",
    "     image2=input_image, title2=\"Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch1, contour_alpha=0.45,\n",
    "     axis=False)\n",
    "\n",
    "# Plot the raw vesselness image FOV1\n",
    "show(image=segmented_vessels_array, title=f\"CH1 FOV1: Vesselness image\",\n",
    "     image2=thresholded_vessels_ch1, title2=f\"CH1 FOV1: Vessel mask\",\n",
    "     xlim=fov1_xlim, ylim=fov1_ylim, xlim2=fov1_xlim, ylim2=fov1_ylim,\n",
    "     axis=False)\n",
    "\n",
    "\n",
    "# FOV1\n",
    "show(image=input_image, title=\"CH1 FOV1: Input image\",\n",
    "     image2=input_image, title2=\"CH1 FOV1: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch1, contour_alpha=0.45,\n",
    "     xlim=fov1_xlim, ylim=fov1_ylim, xlim2=fov1_xlim, ylim2=fov1_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV2\n",
    "show(image=input_image, title=\"CH1 FOV2: Input image\",\n",
    "     image2=input_image, title2=\"CH1 FOV2: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch1, contour_alpha=0.45,\n",
    "     xlim=fov2_xlim, ylim=fov2_ylim, xlim2=fov2_xlim, ylim2=fov2_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV3\n",
    "show(image=input_image, title=\"CH1 FOV3: Input image\",\n",
    "     image2=input_image, title2=\"CH1 FOV3: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch1, contour_alpha=0.45,\n",
    "     xlim=fov3_xlim, ylim=fov3_ylim, xlim2=fov3_xlim, ylim2=fov3_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV4\n",
    "show(image=input_image, title=\"CH1 FOV4: Input image\",\n",
    "     image2=input_image, title2=\"CH1 FOV4: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch1, contour_alpha=0.45,\n",
    "     xlim=fov4_xlim, ylim=fov4_ylim, xlim2=fov4_xlim, ylim2=fov4_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV5\n",
    "show(image=input_image, title=\"CH1 FOV5: Input image\",\n",
    "     image2=input_image, title2=\"CH1 FOV5: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch1, contour_alpha=0.45,\n",
    "     xlim=fov5_xlim, ylim=fov5_ylim, xlim2=fov5_xlim, ylim2=fov5_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV6\n",
    "show(image=input_image, title=\"CH1 FOV6: Input image\",\n",
    "     image2=input_image, title2=\"CH1 FOV6: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch1, contour_alpha=0.45,\n",
    "     xlim=fov6_xlim, ylim=fov6_ylim, xlim2=fov6_xlim, ylim2=fov6_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# Full section\n",
    "show(image=thresholded_vessels_ch1, title=\"CH1: Vessel segmentation\",\n",
    "     image2=curr_ch2_thresh, title2=\"CH2: Thresholded vessels\",\n",
    "     figsize=(20, 10), axis=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANNEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for vessel detection\n",
    "sigma_minimum = 1.0  # Range of scales in which MultiScaleHessianBasedMeasureImageFilter will search for vessels\n",
    "sigma_maximum = 10.0  # 10\n",
    "number_of_sigma_steps = 10  # 10 Number of scales to search for vessels\n",
    "\n",
    "# Parameters for post-processing\n",
    "thresh = 230  # Threshold for binarization, 230\n",
    "min_size = 100  # Minimum size of objects to keep\n",
    "area_threshold = 2000 # Minimum area of holes to keep\n",
    "smoothing = 1  # Smoothing factor for closing, 3\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# Alternative: load image in memory\n",
    "input_image = auto_ch2_median * bg_mask\n",
    "input_image = input_image.astype(np.float32)\n",
    "input_image *= 255.0\n",
    "\n",
    "show(input_image, title=\"CH2: Input image\", axis=False)\n",
    "\n",
    "# Print statistics\n",
    "print(\"Input image type:\", input_image.dtype)\n",
    "print(\"Input image min:\", input_image.min())\n",
    "print(\"Input image max:\", input_image.max())\n",
    "\n",
    "# Run the vessel detection\n",
    "segmented_vessels_array = detect_vessels(input_image, sigma_minimum, sigma_maximum, number_of_sigma_steps)\n",
    "\n",
    "# Process the thresholded vessels\n",
    "thresholded_vessels_ch2 = process_vessels(segmented_vessels_array, thresh=thresh, min_size=min_size, area_threshold=area_threshold, smoothing=smoothing)\n",
    "thresholded_vessels_ch2 = thresholded_vessels_ch2 * bg_mask * curr_ch2_thresh\n",
    "\n",
    "# Print statistics\n",
    "print(\"Vesselness image statistics:\")\n",
    "print(\"Shape:\", segmented_vessels_array.shape)\n",
    "print(\"Min:\", segmented_vessels_array.min())\n",
    "print(\"Max:\", segmented_vessels_array.max())\n",
    "print(\"Mean:\", segmented_vessels_array.mean())\n",
    "print(\"Median:\", np.median(segmented_vessels_array))\n",
    "#print(\"Std:\", segmented_vessels_array.std())\n",
    "\n",
    "print(\"CHANNEL 2\")\n",
    "\n",
    "# Plot the raw vesselness image\n",
    "show(image=segmented_vessels_array, title=f\"CH2: Vesselness image\",\n",
    "     image2=thresholded_vessels_ch2, title2=f\"CH2: Vessel mask\",\n",
    "     axis=False)\n",
    "\n",
    "# Show the results\n",
    "show(image=input_image, title=\"CH2: Input image\",\n",
    "     image2=input_image, title2=\"Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch2, contour_alpha=0.45,\n",
    "     axis=False)\n",
    "\n",
    "# Plot the raw vesselness image FOV1\n",
    "show(image=segmented_vessels_array, title=f\"CH2 FOV1: Vesselness image\",\n",
    "     image2=thresholded_vessels_ch2, title2=f\"CH2 FOV1: Vessel mask\",\n",
    "     xlim=fov1_xlim, ylim=fov1_ylim, xlim2=fov1_xlim, ylim2=fov1_ylim,\n",
    "     axis=False)\n",
    "\n",
    "\n",
    "# FOV1\n",
    "show(image=input_image, title=\"CH2 FOV1: Input image\",\n",
    "     image2=input_image, title2=\"CH2 FOV1: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch2, contour_alpha=0.45,\n",
    "     xlim=fov1_xlim, ylim=fov1_ylim, xlim2=fov1_xlim, ylim2=fov1_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV2\n",
    "show(image=input_image, title=\"CH2 FOV2: Input image\",\n",
    "     image2=input_image, title2=\"CH2 FOV2: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch2, contour_alpha=0.45,\n",
    "     xlim=fov2_xlim, ylim=fov2_ylim, xlim2=fov2_xlim, ylim2=fov2_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV3\n",
    "show(image=input_image, title=\"CH2 FOV3: Input image\",\n",
    "     image2=input_image, title2=\"CH2 FOV3: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch2, contour_alpha=0.45,\n",
    "     xlim=fov3_xlim, ylim=fov3_ylim, xlim2=fov3_xlim, ylim2=fov3_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV4\n",
    "show(image=input_image, title=\"CH2 FOV4: Input image\",\n",
    "     image2=input_image, title2=\"CH2 FOV4: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch2, contour_alpha=0.45,\n",
    "     xlim=fov4_xlim, ylim=fov4_ylim, xlim2=fov4_xlim, ylim2=fov4_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV5\n",
    "show(image=input_image, title=\"CH2 FOV5: Input image\",\n",
    "     image2=input_image, title2=\"CH2 FOV5: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch2, contour_alpha=0.45,\n",
    "     xlim=fov5_xlim, ylim=fov5_ylim, xlim2=fov5_xlim, ylim2=fov5_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV6\n",
    "show(image=input_image, title=\"CH2 FOV6: Input image\",\n",
    "     image2=input_image, title2=\"CH2 FOV6: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch2, contour_alpha=0.45,\n",
    "     xlim=fov6_xlim, ylim=fov6_ylim, xlim2=fov6_xlim, ylim2=fov6_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# Full section\n",
    "show(image=thresholded_vessels_ch1, title=\"CH1: Vessel segmentation\",\n",
    "     image2=thresholded_vessels_ch2, title2=\"CH2: Vessel segmentation\",\n",
    "     figsize=(10, 10), axis=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i = 0:\n",
    "\n",
    "\n",
    "Dice coefficient: 0.42411068987180006\n",
    "IoU score: 0.2691246695729526\n",
    "Precision score: 0.6294159745347224\n",
    "Recall score: 0.31979782500429416\n",
    "SSIM score: 0.7485813152339447\n",
    "MSE score: 0.11598956526140992\n",
    "Hamming distance: 0.11598956526140992\n",
    "Rand index: 0.8840104347385901\n",
    "\n",
    "i = 1:\n",
    "\n",
    "Dice coefficient: 0.42784078682519283\n",
    "IoU score: 0.27213578830938767\n",
    "Precision score: 0.6226656435973017\n",
    "Recall score: 0.3258774979835265\n",
    "SSIM score: 0.7482098056616051\n",
    "MSE score: 0.11578135242146209\n",
    "Hamming distance: 0.11578135242146209\n",
    "Rand index: 0.884218647578538\n",
    "\n",
    "\n",
    "i = 2:\n",
    "\n",
    "Dice coefficient: 0.35917833330468135\n",
    "IoU score: 0.2189015056268004\n",
    "Precision score: 0.5407998576777105\n",
    "Recall score: 0.26887851932163065\n",
    "SSIM score: 0.8319550597966561\n",
    "MSE score: 0.07499218512130308\n",
    "Hamming distance: 0.07499218512130308\n",
    "Rand index: 0.9250078148786969\n",
    "\n",
    "i = 3:\n",
    "\n",
    "Dice coefficient: 0.3879609013801778\n",
    "IoU score: 0.24066469709843755\n",
    "Precision score: 0.612943451204528\n",
    "Recall score: 0.2837936685726384\n",
    "SSIM score: 0.8111572870712608\n",
    "MSE score: 0.08667642593981273\n",
    "Hamming distance: 0.08667642593981273\n",
    "Rand index: 0.9133235740601873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_ch0 = thresholded_vessels_ch1\n",
    "thresholded_ch1 = thresholded_vessels_ch2\n",
    "\n",
    "# Compute the metrics\n",
    "dice_score = dice_coefficient(thresholded_ch0, thresholded_ch1)  \n",
    "iou_score = iou(thresholded_ch0, thresholded_ch1)  # Strongly penalizes over-segmentation and under-segmentation\n",
    "precision_score = precision(thresholded_ch0, thresholded_ch1) \n",
    "recall_score = recall(thresholded_ch0, thresholded_ch1)\n",
    "ssim_score = ssim(thresholded_ch0, thresholded_ch1)\n",
    "mse_score = mean_squared_error(thresholded_ch0, thresholded_ch1)\n",
    "thresh_ch0_flat = thresholded_ch0.flatten()\n",
    "thresh_ch1_flat = thresholded_ch1.flatten()\n",
    "hamming_distance = hamming(thresh_ch0_flat, thresh_ch1_flat)\n",
    "rand_score = rand_index(thresholded_ch0, thresholded_ch1)  # Measures how close points are clustered together\n",
    "\n",
    "print(\"idx =\", IDX)\n",
    "print(\"thresh =\", THRESH)\n",
    "print(\"Dice coefficient:\", dice_score)\n",
    "print(\"IoU score:\", iou_score)\n",
    "print(\"Precision score:\", precision_score)\n",
    "print(\"Recall score:\", recall_score)\n",
    "print(\"SSIM score:\", ssim_score)\n",
    "print(\"MSE score:\", mse_score)\n",
    "print(\"Hamming distance:\", hamming_distance)\n",
    "print(\"Rand index:\", rand_score)\n",
    "\n",
    "# Write the solutions to a CSV file\n",
    "csv_filename = 'stats_enhanced_M106.csv'\n",
    "\n",
    "# Write to rows\n",
    "rows = [[\"Index\", \"Dice coefficient\", \"IoU score\", \"Precision\", \"Recall\", \"SSIM\", \"MSE\", \"Hamming distance\", \"Rand index\"]]\n",
    "rows.append([IDX, dice_score, iou_score, precision_score, recall_score, ssim_score, mse_score, hamming_distance, rand_score])\n",
    "\n",
    "#with open(csv_filename, mode='w', newline='') as file:\n",
    "#    writer = csv.writer(file)\n",
    "#    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M106\n",
    "\n",
    "i = 0 (original 2200)\n",
    "\n",
    "no mask\n",
    "Dice coefficient: 0.47672714941402217\n",
    "IoU score: 0.31296241460000623\n",
    "Precision score: 0.37038620546108075\n",
    "Recall score: 0.6687230776390751\n",
    "SSIM score: 0.6041838404919053\n",
    "MSE score: 0.19605965989461135\n",
    "Hamming distance: 0.19605965989461135\n",
    "Rand index: 0.8039403401053886\n",
    "\n",
    "thresh = 1000\n",
    "Dice coefficient: 0.5025460148664612\n",
    "IoU score: 0.33560030548895003\n",
    "Precision score: 0.4298795843696149\n",
    "Recall score: 0.6047769228407175\n",
    "SSIM score: 0.6562935647078479\n",
    "MSE score: 0.15990274121342082\n",
    "Hamming distance: 0.15990274121342082\n",
    "Rand index: 0.8400972587865791\n",
    "\n",
    "thresh = 1200\n",
    "Dice coefficient: 0.5075368376586201\n",
    "IoU score: 0.3400665761574946\n",
    "Precision score: 0.472912310169995\n",
    "Recall score: 0.547632007730418\n",
    "SSIM score: 0.6872432469474905\n",
    "MSE score: 0.14193144387319145\n",
    "Hamming distance: 0.14193144387319145\n",
    "Rand index: 0.8580685561268085\n",
    "\n",
    "**thresh = 1400**\n",
    "Dice coefficient: 0.5011254601422405\n",
    "IoU score: 0.33433449352592\n",
    "Precision score: 0.5191762362304143\n",
    "Recall score: 0.48428769274467265\n",
    "SSIM score: 0.7120537016214114\n",
    "MSE score: 0.1287751076586028\n",
    "Hamming distance: 0.1287751076586028\n",
    "Rand index: 0.8712248923413972\n",
    "\n",
    "thresh = 1600\n",
    "Dice coefficient: 0.4814350779093821\n",
    "IoU score: 0.31703292424704993\n",
    "Precision score: 0.5675273750605996\n",
    "Recall score: 0.4180222806076477\n",
    "SSIM score: 0.7317205760996874\n",
    "MSE score: 0.12026754696657609\n",
    "Hamming distance: 0.12026754696657609\n",
    "Rand index: 0.879732453033424\n",
    "\n",
    "thresh = 1800\n",
    "Dice coefficient: 0.4583110526190515\n",
    "IoU score: 0.2972785485669073\n",
    "Precision score: 0.5971730846358245\n",
    "Recall score: 0.3718450639419566\n",
    "SSIM score: 0.741116494168267\n",
    "MSE score: 0.11739112952705186\n",
    "Hamming distance: 0.11739112952705186\n",
    "Rand index: 0.8826088704729481\n",
    "\n",
    "i = 1 (original 2000)\n",
    "\n",
    "no mask\n",
    "Dice coefficient: 0.46782207723345515\n",
    "IoU score: 0.30533143069229324\n",
    "Precision score: 0.3616159525834917\n",
    "Recall score: 0.6623548023468838\n",
    "SSIM score: 0.5944701695120423\n",
    "MSE score: 0.200178008456473\n",
    "Hamming distance: 0.200178008456473\n",
    "Rand index: 0.799821991543527\n",
    "\n",
    "thresh = 1000\n",
    "Dice coefficient: 0.5042112707056357\n",
    "IoU score: 0.3370872241720236\n",
    "Precision score: 0.4683638278556711\n",
    "Recall score: 0.5460008660540057\n",
    "SSIM score: 0.6840184170844298\n",
    "MSE score: 0.14263528221310992\n",
    "Hamming distance: 0.14263528221310992\n",
    "Rand index: 0.85736471778689\n",
    "\n",
    "thresh = 1200\n",
    "Dice coefficient: 0.49797427359951096\n",
    "IoU score: 0.33153511610808106\n",
    "Precision score: 0.5195630878441235\n",
    "Recall score: 0.47810799566564377\n",
    "SSIM score: 0.7128161258855013\n",
    "MSE score: 0.12805442984942703\n",
    "Hamming distance: 0.12805442984942703\n",
    "Rand index: 0.871945570150573\n",
    "\n",
    "**thresh = 1400**\n",
    "Dice coefficient: 0.48162972627177847\n",
    "IoU score: 0.31720176205055706\n",
    "Precision score: 0.5629169305311986\n",
    "Recall score: 0.42085654612199963\n",
    "SSIM score: 0.7306963022624658\n",
    "MSE score: 0.12034011585262294\n",
    "Hamming distance: 0.12034011585262294\n",
    "Rand index: 0.8796598841473771\n",
    "\n",
    "thresh = 1600\n",
    "Dice coefficient: 0.4595908083781006\n",
    "IoU score: 0.2983563139442168\n",
    "Precision score: 0.5960952101069142\n",
    "Recall score: 0.37395580758890845\n",
    "SSIM score: 0.7412197757823129\n",
    "MSE score: 0.11682107778963834\n",
    "Hamming distance: 0.11682107778963834\n",
    "Rand index: 0.8831789222103616\n",
    "\n",
    "thresh = 1800\n",
    "Dice coefficient: 0.44163626507058085\n",
    "IoU score: 0.2833974220341975\n",
    "Precision score: 0.6134206037515663\n",
    "Recall score: 0.34501665707670104\n",
    "SSIM score: 0.745937567421992\n",
    "MSE score: 0.11588896169018616\n",
    "Hamming distance: 0.11588896169018616\n",
    "Rand index: 0.8841110383098139\n",
    "\n",
    "i = 2 (original 2000)\n",
    "\n",
    "no mask\n",
    "Dice coefficient: 0.36291282283738036\n",
    "IoU score: 0.22168203862324337\n",
    "Precision score: 0.24685436458457544\n",
    "Recall score: 0.6849343897191634\n",
    "SSIM score: 0.6460981096769284\n",
    "MSE score: 0.18796559629673285\n",
    "Hamming distance: 0.18796559629673285\n",
    "Rand index: 0.8120344037032672\n",
    "\n",
    "\n",
    "**thresh = 1000**\n",
    "Dice coefficient: 0.4165464264858243\n",
    "IoU score: 0.26306197633655803\n",
    "Precision score: 0.5039227428138098\n",
    "Recall score: 0.354993322750563\n",
    "SSIM score: 0.8215916080427953\n",
    "MSE score: 0.07773129792460191\n",
    "Hamming distance: 0.07773129792460191\n",
    "Rand index: 0.9222687020753981\n",
    "\n",
    "\n",
    "thresh = 1200\n",
    "Dice coefficient: 0.3987961797614054\n",
    "IoU score: 0.24906022251557017\n",
    "Precision score: 0.5192037755366908\n",
    "Recall score: 0.3237223281021639\n",
    "SSIM score: 0.8263121923587782\n",
    "MSE score: 0.07629151536745102\n",
    "Hamming distance: 0.07629151536745102\n",
    "Rand index: 0.923708484632549\n",
    "\n",
    "thresh = 1400\n",
    "Dice coefficient: 0.38551205929679194\n",
    "IoU score: 0.23878286704877952\n",
    "Precision score: 0.5272931777739085\n",
    "Recall score: 0.30381959067293557\n",
    "SSIM score: 0.828550361476516\n",
    "MSE score: 0.07570490430071579\n",
    "Hamming distance: 0.07570490430071579\n",
    "Rand index: 0.9242950956992843\n",
    "\n",
    "thresh = 1600\n",
    "Dice coefficient: 0.37332748875599187\n",
    "IoU score: 0.22950377914143721\n",
    "Precision score: 0.533435625279878\n",
    "Recall score: 0.2871429221434867\n",
    "SSIM score: 0.8301766883931667\n",
    "MSE score: 0.0753497187802167\n",
    "Hamming distance: 0.0753497187802167\n",
    "Rand index: 0.9246502812197833\n",
    "\n",
    "thresh = 1800\n",
    "Dice coefficient: 0.3652086988775218\n",
    "IoU score: 0.22339775029801215\n",
    "Precision score: 0.5374605065780946\n",
    "Recall score: 0.2765701656239947\n",
    "SSIM score: 0.8312124879835611\n",
    "MSE score: 0.07514983427623859\n",
    "Hamming distance: 0.07514983427623859\n",
    "Rand index: 0.9248501657237614\n",
    "\n",
    "thresh = 2000\n",
    "Dice coefficient: 0.35917833330468135\n",
    "IoU score: 0.2189015056268004\n",
    "Precision score: 0.5407998576777105\n",
    "Recall score: 0.26887851932163065\n",
    "SSIM score: 0.8319550597966561\n",
    "MSE score: 0.07499218512130308\n",
    "Hamming distance: 0.07499218512130308\n",
    "Rand index: 0.9250078148786969\n",
    "\n",
    "\n",
    "\n",
    "i = 3 (original 1000)\n",
    "\n",
    "no mask\n",
    "Dice coefficient: 0.4322241418857131\n",
    "IoU score: 0.2756925613114047\n",
    "Precision score: 0.3214284478114834\n",
    "Recall score: 0.6595799208240772\n",
    "SSIM score: 0.6697726538931316\n",
    "MSE score: 0.16774223049025985\n",
    "Hamming distance: 0.16774223049025985\n",
    "Rand index: 0.8322577695097402\n",
    "\n",
    "thresh = 750\n",
    "Dice coefficient: 0.4590960968007366\n",
    "IoU score: 0.29793947295970225\n",
    "Precision score: 0.49875884849621777\n",
    "Recall score: 0.4252768471917144\n",
    "SSIM score: 0.7826364595440669\n",
    "MSE score: 0.09700527256928453\n",
    "Hamming distance: 0.09700527256928453\n",
    "Rand index: 0.9029947274307155\n",
    "\n",
    "**thresh = 800**\n",
    "Dice coefficient: 0.45261626874092675\n",
    "IoU score: 0.2925042183121846\n",
    "Precision score: 0.5206103101403131\n",
    "Recall score: 0.4003312164230105\n",
    "SSIM score: 0.7899104427730833\n",
    "MSE score: 0.0937320828052005\n",
    "Hamming distance: 0.0937320828052005\n",
    "Rand index: 0.9062679171947995\n",
    "\n",
    "thresh = 900\n",
    "Dice coefficient: 0.43812354688446187\n",
    "IoU score: 0.28051101353792685\n",
    "Precision score: 0.556280270620867\n",
    "Recall score: 0.3613673141677577\n",
    "SSIM score: 0.7996764566085222\n",
    "MSE score: 0.08972225722701395\n",
    "Hamming distance: 0.08972225722701395\n",
    "Rand index: 0.910277742772986\n",
    "\n",
    "thresh = 1000\n",
    "Dice coefficient: 0.42390931290666267\n",
    "IoU score: 0.26896251362822654\n",
    "Precision score: 0.5792684253114408\n",
    "Recall score: 0.3342609248295756\n",
    "SSIM score: 0.8050663118161301\n",
    "MSE score: 0.08794488657223096\n",
    "Hamming distance: 0.08794488657223096\n",
    "Rand index: 0.912055113427769"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the whole thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold method (batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data_path = \"/media/data/u01/Fig7/7b/M106/*/*.tif\"\n",
    "output_ch1_path = \"/media/data/u01/lightsheet/quant-fig7/7b-M106 run 2/segmentation/ch1/\"\n",
    "output_ch2_path = \"/media/data/u01/lightsheet/quant-fig7/7b-M106 run 2/segmentation/ch2/\"\n",
    "output_csv_ch1_ch2_path = \"/media/data/u01/lightsheet/quant-fig7/7b-M106 run 2/stats_enhanced2_ch1_ch2.csv\"\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# Ch1 settings\n",
    "gamma_ch1 = 2  # You can adjust this value to control the contrast enhancement\n",
    "contrast_alpha_ch1 = 0.0225  # 2\n",
    "\n",
    "# Ch2 settings\n",
    "gamma_ch2 = 2  # You can adjust this value to control the contrast enhancement\n",
    "contrast_alpha_ch2 = 0.125  # Try 0.15 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "# Parameters for vessel detection\n",
    "sigma_minimum = 1.0  # Range of scales in which MultiScaleHessianBasedMeasureImageFilter will search for vessels\n",
    "sigma_maximum = 10.0  # 10\n",
    "number_of_sigma_steps = 10  # 10 Number of scales to search for vessels\n",
    "\n",
    "# Parameters for post-processing\n",
    "thresh1 = 230  # Threshold for binarization, 230 (ch1)\n",
    "thresh2 = 230  # Threshold for binarization, 230 (ch2)\n",
    "min_size1 = 100  # Minimum size of objects to keep (ch1)\n",
    "min_size2 = 100  # Minimum size of objects to keep (ch2)\n",
    "area_threshold = 2000 # Minimum area of holes to keep\n",
    "smoothing = 1  # Smoothing factor for closing, 3\n",
    "\n",
    "# Read all tif files in the folder\n",
    "data_files = sorted(glob.glob(data_path))\n",
    "num_slices = len(data_files) // 2\n",
    "rows_ch1_ch2 = [[\"Index\", \"Dice coefficient\", \"IoU score\", \"Precision\", \"Recall\", \"SSIM\", \"MSE\", \"Hamming distance\", \"Rand index\"]]\n",
    "\n",
    "# Load the image channels\n",
    "for i in tqdm(range(num_slices)):\n",
    "    curr_ch1, curr_ch2 = load_channels(data_path, i)\n",
    "    curr_ch1 = curr_ch1.astype(np.float32)\n",
    "    curr_ch2 = curr_ch2.astype(np.float32)\n",
    "        \n",
    "    # Ch1 settings\n",
    "    gamma_ch1 = 2  # You can adjust this value to control the contrast enhancement\n",
    "    contrast_alpha_ch1 = 0.0225  # 2\n",
    "\n",
    "    # Ch2 settings\n",
    "    gamma_ch2 = 2  # You can adjust this value to control the contrast enhancement\n",
    "    contrast_alpha_ch2 = 0.125  # Try 0.15 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "    THRESH = 1750   # Default 1500\n",
    "    THRESH2 = 400  # Default 400\n",
    "    max_value = 2000\n",
    "\n",
    "\n",
    "    if i == 0:\n",
    "        THRESH = 1400  # 1600\n",
    "        max_value = 4000  # 4000\n",
    "    elif i == 1:\n",
    "        THRESH = 1400  # 1400\n",
    "        max_value = 4000  # 4000\n",
    "    elif i == 2:\n",
    "        THRESH = 1000  # 1400\n",
    "        max_value = 4000  # 4000\n",
    "    elif i == 3:\n",
    "        THRESH = 800  # 800\n",
    "        max_value = 4000\n",
    "    \n",
    "    # Create a threshold mask for the image\n",
    "    curr_ch1_median = ndimage.median_filter(curr_ch1.copy(), size=5)\n",
    "    curr_ch2_median = ndimage.median_filter(curr_ch2.copy(), size=5)  # Repeat for ch2\n",
    "    \n",
    "    cc_ch1_alt = gamma_correction(curr_ch1_median, gamma=gamma_ch1, max_value=max_value)\n",
    "\n",
    "    curr_ch1_thresh = cc_ch1_alt.copy() > THRESH\n",
    "    curr_ch1_thresh[curr_ch1_thresh != 0] = 1\n",
    "    curr_ch1_thresh = curr_ch1_thresh.astype(bool)\n",
    "    \n",
    "    curr_ch2_thresh = curr_ch2_median.copy() > THRESH2\n",
    "    curr_ch2_thresh[curr_ch2_thresh != 0] = 1\n",
    "    curr_ch2_thresh = curr_ch2_thresh.astype(bool)\n",
    "\n",
    "    auto_ch1 = auto_contrast(curr_ch1, alpha=0.0225)\n",
    "    auto_ch2 = auto_contrast(curr_ch2, alpha=0.125)\n",
    "    auto_ch1_median = ndimage.median_filter(auto_ch1.copy(), size=5)\n",
    "    auto_ch2_median = ndimage.median_filter(auto_ch2.copy(), size=5)\n",
    "\n",
    "\n",
    "    bg_alpha = 0.5  #\n",
    "    bg_mask = auto_contrast(curr_ch1, alpha=bg_alpha)  # \n",
    "    bg_mask = get_brain_mask(bg_mask, area_threshold=25000)  # 255 default ch0, 150 for ch1\n",
    "    \n",
    "    input_ch1 = auto_ch1_median * bg_mask\n",
    "    input_ch1 = input_ch1.astype(np.float32)\n",
    "    input_ch1 *= 255.0\n",
    "        \n",
    "    input_ch2 = auto_ch2_median * bg_mask\n",
    "    input_ch2 = input_ch2.astype(np.float32)\n",
    "    input_ch2 *= 255.0\n",
    "\n",
    "\n",
    "    # Run the vessel detection\n",
    "    segmented_vessels_ch1 = detect_vessels(input_ch1, sigma_minimum, sigma_maximum, number_of_sigma_steps)\n",
    "    segmented_vessels_ch2 = detect_vessels(input_ch2, sigma_minimum, sigma_maximum, number_of_sigma_steps)\n",
    "\n",
    "    # Process the thresholded vessels\n",
    "    thresholded_vessels_ch1 = process_vessels(segmented_vessels_ch1, thresh=thresh1, min_size=min_size1, area_threshold=area_threshold, smoothing=smoothing)\n",
    "    thresholded_vessels_ch2 = process_vessels(segmented_vessels_ch2, thresh=thresh2, min_size=min_size2, area_threshold=area_threshold, smoothing=smoothing)\n",
    "\n",
    "    thresholded_vessels_ch1 = thresholded_vessels_ch1 * bg_mask * curr_ch1_thresh\n",
    "    thresholded_vessels_ch2 = thresholded_vessels_ch2 * bg_mask * curr_ch2_thresh\n",
    "    \n",
    "    # Save to file\n",
    "    sitk_ch1 = sitk.GetImageFromArray(thresholded_vessels_ch1.astype(np.uint8))  # Ch1\n",
    "    output_ch1_file = output_ch1_path + f\"ch1_seg_{str(i).zfill(4)}.tif\"\n",
    "    sitk.WriteImage(sitk_ch1, output_ch1_file)\n",
    "    sitk_ch2 = sitk.GetImageFromArray(thresholded_vessels_ch2.astype(np.uint8))  # Ch1\n",
    "    output_ch2_file = output_ch2_path + f\"ch2_seg_{str(i).zfill(4)}.tif\"\n",
    "    sitk.WriteImage(sitk_ch2, output_ch2_file)\n",
    "    \n",
    "    # Compute statistics between ch1 and ch2\n",
    "    thresh_ch1_flat = thresholded_vessels_ch1.flatten()\n",
    "    thresh_ch2_flat = thresholded_vessels_ch2.flatten()\n",
    "    dice_score = dice_coefficient(thresholded_vessels_ch1, thresholded_vessels_ch2)  \n",
    "    iou_score = iou(thresholded_vessels_ch1, thresholded_vessels_ch2)  # Strongly penalizes over-segmentation and under-segmentation\n",
    "    precision_score = precision(thresholded_vessels_ch1, thresholded_vessels_ch2) \n",
    "    recall_score = recall(thresholded_vessels_ch1, thresholded_vessels_ch2)\n",
    "    ssim_score = ssim(thresholded_vessels_ch1, thresholded_vessels_ch2)\n",
    "    mse_score = mean_squared_error(thresholded_vessels_ch1, thresholded_vessels_ch2)\n",
    "    hamming_distance = hamming(thresh_ch1_flat, thresh_ch2_flat)\n",
    "    rand_score = rand_index(thresholded_vessels_ch1, thresholded_vessels_ch2)  # Measures how close points are clustered together\n",
    "    rows_ch1_ch2.append([i, dice_score, iou_score, precision_score, recall_score, ssim_score, mse_score, hamming_distance, rand_score])\n",
    "    print(\"ch1-ch2:\", rows_ch1_ch2[i + 1])\n",
    "\n",
    "with open(output_csv_ch1_ch2_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows_ch1_ch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "i=0 should match:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tissuecyte",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
