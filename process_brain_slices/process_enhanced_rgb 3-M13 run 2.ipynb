{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Standard imports\n",
    "import glob\n",
    "\n",
    "# 3rd party imports\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from pprint import pprint\n",
    "import SimpleITK as sitk\n",
    "sitk.ProcessObject_SetGlobalWarningDisplay(False)\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for IO operations\n",
    "def load_channels(filepath: str, idx: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load the image channels from the given filepath.\n",
    "    \n",
    "    Args:\n",
    "        filepath: str, path to the image\n",
    "        idx: int, index of the image to load\n",
    "        \n",
    "    Returns:\n",
    "        channels: np.ndarray, image channels\n",
    "    \"\"\"\n",
    "    filepaths = sorted(glob.glob(filepath))\n",
    "    print(f\"Found {int(len(filepaths)/2)} slices\")\n",
    "    pprint(filepaths)\n",
    "    \n",
    "    # Load the image\n",
    "    file_idx = idx * 2  # Multiply by 2 because we have 2 channels and they're stored in pairs\n",
    "    curr_img = (read_tif(filepaths[file_idx]), read_tif(filepaths[file_idx + 1]))\n",
    "    print(\"\\nCh1:\", filepaths[file_idx])\n",
    "    print(\"Ch2:\", filepaths[file_idx + 1])\n",
    "    curr_ch1 = curr_img[0]\n",
    "    curr_ch2 = curr_img[1]\n",
    "\n",
    "    # Check image stats\n",
    "    print(f\"\\nChannel shape: {curr_ch1.shape}\")\n",
    "    print(f\"Channel dtype: {curr_ch1.dtype}\")\n",
    "    print(f\"Channel 1 min: {curr_ch1.min()}\")\n",
    "    print(f\"Channel 1 max: {curr_ch1.max()}\")\n",
    "    print(f\"Channel 1 mean: {curr_ch1.mean()}\")\n",
    "    \n",
    "    return curr_ch1, curr_ch2\n",
    "\n",
    "\n",
    "def load_3_channels(filepath: str, idx: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load the image channels from the given filepath.\n",
    "    \n",
    "    Args:\n",
    "        filepath: str, path to the image\n",
    "        idx: int, index of the image to load\n",
    "        \n",
    "    Returns:\n",
    "        channels: np.ndarray, image channels\n",
    "    \"\"\"\n",
    "    filepaths = sorted(glob.glob(filepath))\n",
    "    print(f\"Found {int(len(filepaths)/3)} slices\")\n",
    "    pprint(filepaths)\n",
    "    \n",
    "    # Load the image\n",
    "    file_idx = idx * 3  # Multiply by 2 because we have 2 channels and they're stored in pairs\n",
    "    curr_img = (read_tif(filepaths[file_idx]), read_tif(filepaths[file_idx + 1]), read_tif(filepaths[file_idx + 2]))\n",
    "    print(\"\\nCh1:\", filepaths[file_idx])\n",
    "    print(\"Ch2:\", filepaths[file_idx + 1])\n",
    "    print(\"Ch3:\", filepaths[file_idx + 2])\n",
    "    curr_ch1 = curr_img[0]\n",
    "    curr_ch2 = curr_img[1]\n",
    "    curr_ch3 = curr_img[2]\n",
    "    \n",
    "    # Check image stats\n",
    "    print(f\"\\nChannel shape: {curr_ch1.shape}\")\n",
    "    print(f\"Channel dtype: {curr_ch1.dtype}\")\n",
    "    print(f\"Channel 1 min: {curr_ch1.min()}\")\n",
    "    print(f\"Channel 1 max: {curr_ch1.max()}\")\n",
    "    print(f\"Channel 1 mean: {curr_ch1.mean()}\")\n",
    "\n",
    "    return curr_ch1, curr_ch2, curr_ch3\n",
    "\n",
    "\n",
    "\n",
    "def read_tif(filepath):\n",
    "    \"\"\"\n",
    "    Read tiff files using SimpleITK\n",
    "    \n",
    "    Args:\n",
    "        filepath: str, path to tiff file\n",
    "        \n",
    "    Returns:\n",
    "        image: np.ndarray, tiff image\n",
    "    \"\"\"\n",
    "    image = sitk.ReadImage(filepath)\n",
    "    image = sitk.GetArrayFromImage(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def auto_contrast(data: np.ndarray, alpha: float = None, beta: float = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocess tiff files to automatically adjust brightness and contrast.\n",
    "    https://stackoverflow.com/questions/56905592/automatic-contrast-and-brightness-adjustment-of-a-color-photo-of-a-sheet-of-pape\n",
    "    \"\"\"\n",
    "    if not alpha:\n",
    "        alpha = np.iinfo(data.dtype).max / (np.max(data) - np.min(data))\n",
    "    if not beta:\n",
    "        beta = -np.min(data) * alpha\n",
    "    img = cv2.convertScaleAbs(data.copy(), alpha=alpha, beta=beta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def gamma_correction(image: np.ndarray, gamma: float=2.0, min_value=None, max_value=None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply gamma correction to the image.\n",
    "    \n",
    "    Args:\n",
    "        image: np.ndarray, input image\n",
    "        gamma: float, gamma value\n",
    "        \n",
    "    Returns:\n",
    "        image_enhanced: np.ndarray, gamma corrected image\n",
    "    \"\"\"\n",
    "    if min_value is not None:\n",
    "        image = image.copy()\n",
    "        image[image < min_value] = 0\n",
    "    if max_value is None:\n",
    "        max_value = image.max()\n",
    "    else:\n",
    "        image = image.copy()\n",
    "        image[image > max_value] = max_value\n",
    "    # Normalize the image to the range [0, 1]\n",
    "    image_normalized = image / max_value\n",
    "    # Apply the exponential transformation\n",
    "    image_enhanced = np.power(image_normalized, gamma)\n",
    "    # Rescale the image back to the original intensity range\n",
    "    image_enhanced = image_enhanced * max_value\n",
    "    return image_enhanced\n",
    "\n",
    "\n",
    "def save_figure(image, filename, contours=None):\n",
    "    \"\"\"\n",
    "    Save figure to disk.\n",
    "    \n",
    "    Args:\n",
    "        image: np.ndarray, input image\n",
    "        filename: str, path to save the image\n",
    "        contours: np.ndarray, contours to overlay on the image\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    if contours is not None:\n",
    "        plt.contour(contours, colors='red', linewidths=0.15, alpha=0.35)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(filename, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Saved figure to {filename}\")\n",
    "    \n",
    "    \n",
    "def show(image: np.ndarray, contour: np.ndarray = None,\n",
    "         image2: np.ndarray = None, contour2: np.ndarray = None, contour_alpha: float = 0.75,\n",
    "         title: str = \"\", title2: str = \"\", \n",
    "         xlim: tuple[int, int] = None, ylim: tuple[int, int] = None,\n",
    "         xlim2: tuple[int, int] = None, ylim2: tuple[int, int] = None,\n",
    "         axis: bool = True,\n",
    "         figsize: tuple[int, int] = (10, 10)):\n",
    "    \"\"\"\n",
    "    Display the image.\n",
    "    \n",
    "    Args:\n",
    "        image: np.ndarray, input image\n",
    "        title: str, title of the image\n",
    "    \"\"\"\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    # If there are two images, display them side by side\n",
    "    if image2 is not None:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(title)\n",
    "        if contour is not None:\n",
    "            plt.contour(contour, colors='red', linewidths=0.5, alpha=contour_alpha)\n",
    "        if xlim is not None:\n",
    "            plt.xlim(xlim)\n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim)\n",
    "        plt.axis(axis)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(image2, cmap='gray')\n",
    "        plt.title(title2)\n",
    "        if contour2 is not None:\n",
    "            plt.contour(contour2, colors='red', linewidths=0.5, alpha=contour_alpha)\n",
    "        if xlim2 is not None:\n",
    "            plt.xlim(xlim2)\n",
    "        if ylim2 is not None:\n",
    "            plt.ylim(ylim2)\n",
    "        plt.axis(axis)\n",
    "    # If there is only one image, display it\n",
    "    else:\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(title)\n",
    "        if contour is not None:\n",
    "            plt.contour(contour, colors='red', linewidths=0.5, alpha=contour_alpha)\n",
    "        if xlim is not None:\n",
    "            plt.xlim(xlim)\n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim)\n",
    "        plt.axis(axis)\n",
    "    plt.show()\n",
    "    f.clear()\n",
    "    plt.close(f)\n",
    "    \n",
    "    \n",
    "def show3(image: np.ndarray, contour: np.ndarray = None,\n",
    "          image2: np.ndarray = None, contour2: np.ndarray = None, \n",
    "          image3: np.ndarray = None, contour3: np.ndarray = None, \n",
    "          contour_alpha: float = 0.75,\n",
    "          title: str = \"\", title2: str = \"\", title3: str = \"\",\n",
    "          xlim: tuple[int, int] = None, ylim: tuple[int, int] = None,\n",
    "          xlim2: tuple[int, int] = None, ylim2: tuple[int, int] = None,\n",
    "          xlim3: tuple[int, int] = None, ylim3: tuple[int, int] = None,\n",
    "          axis: bool = True,\n",
    "          figsize: tuple[int, int] = (20, 10)):\n",
    "    \"\"\"\n",
    "    Display the image.\n",
    "    \n",
    "    Args:\n",
    "        image: np.ndarray, input image\n",
    "        title: str, title of the image\n",
    "    \"\"\"\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(title)\n",
    "    if contour is not None:\n",
    "        plt.contour(contour, colors='red', linewidths=0.5, alpha=contour_alpha)\n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    plt.axis(axis)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(image2, cmap='gray')\n",
    "    plt.title(title2)\n",
    "    if contour2 is not None:\n",
    "        plt.contour(contour2, colors='red', linewidths=0.5, alpha=contour_alpha)\n",
    "    if xlim2 is not None:\n",
    "        plt.xlim(xlim2)\n",
    "    if ylim2 is not None:\n",
    "        plt.ylim(ylim2)\n",
    "    plt.axis(axis)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(image3, cmap='gray')\n",
    "    plt.title(title3)\n",
    "    if contour3 is not None:\n",
    "        plt.contour(contour3, colors='red', linewidths=0.5, alpha=contour_alpha)\n",
    "    if xlim3 is not None:\n",
    "        plt.xlim(xlim3)\n",
    "    if ylim3 is not None:\n",
    "        plt.ylim(ylim3)\n",
    "    plt.axis(axis)\n",
    "    \n",
    "    plt.show()\n",
    "    f.clear()\n",
    "    plt.close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for vessel detection\n",
    "import itk\n",
    "import numpy as np\n",
    "from skimage.morphology import remove_small_objects, binary_closing, disk, remove_small_holes\n",
    "\n",
    "# Parameters for vessel detection\n",
    "#ALPHA = 0.5  # Default 0.5\n",
    "#BETA = 0.5  # Default 0.5\n",
    "#GAMMA = 5.0  # Default 5\n",
    "\n",
    "def detect_vessels(input_image: np.ndarray, min_sigma: float=1.0, max_sigma: float=10.0, num_steps: int=10,\n",
    "                   alpha=0.5, beta=0.5, gamma=5.0):\n",
    "    \"\"\"\n",
    "    Use the Hessian-based vesselness filter to detect vessels in the image.\n",
    "    \n",
    "    Args:\n",
    "        input_image: np.ndarray, input image\n",
    "        min_sigma: float, minimum sigma value\n",
    "        max_sigma: float, maximum sigma value\n",
    "        num_steps: int, number of steps\n",
    "        \n",
    "    Returns:\n",
    "        segmented_vessels_array: np.ndarray, segmented vessels\n",
    "    \"\"\"\n",
    "    # Run ITK\n",
    "    input_image = itk.image_from_array(input_image)\n",
    "    #input_image = itk.imread(input_image, itk.F)\n",
    "\n",
    "    ImageType = type(input_image)\n",
    "    Dimension = input_image.GetImageDimension()\n",
    "    HessianPixelType = itk.SymmetricSecondRankTensor[itk.D, Dimension]\n",
    "    HessianImageType = itk.Image[HessianPixelType, Dimension]\n",
    "\n",
    "    objectness_filter = itk.HessianToObjectnessMeasureImageFilter[\n",
    "        HessianImageType, ImageType\n",
    "    ].New()\n",
    "    objectness_filter.SetBrightObject(False)  # Set to True if the structures are bright on a dark background\n",
    "    objectness_filter.SetScaleObjectnessMeasure(False)  # Set to True to scale the objectness measure by the scale\n",
    "    objectness_filter.SetAlpha(alpha)  # Sensitivity to blob-like structures\n",
    "                                     # Set/Get Alpha, the weight corresponding to R_A \n",
    "                                     # (the ratio of the smallest eigenvalue that has to be large to the larger ones). \n",
    "                                     # Smaller values lead to increased sensitivity to the object dimensionality.\n",
    "    objectness_filter.SetBeta(beta)   # Sensitivity to plate-like structures - 1.0 default\n",
    "                                     # Set/Get Beta, the weight corresponding to R_B \n",
    "                                     # (the ratio of the largest eigenvalue that has to be small to the larger ones). \n",
    "                                     # Smaller values lead to increased sensitivity to the object dimensionality.\n",
    "    objectness_filter.SetGamma(gamma)  # Sensitivity to noise - 5.0 default\n",
    "                                     # Set/Get Gamma, the weight corresponding to S \n",
    "                                     # (the Frobenius norm of the Hessian matrix, or second-order structureness)\n",
    "\n",
    "    multi_scale_filter = itk.MultiScaleHessianBasedMeasureImageFilter[\n",
    "        ImageType, HessianImageType, ImageType\n",
    "    ].New()\n",
    "    multi_scale_filter.SetInput(input_image)\n",
    "    multi_scale_filter.SetHessianToMeasureFilter(objectness_filter)\n",
    "    multi_scale_filter.SetSigmaStepMethodToLogarithmic()\n",
    "    multi_scale_filter.SetSigmaMinimum(min_sigma)\n",
    "    multi_scale_filter.SetSigmaMaximum(max_sigma)\n",
    "    multi_scale_filter.SetNumberOfSigmaSteps(num_steps)\n",
    "\n",
    "    OutputPixelType = itk.UC\n",
    "    OutputImageType = itk.Image[OutputPixelType, Dimension]\n",
    "\n",
    "    rescale_filter = itk.RescaleIntensityImageFilter[ImageType, OutputImageType].New()\n",
    "    rescale_filter.SetInput(multi_scale_filter)\n",
    "    rescale_filter.Update()\n",
    "\n",
    "    # Get numpy array\n",
    "    segmented_vessels = rescale_filter.GetOutput()\n",
    "    segmented_vessels_array = itk.array_view_from_image(segmented_vessels)\n",
    "    segmented_vessels_array = np.asarray(segmented_vessels_array, dtype=np.float32)\n",
    "    return segmented_vessels_array\n",
    "\n",
    "\n",
    "def process_vessels(vessel_image: np.ndarray, thresh: int, min_size: int=10, area_threshold: float=2000, smoothing: int=3):\n",
    "    \"\"\"\n",
    "    Process the thresholded vessels.\n",
    "    \n",
    "    Args:\n",
    "        vessel_image: np.ndarray, input image\n",
    "        thresh: int, threshold value\n",
    "        min_size: int, minimum size\n",
    "        area_threshold: float, area threshold\n",
    "        smoothing: int, smoothing factor\n",
    "        \n",
    "    Returns:\n",
    "        thresholded_vessels: np.ndarray, thresholded vessels\n",
    "    \"\"\"\n",
    "    # Process the thresholded vessels\n",
    "    thresholded_vessels = vessel_image > thresh\n",
    "    thresholded_vessels = np.invert(thresholded_vessels)\n",
    "\n",
    "    # Get rid of small objects\n",
    "    thresholded_vessels = remove_small_objects(thresholded_vessels, min_size=min_size)\n",
    "    thresholded_vessels = remove_small_holes(thresholded_vessels, area_threshold=area_threshold)\n",
    "\n",
    "    # Smoothen edges\n",
    "    thresholded_vessels = binary_closing(thresholded_vessels, footprint=disk(smoothing))\n",
    "    \n",
    "    return thresholded_vessels\n",
    "\n",
    "\n",
    "def get_brain_mask(brain_image, area_threshold=300000, min_size=10000):\n",
    "    \"\"\"\n",
    "    Get the mask of the brain from the image (run before contrast enhancement).\n",
    "    \n",
    "    Args:\n",
    "        brain_image: np.ndarray, input image\n",
    "        thresh: int, threshold value\n",
    "        area_threshold: int, area threshold\n",
    "        \n",
    "    Returns:\n",
    "        mask: np.ndarray, mask of the brain\n",
    "    \"\"\"\n",
    "    _, mask = cv2.threshold(brain_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_TRIANGLE)\n",
    "    mask = remove_small_holes(mask.astype(bool), area_threshold=area_threshold)\n",
    "    mask = remove_small_objects(mask, min_size=min_size)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for evaluation\n",
    "import csv\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error\n",
    "from scipy.spatial.distance import hamming\n",
    "\n",
    "def dice_coefficient(binary_image1, binary_image2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the Dice coefficient between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - dice: Dice coefficient.\n",
    "    \"\"\"\n",
    "    intersection = np.sum(binary_image1 * binary_image2)\n",
    "    size1 = np.sum(binary_image1)\n",
    "    size2 = np.sum(binary_image2)\n",
    "    \n",
    "    dice = (2. * intersection + epsilon) / (size1 + size2 + epsilon)\n",
    "    return dice\n",
    "\n",
    "\n",
    "def iou(binary_image1, binary_image2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the Intersection over Union (IoU) between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - iou: IoU.\n",
    "    \"\"\"\n",
    "    intersection = np.sum(binary_image1 * binary_image2)\n",
    "    union = np.sum(binary_image1 + binary_image2)\n",
    "    \n",
    "    if union == 0:\n",
    "        iou = 1.0\n",
    "    \n",
    "    iou = (intersection + epsilon) / (union + epsilon)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def precision(binary_image1, binary_image2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the precision between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - precision: Precision.\n",
    "    \"\"\"\n",
    "    true_positives = np.sum(binary_image1 * binary_image2)\n",
    "    false_positives = np.sum(binary_image1 * (1 - binary_image2))\n",
    "    \n",
    "    precision = (true_positives) / (true_positives + false_positives + epsilon)\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(binary_image1, binary_image2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the recall between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - recall: Recall.\n",
    "    \"\"\"\n",
    "    true_positives = np.sum(binary_image1 * binary_image2)\n",
    "    false_negatives = np.sum((1 - binary_image1) * binary_image2)\n",
    "    \n",
    "    recall = true_positives / (true_positives + false_negatives + epsilon)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def rand_index(binary_image1, binary_image2):\n",
    "    \"\"\"\n",
    "    Compute the Rand index between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - rand_index: Rand index.\n",
    "    \"\"\"\n",
    "    true_positives = np.sum(binary_image1 * binary_image2)\n",
    "    false_positives = np.sum(binary_image1 * (1 - binary_image2))\n",
    "    false_negatives = np.sum((1 - binary_image1) * binary_image2)\n",
    "    true_negatives = np.sum((1 - binary_image1) * (1 - binary_image2))\n",
    "    \n",
    "    rand_index = (true_positives + true_negatives) / (true_positives + false_positives + false_negatives + true_negatives)\n",
    "    return rand_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IO parameters\n",
    "filepath = \"/media/data/u01/Fig3/M13/*/*.tif\"\n",
    "IDX = 4\n",
    "\n",
    "# Load the image channels\n",
    "curr_ch1, curr_ch2, curr_ch3 = load_3_channels(filepath, IDX)\n",
    "curr_ch1 = curr_ch1.astype(np.float32)\n",
    "curr_ch2 = curr_ch2.astype(np.float32)\n",
    "curr_ch3 = curr_ch3.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ch1 settings\n",
    "gamma_ch1 = 2  # You can adjust this value to control the contrast enhancement\n",
    "contrast_alpha_ch1 = 0.00525  # Try 0.0225 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "# Ch2 settings\n",
    "gamma_ch2 = 2  # You can adjust this value to control the contrast enhancement\n",
    "contrast_alpha_ch2 = 0.0125  # Try 0.125 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "# Ch3 settings\n",
    "gamma_ch3 = 2  # You can adjust this value to control the contrast enhancement\n",
    "contrast_alpha_ch3 = 0.0425  # Try 0.125 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "\n",
    "# No change\n",
    "contrast_ch1 = curr_ch1\n",
    "contrast_ch2 = curr_ch2\n",
    "contrast_ch3 = curr_ch3\n",
    "\n",
    "\n",
    "cc_ch1 = auto_contrast(contrast_ch1, alpha=contrast_alpha_ch1)\n",
    "cc_ch2 = auto_contrast(contrast_ch2, alpha=contrast_alpha_ch2)\n",
    "cc_ch3 = auto_contrast(contrast_ch3, alpha=contrast_alpha_ch3)\n",
    "\n",
    "\n",
    "bg_alpha = 0.25  # 0.5\n",
    "bg_mask = auto_contrast(curr_ch1, alpha=bg_alpha)  # 7\n",
    "bg_mask = get_brain_mask(bg_mask, area_threshold=25000)  # 255 default ch0, 150 for ch1\n",
    "\n",
    "show(cc_ch1, bg_mask, title=f\"Section {IDX} ch1 contrast\", axis=True)\n",
    "show(cc_ch2, bg_mask, title=f\"Section {IDX} ch2 contrast\", axis=True)\n",
    "show(cc_ch3, bg_mask, title=f\"Section {IDX} ch3 contrast\", axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup FOVs\n",
    "fovs = [ \n",
    "    # xlim,             ylim\n",
    "    ( (4000, 5000),     (4000, 5000) ),\n",
    "    ( (2000, 3000),     (2000, 4000) ),\n",
    "    ( (2000, 4000),     (4000, 6000) ),\n",
    "    ( (5000, 6000),     (2000, 4000) ),\n",
    "    ( (5000, 6000),     (1000, 2000) ),\n",
    "    ( (5000, 6000),     (4000, 5000) ),\n",
    "]\n",
    "\n",
    "fov1_xlim, fov1_ylim = fovs[0][0], fovs[0][1][::-1]\n",
    "fov2_xlim, fov2_ylim = fovs[1][0], fovs[1][1][::-1]\n",
    "fov3_xlim, fov3_ylim = fovs[2][0], fovs[2][1][::-1]\n",
    "fov4_xlim, fov4_ylim = fovs[3][0], fovs[3][1][::-1]\n",
    "fov5_xlim, fov5_ylim = fovs[4][0], fovs[4][1][::-1]\n",
    "fov6_xlim, fov6_ylim = fovs[5][0], fovs[5][1][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold for CH1 and CH2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a threshold mask for the image\n",
    "curr_ch1_median = ndimage.median_filter(curr_ch1.copy(), size=5)\n",
    "curr_ch2_median = ndimage.median_filter(curr_ch2.copy(), size=5)  # Repeat for ch2\n",
    "curr_ch3_median = ndimage.median_filter(curr_ch3.copy(), size=5)  # Repeat for ch2\n",
    "\n",
    "# Create auto contrast brightened images\n",
    "auto_ch1 = auto_contrast(curr_ch1, alpha=contrast_alpha_ch1)\n",
    "auto_ch2 = auto_contrast(curr_ch2, alpha=contrast_alpha_ch2)\n",
    "auto_ch3 = auto_contrast(curr_ch3, alpha=contrast_alpha_ch3)\n",
    "auto_ch1_median = ndimage.median_filter(auto_ch1.copy(), size=5) # 5\n",
    "auto_ch2_median = ndimage.median_filter(auto_ch2.copy(), size=5)\n",
    "auto_ch3_median = ndimage.median_filter(auto_ch3.copy(), size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run thresholding for CH1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ch1 settings\n",
    "gamma_ch1 = 2  # You can adjust this value to control the contrast enhancement\n",
    "contrast_alpha_ch1 = 0.00525  # Try 0.0225 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "# Ch2 settings\n",
    "gamma_ch2 = 2  # You can adjust this value to control the contrast enhancement\n",
    "contrast_alpha_ch2 = 0.0125  # Try 0.125 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "# Ch3 settings\n",
    "gamma_ch3 = 2  # You can adjust this value to control the contrast enhancement\n",
    "contrast_alpha_ch3 = 0.0425  # Try 0.125 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "\n",
    "THRESH = 4000   # 4000 for all of channel 1\n",
    "THRESH2 = 3000  # 3000 for all of channel 2\n",
    "THRESH3 = None\n",
    "max_value = 20000\n",
    "max_value3 = 2000\n",
    "\n",
    "beta1 = 0.5  # Use beta=0.5 for all of ch1\n",
    "beta2 = 1.0  # Use beta=1.0 for all of ch2\n",
    "beta3 = None # Swap between 0.5 and 1.0\n",
    "\n",
    "# Index by index basis\n",
    "if IDX == 0:\n",
    "    THRESH = 7500\n",
    "    \n",
    "    THRESH3 = 400\n",
    "    beta3 = 1.0\n",
    "elif IDX == 1:\n",
    "    THRESH = 5000\n",
    "    \n",
    "    THRESH3 = 750\n",
    "    beta3 = 0.5\n",
    "elif IDX == 2:\n",
    "    THRESH = 5000  # 5000\n",
    "    \n",
    "    THRESH3 = 750\n",
    "    beta3 = 0.5\n",
    "elif IDX == 3:\n",
    "    THRESH = 5500  # 5000\n",
    "    \n",
    "    THRESH3 = 750\n",
    "    beta3 = 0.5\n",
    "elif IDX == 4:\n",
    "    THRESH = 7000\n",
    "    \n",
    "    THRESH2 = 4000 # Specific to this index\n",
    "    \n",
    "    THRESH3 = 1000\n",
    "    beta3 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create contrast enhanced images\n",
    "cc_ch1 = gamma_correction(curr_ch1, gamma=gamma_ch1)\n",
    "cc_ch1 = auto_contrast(cc_ch1, alpha=contrast_alpha_ch1)\n",
    "cc_ch1_alt = gamma_correction(curr_ch1_median, gamma=gamma_ch1, max_value=max_value)\n",
    "\n",
    "cc_ch2 = gamma_correction(curr_ch2, gamma=gamma_ch2)\n",
    "cc_ch2 = auto_contrast(cc_ch2, alpha=contrast_alpha_ch2)\n",
    "\n",
    "cc_ch3 = gamma_correction(curr_ch3, gamma=gamma_ch3)\n",
    "cc_ch3 = auto_contrast(cc_ch3, alpha=contrast_alpha_ch3)\n",
    "cc_ch3_alt = gamma_correction(curr_ch3_median, gamma=gamma_ch3, max_value=max_value3)\n",
    "\n",
    "\n",
    "print(f\"Threshold for ch1: {THRESH}\")\n",
    "print(f\"Threshold for ch2: {THRESH2}\")\n",
    "print(f\"Threshold for ch3: {THRESH3}\")\n",
    "\n",
    "\n",
    "curr_ch1_thresh = cc_ch1_alt.copy() > THRESH\n",
    "curr_ch1_thresh[curr_ch1_thresh != 0] = 1\n",
    "curr_ch1_thresh = curr_ch1_thresh.astype(bool)\n",
    "\n",
    "curr_ch2_thresh = curr_ch2_median.copy() > THRESH2\n",
    "curr_ch2_thresh[curr_ch2_thresh != 0] = 1\n",
    "curr_ch2_thresh = curr_ch2_thresh.astype(bool)\n",
    "\n",
    "curr_ch3_thresh = cc_ch3_alt.copy() > THRESH3\n",
    "curr_ch3_thresh[curr_ch3_thresh != 0] = 1\n",
    "curr_ch3_thresh = curr_ch3_thresh.astype(bool)\n",
    "\n",
    "##########################################\n",
    "# FOV 1\n",
    "##########################################\n",
    "\n",
    "show3(image=cc_ch1_alt, title=f\"Section {IDX} ch1 contrast alt FOV1\", \n",
    "     xlim=fov1_xlim, ylim=fov1_ylim,\n",
    "     contour=curr_ch1_thresh, \n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 contrast FOV1\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov1_xlim, ylim2=fov1_ylim,\n",
    "     image3=cc_ch3_alt, title3=f\"Section {IDX} ch3 contrast alt FOV1\", \n",
    "     contour3=curr_ch3_thresh, \n",
    "     xlim3=fov1_xlim, ylim3=fov1_ylim\n",
    "     )\n",
    "\n",
    "show3(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV1\", \n",
    "     xlim=fov1_xlim, ylim=fov1_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV1\", \n",
    "     xlim2=fov1_xlim, ylim2=fov1_ylim,\n",
    "     image3=auto_ch3, title3=f\"Section {IDX} ch3 brightened FOV1\", \n",
    "     xlim3=fov1_xlim, ylim3=fov1_ylim\n",
    "     )\n",
    "\n",
    "show3(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV1\", \n",
    "     contour=curr_ch1_thresh, \n",
    "     xlim=fov1_xlim, ylim=fov1_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV1\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov1_xlim, ylim2=fov1_ylim,\n",
    "     image3=auto_ch3, title3=f\"Section {IDX} ch3 brightened FOV1\", \n",
    "     contour3=curr_ch3_thresh, \n",
    "     xlim3=fov1_xlim, ylim3=fov1_ylim\n",
    "     )\n",
    "print(\"##########################################\")\n",
    "\n",
    "##########################################\n",
    "# FOV 2\n",
    "##########################################\n",
    "\n",
    "\"\"\"\n",
    "show(image=cc_ch1, title=f\"Section {IDX} ch1 contrast FOV2\", \n",
    "     contour=curr_ch1_thresh, \n",
    "     xlim=fov2_xlim, ylim=fov2_ylim,\n",
    "     image2=cc_ch2, title2=f\"Section {IDX} ch2 contrast FOV2\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov2_xlim, ylim2=fov2_ylim)\n",
    "\"\"\"\n",
    "\n",
    "show3(image=cc_ch1_alt, title=f\"Section {IDX} ch1 contrast alt FOV2\", \n",
    "     contour=curr_ch1_thresh, \n",
    "     xlim=fov2_xlim, ylim=fov2_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 contrast FOV2\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov2_xlim, ylim2=fov2_ylim,\n",
    "     image3=cc_ch3_alt, title3=f\"Section {IDX} ch3 contrast alt FOV2\", \n",
    "     contour3=curr_ch3_thresh, \n",
    "     xlim3=fov2_xlim, ylim3=fov2_ylim\n",
    "     )\n",
    "\n",
    "show3(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV2\", \n",
    "     xlim=fov2_xlim, ylim=fov2_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV2\", \n",
    "     xlim2=fov2_xlim, ylim2=fov2_ylim,\n",
    "     image3=auto_ch3, title3=f\"Section {IDX} ch3 brightened FOV2\", \n",
    "     xlim3=fov2_xlim, ylim3=fov2_ylim\n",
    "     )\n",
    "\n",
    "show3(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV2\", \n",
    "     contour=curr_ch1_thresh, \n",
    "     xlim=fov2_xlim, ylim=fov2_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV2\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov2_xlim, ylim2=fov2_ylim,\n",
    "     image3=auto_ch3, title3=f\"Section {IDX} ch3 brightened FOV2\", \n",
    "     contour3=curr_ch3_thresh, \n",
    "     xlim3=fov2_xlim, ylim3=fov2_ylim\n",
    "     )\n",
    "print(\"##########################################\")\n",
    "\n",
    "##########################################\n",
    "# FOV 3\n",
    "##########################################\n",
    "\n",
    "show3(image=cc_ch1_alt, title=f\"Section {IDX} ch1 contrast alt FOV3\", \n",
    "     contour=curr_ch1_thresh, \n",
    "     xlim=fov3_xlim, ylim=fov3_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 contrast FOV3\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov3_xlim, ylim2=fov3_ylim,\n",
    "     image3=cc_ch3_alt, title3=f\"Section {IDX} ch3 contrast alt FOV3\", \n",
    "     contour3=curr_ch3_thresh, \n",
    "     xlim3=fov3_xlim, ylim3=fov3_ylim\n",
    "     )\n",
    "\n",
    "show3(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV3\",\n",
    "     xlim=fov3_xlim, ylim=fov3_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV3\", \n",
    "     xlim2=fov3_xlim, ylim2=fov3_ylim,\n",
    "     image3=auto_ch3, title3=f\"Section {IDX} ch3 brightened FOV3\", \n",
    "     xlim3=fov3_xlim, ylim3=fov3_ylim\n",
    "     )\n",
    "\n",
    "show3(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV3\", \n",
    "     contour=curr_ch1_thresh,\n",
    "     xlim=fov3_xlim, ylim=fov3_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV3\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov3_xlim, ylim2=fov3_ylim,\n",
    "     image3=auto_ch3, title3=f\"Section {IDX} ch3 brightened FOV3\", \n",
    "     contour3=curr_ch3_thresh, \n",
    "     xlim3=fov3_xlim, ylim3=fov3_ylim\n",
    "     )\n",
    "print(\"##########################################\")\n",
    "\n",
    "##########################################\n",
    "# FOV 4\n",
    "##########################################\n",
    "\n",
    "show3(image=cc_ch1_alt, title=f\"Section {IDX} ch1 contrast alt FOV4\", \n",
    "     contour=curr_ch1_thresh, \n",
    "     xlim=fov4_xlim, ylim=fov4_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 contrast FOV4\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov4_xlim, ylim2=fov4_ylim,\n",
    "     image3=cc_ch3_alt, title3=f\"Section {IDX} ch3 contrast alt FOV4\", \n",
    "     contour3=curr_ch3_thresh, \n",
    "     xlim3=fov4_xlim, ylim3=fov4_ylim\n",
    "     )\n",
    "\n",
    "show3(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV4\",\n",
    "     xlim=fov4_xlim, ylim=fov4_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV4\", \n",
    "     xlim2=fov4_xlim, ylim2=fov4_ylim,\n",
    "     image3=auto_ch3, title3=f\"Section {IDX} ch3 brightened FOV4\", \n",
    "     xlim3=fov4_xlim, ylim3=fov4_ylim\n",
    "     )\n",
    "\n",
    "show3(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV4\", \n",
    "     contour=curr_ch1_thresh,\n",
    "     xlim=fov4_xlim, ylim=fov4_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV4\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov4_xlim, ylim2=fov4_ylim,\n",
    "     image3=auto_ch3, title3=f\"Section {IDX} ch3 brightened FOV4\", \n",
    "     contour3=curr_ch3_thresh, \n",
    "     xlim3=fov4_xlim, ylim3=fov4_ylim\n",
    "     )\n",
    "\n",
    "print(\"##########################################\")\n",
    "\n",
    "##########################################\n",
    "# FOV 5\n",
    "##########################################\n",
    "\n",
    "show3(image=cc_ch1_alt, title=f\"Section {IDX} ch1 contrast alt FOV5\", \n",
    "     contour=curr_ch1_thresh, \n",
    "     xlim=fov5_xlim, ylim=fov5_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV5\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov5_xlim, ylim2=fov5_ylim,\n",
    "     image3=cc_ch3_alt, title3=f\"Section {IDX} ch3 contrast alt FOV5\", \n",
    "     contour3=curr_ch3_thresh, \n",
    "     xlim3=fov5_xlim, ylim3=fov5_ylim\n",
    "     )\n",
    "\n",
    "show3(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV5\",\n",
    "     xlim=fov5_xlim, ylim=fov5_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV5\", \n",
    "     xlim2=fov5_xlim, ylim2=fov5_ylim,\n",
    "     image3=auto_ch3, title3=f\"Section {IDX} ch3 brightened FOV5\", \n",
    "     xlim3=fov5_xlim, ylim3=fov5_ylim\n",
    "     )\n",
    "\n",
    "show3(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV5\", \n",
    "     contour=curr_ch1_thresh,\n",
    "     xlim=fov5_xlim, ylim=fov5_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV5\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov5_xlim, ylim2=fov5_ylim,\n",
    "     image3=auto_ch3, title3=f\"Section {IDX} ch3 brightened FOV5\", \n",
    "     contour3=curr_ch3_thresh, \n",
    "     xlim3=fov5_xlim, ylim3=fov5_ylim\n",
    "     )\n",
    "\n",
    "print(\"##########################################\")\n",
    "\n",
    "##########################################\n",
    "# FOV 6\n",
    "##########################################\n",
    "\n",
    "show3(image=cc_ch1_alt, title=f\"Section {IDX} ch1 contrast alt FOV6\", \n",
    "     contour=curr_ch1_thresh, \n",
    "     xlim=fov6_xlim, ylim=fov6_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 contrast FOV6\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov6_xlim, ylim2=fov6_ylim,\n",
    "     image3=cc_ch3_alt, title3=f\"Section {IDX} ch3 contrast alt FOV6\", \n",
    "     contour3=curr_ch3_thresh, \n",
    "     xlim3=fov6_xlim, ylim3=fov6_ylim\n",
    "     )\n",
    "\n",
    "show3(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV6\",\n",
    "     xlim=fov6_xlim, ylim=fov6_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV6\", \n",
    "     xlim2=fov6_xlim, ylim2=fov6_ylim,\n",
    "     image3=auto_ch3, title3=f\"Section {IDX} ch3 brightened FOV6\", \n",
    "     xlim3=fov6_xlim, ylim3=fov6_ylim\n",
    "     )\n",
    "\n",
    "show3(image=auto_ch1, title=f\"Section {IDX} ch1 brightened FOV6\", \n",
    "     contour=curr_ch1_thresh,\n",
    "     xlim=fov6_xlim, ylim=fov6_ylim,\n",
    "     image2=auto_ch2, title2=f\"Section {IDX} ch2 brightened FOV6\", \n",
    "     contour2=curr_ch2_thresh, \n",
    "     xlim2=fov6_xlim, ylim2=fov6_ylim,\n",
    "     image3=auto_ch3, title3=f\"Section {IDX} ch3 brightened FOV6\", \n",
    "     contour3=curr_ch3_thresh, \n",
    "     xlim3=fov6_xlim, ylim3=fov6_ylim\n",
    "     )     \n",
    "\n",
    "print(\"##########################################\")\n",
    "\n",
    "##########################################################\n",
    "# FULL SECTION\n",
    "##########################################################\n",
    "\n",
    "show3(image=cc_ch1, title=f\"Full section {IDX} ch1 contrast\", \n",
    "      image2=cc_ch2, title2=f\"Full section {IDX} ch2 contrast\",\n",
    "      image3=cc_ch3, title3=f\"Full section {IDX} ch3 contrast\",\n",
    "      figsize=(20, 10), axis=True)\n",
    "\n",
    "show3(image=auto_ch1, title=f\"Full section {IDX} ch1 brightened\", \n",
    "      image2=auto_ch2, title2=f\"Full section {IDX} ch2 brightened\",\n",
    "      image3=auto_ch3, title3=f\"Full section {IDX} ch3 brightened\",\n",
    "      figsize=(20, 10), axis=True)\n",
    "\n",
    "show3(image=curr_ch1_thresh, title=f\"Full section {IDX} ch1 thresholded\", \n",
    "      image2=curr_ch2_thresh, title2=f\"Full section {IDX} ch2 thresholded\",\n",
    "      image3=curr_ch3_thresh, title3=f\"Full section {IDX} ch3 thresholded\",\n",
    "      figsize=(20, 10), axis=True)\n",
    "\n",
    "#thresholded_vessels_ch1 = curr_ch1_thresh\n",
    "#thresholded_vessels_ch2 = curr_ch2_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hessian Filter\n",
    "https://examples.itk.org/src/nonunit/review/segmentbloodvesselswithmultiscalehessianbasedmeasure/documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANNEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for vessel detection\n",
    "sigma_minimum = 1.0  # Range of scales in which MultiScaleHessianBasedMeasureImageFilter will search for vessels\n",
    "sigma_maximum = 10.0  # 10\n",
    "number_of_sigma_steps = 10  # 10 Number of scales to search for vessels\n",
    "\n",
    "# Parameters for post-processing\n",
    "thresh = 230  # Threshold for binarization, 230 and 25 and 15\n",
    "min_size = 100  # Minimum size of objects to keep 100\n",
    "area_threshold = 2000 # Minimum area of holes to keep\n",
    "smoothing = 1  # Smoothing factor for closing, 3\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# Alternative: load image in memory\n",
    "input_image = auto_ch1_median * bg_mask\n",
    "#input_image = cc_ch1_alt * bg_mask\n",
    "input_image = input_image.astype(np.float32)\n",
    "input_image *= 255.0\n",
    "\n",
    "show(input_image, title=\"CH1: Input image\", axis=False)\n",
    "\n",
    "# Print statistics\n",
    "print(\"Input image type:\", input_image.dtype)\n",
    "print(\"Input image min:\", input_image.min())\n",
    "print(\"Input image max:\", input_image.max())\n",
    "\n",
    "# Run the vessel detection\n",
    "segmented_vessels_array = detect_vessels(input_image, sigma_minimum, sigma_maximum, number_of_sigma_steps,\n",
    "                                         beta=beta1)\n",
    "\n",
    "# Process the thresholded vessels\n",
    "thresholded_vessels_ch1 = process_vessels(segmented_vessels_array, thresh=thresh, min_size=min_size, area_threshold=area_threshold, smoothing=smoothing)\n",
    "thresholded_vessels_ch1 = thresholded_vessels_ch1 * bg_mask * curr_ch1_thresh\n",
    "\n",
    "# Print statistics\n",
    "print(\"Vesselness image statistics:\")\n",
    "print(\"Shape:\", segmented_vessels_array.shape)\n",
    "print(\"Min:\", segmented_vessels_array.min())\n",
    "print(\"Max:\", segmented_vessels_array.max())\n",
    "print(\"Mean:\", segmented_vessels_array.mean())\n",
    "print(\"Median:\", np.median(segmented_vessels_array))\n",
    "#print(\"Std:\", segmented_vessels_array.std())\n",
    "\n",
    "print(\"CHANNEL 1\")\n",
    "\n",
    "# Plot the raw vesselness image\n",
    "show(image=segmented_vessels_array, title=f\"CH1: Vesselness image\",\n",
    "     image2=thresholded_vessels_ch1, title2=f\"CH1: Vessel mask\",\n",
    "     axis=False)\n",
    "\n",
    "# Show the results\n",
    "show(image=input_image, title=\"CH1: Input image\",\n",
    "     image2=input_image, title2=\"Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch1, contour_alpha=0.45,\n",
    "     axis=False)\n",
    "\n",
    "# Plot the raw vesselness image FOV1\n",
    "show(image=segmented_vessels_array, title=f\"CH1 FOV1: Vesselness image\",\n",
    "     image2=thresholded_vessels_ch1, title2=f\"CH1 FOV1: Vessel mask\",\n",
    "     xlim=fov1_xlim, ylim=fov1_ylim, xlim2=fov1_xlim, ylim2=fov1_ylim,\n",
    "     axis=False)\n",
    "\n",
    "\n",
    "# FOV1\n",
    "show(image=input_image, title=\"CH1 FOV1: Input image\",\n",
    "     image2=input_image, title2=\"CH1 FOV1: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch1, contour_alpha=0.45,\n",
    "     xlim=fov1_xlim, ylim=fov1_ylim, xlim2=fov1_xlim, ylim2=fov1_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV2\n",
    "show(image=input_image, title=\"CH1 FOV2: Input image\",\n",
    "     image2=input_image, title2=\"CH1 FOV2: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch1, contour_alpha=0.45,\n",
    "     xlim=fov2_xlim, ylim=fov2_ylim, xlim2=fov2_xlim, ylim2=fov2_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV3\n",
    "show(image=input_image, title=\"CH1 FOV3: Input image\",\n",
    "     image2=input_image, title2=\"CH1 FOV3: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch1, contour_alpha=0.45,\n",
    "     xlim=fov3_xlim, ylim=fov3_ylim, xlim2=fov3_xlim, ylim2=fov3_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV4\n",
    "show(image=input_image, title=\"CH1 FOV4: Input image\",\n",
    "     image2=input_image, title2=\"CH1 FOV4: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch1, contour_alpha=0.45,\n",
    "     xlim=fov4_xlim, ylim=fov4_ylim, xlim2=fov4_xlim, ylim2=fov4_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV5\n",
    "show(image=input_image, title=\"CH1 FOV5: Input image\",\n",
    "     image2=input_image, title2=\"CH1 FOV5: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch1, contour_alpha=0.45,\n",
    "     xlim=fov5_xlim, ylim=fov5_ylim, xlim2=fov5_xlim, ylim2=fov5_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV6\n",
    "show(image=input_image, title=\"CH1 FOV6: Input image\",\n",
    "     image2=input_image, title2=\"CH1 FOV6: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch1, contour_alpha=0.45,\n",
    "     xlim=fov6_xlim, ylim=fov6_ylim, xlim2=fov6_xlim, ylim2=fov6_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# Full section\n",
    "show(image=thresholded_vessels_ch1, title=\"CH1: Vessel segmentation\",\n",
    "     image2=curr_ch2_thresh, title2=\"CH2: Thresholded vessels\",\n",
    "     figsize=(20, 10), axis=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANNEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for vessel detection\n",
    "sigma_minimum = 1.0  # Range of scales in which MultiScaleHessianBasedMeasureImageFilter will search for vessels\n",
    "sigma_maximum = 10.0  # 10\n",
    "number_of_sigma_steps = 10  # 10 Number of scales to search for vessels\n",
    "\n",
    "# Parameters for post-processing\n",
    "thresh = 230  # Threshold for binarization, 230\n",
    "min_size = 100  # Minimum size of objects to keep\n",
    "area_threshold = 2000 # Minimum area of holes to keep\n",
    "smoothing = 1  # Smoothing factor for closing, 3\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# Alternative: load image in memory\n",
    "input_image = auto_ch2_median * bg_mask\n",
    "input_image = input_image.astype(np.float32)\n",
    "input_image *= 255.0\n",
    "\n",
    "show(input_image, title=\"CH2: Input image\", axis=False)\n",
    "\n",
    "# Print statistics\n",
    "print(\"Input image type:\", input_image.dtype)\n",
    "print(\"Input image min:\", input_image.min())\n",
    "print(\"Input image max:\", input_image.max())\n",
    "\n",
    "# Run the vessel detection\n",
    "segmented_vessels_array = detect_vessels(input_image, sigma_minimum, sigma_maximum, number_of_sigma_steps,\n",
    "                                         beta=beta2)\n",
    "\n",
    "# Process the thresholded vessels\n",
    "thresholded_vessels_ch2 = process_vessels(segmented_vessels_array, thresh=thresh, min_size=min_size, area_threshold=area_threshold, smoothing=smoothing)\n",
    "thresholded_vessels_ch2 = thresholded_vessels_ch2 * bg_mask * curr_ch2_thresh\n",
    "\n",
    "# Print statistics\n",
    "print(\"Vesselness image statistics:\")\n",
    "print(\"Shape:\", segmented_vessels_array.shape)\n",
    "print(\"Min:\", segmented_vessels_array.min())\n",
    "print(\"Max:\", segmented_vessels_array.max())\n",
    "print(\"Mean:\", segmented_vessels_array.mean())\n",
    "print(\"Median:\", np.median(segmented_vessels_array))\n",
    "#print(\"Std:\", segmented_vessels_array.std())\n",
    "\n",
    "print(\"CHANNEL 2\")\n",
    "\n",
    "# Plot the raw vesselness image\n",
    "show(image=segmented_vessels_array, title=f\"CH2: Vesselness image\",\n",
    "     image2=thresholded_vessels_ch2, title2=f\"CH2: Vessel mask\",\n",
    "     axis=False)\n",
    "\n",
    "# Show the results\n",
    "show(image=input_image, title=\"CH2: Input image\",\n",
    "     image2=input_image, title2=\"Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch2, contour_alpha=0.45,\n",
    "     axis=False)\n",
    "\n",
    "# Plot the raw vesselness image FOV1\n",
    "show(image=segmented_vessels_array, title=f\"CH2 FOV1: Vesselness image\",\n",
    "     image2=thresholded_vessels_ch2, title2=f\"CH2 FOV1: Vessel mask\",\n",
    "     xlim=fov1_xlim, ylim=fov1_ylim, xlim2=fov1_xlim, ylim2=fov1_ylim,\n",
    "     axis=False)\n",
    "\n",
    "\n",
    "# FOV1\n",
    "show(image=input_image, title=\"CH2 FOV1: Input image\",\n",
    "     image2=input_image, title2=\"CH2 FOV1: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch2, contour_alpha=0.45,\n",
    "     xlim=fov1_xlim, ylim=fov1_ylim, xlim2=fov1_xlim, ylim2=fov1_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV2\n",
    "show(image=input_image, title=\"CH2 FOV2: Input image\",\n",
    "     image2=input_image, title2=\"CH2 FOV2: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch2, contour_alpha=0.45,\n",
    "     xlim=fov2_xlim, ylim=fov2_ylim, xlim2=fov2_xlim, ylim2=fov2_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV3\n",
    "show(image=input_image, title=\"CH2 FOV3: Input image\",\n",
    "     image2=input_image, title2=\"CH2 FOV3: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch2, contour_alpha=0.45,\n",
    "     xlim=fov3_xlim, ylim=fov3_ylim, xlim2=fov3_xlim, ylim2=fov3_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV4\n",
    "show(image=input_image, title=\"CH2 FOV4: Input image\",\n",
    "     image2=input_image, title2=\"CH2 FOV4: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch2, contour_alpha=0.45,\n",
    "     xlim=fov4_xlim, ylim=fov4_ylim, xlim2=fov4_xlim, ylim2=fov4_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV5\n",
    "show(image=input_image, title=\"CH2 FOV5: Input image\",\n",
    "     image2=input_image, title2=\"CH2 FOV5: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch2, contour_alpha=0.45,\n",
    "     xlim=fov5_xlim, ylim=fov5_ylim, xlim2=fov5_xlim, ylim2=fov5_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV6\n",
    "show(image=input_image, title=\"CH2 FOV6: Input image\",\n",
    "     image2=input_image, title2=\"CH2 FOV6: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch2, contour_alpha=0.45,\n",
    "     xlim=fov6_xlim, ylim=fov6_ylim, xlim2=fov6_xlim, ylim2=fov6_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# Full section\n",
    "show(image=thresholded_vessels_ch1, title=\"CH1: Vessel segmentation\",\n",
    "     image2=thresholded_vessels_ch2, title2=\"CH2: Vessel segmentation\",\n",
    "     figsize=(10, 10), axis=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANNEL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for vessel detection\n",
    "sigma_minimum = 1.0  # Range of scales in which MultiScaleHessianBasedMeasureImageFilter will search for vessels\n",
    "sigma_maximum = 10.0  # 10\n",
    "number_of_sigma_steps = 10  # 10 Number of scales to search for vessels\n",
    "\n",
    "# Parameters for post-processing\n",
    "thresh = 230  # Threshold for binarization, 230 and 25 and 15\n",
    "min_size = 100  # Minimum size of objects to keep 100\n",
    "area_threshold = 2000 # Minimum area of holes to keep\n",
    "smoothing = 1  # Smoothing factor for closing, 3\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# Alternative: load image in memory\n",
    "input_image = auto_ch3_median * bg_mask\n",
    "#input_image = cc_ch1_alt * bg_mask\n",
    "input_image = input_image.astype(np.float32)\n",
    "input_image *= 255.0\n",
    "\n",
    "show(input_image, title=\"CH3: Input image\", axis=False)\n",
    "\n",
    "# Print statistics\n",
    "print(\"Input image type:\", input_image.dtype)\n",
    "print(\"Input image min:\", input_image.min())\n",
    "print(\"Input image max:\", input_image.max())\n",
    "\n",
    "# Run the vessel detection\n",
    "segmented_vessels_array = detect_vessels(input_image, sigma_minimum, sigma_maximum, number_of_sigma_steps,\n",
    "                                         beta=beta3)\n",
    "\n",
    "# Process the thresholded vessels\n",
    "thresholded_vessels_ch3 = process_vessels(segmented_vessels_array, thresh=thresh, min_size=min_size, area_threshold=area_threshold, smoothing=smoothing)\n",
    "thresholded_vessels_ch3 = thresholded_vessels_ch3 * bg_mask * curr_ch3_thresh\n",
    "\n",
    "# Print statistics\n",
    "print(\"Vesselness image statistics:\")\n",
    "print(\"Shape:\", segmented_vessels_array.shape)\n",
    "print(\"Min:\", segmented_vessels_array.min())\n",
    "print(\"Max:\", segmented_vessels_array.max())\n",
    "print(\"Mean:\", segmented_vessels_array.mean())\n",
    "print(\"Median:\", np.median(segmented_vessels_array))\n",
    "#print(\"Std:\", segmented_vessels_array.std())\n",
    "\n",
    "print(\"CHANNEL 3\")\n",
    "\n",
    "# Plot the raw vesselness image\n",
    "show(image=segmented_vessels_array, title=f\"CH3: Vesselness image\",\n",
    "     image2=thresholded_vessels_ch3, title2=f\"CH3: Vessel mask\",\n",
    "     axis=False)\n",
    "\n",
    "# Show the results\n",
    "show(image=input_image, title=\"CH3: Input image\",\n",
    "     image2=input_image, title2=\"Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch3, contour_alpha=0.45,\n",
    "     axis=False)\n",
    "\n",
    "# Plot the raw vesselness image FOV1\n",
    "show(image=segmented_vessels_array, title=f\"CH3 FOV1: Vesselness image\",\n",
    "     image2=thresholded_vessels_ch3, title2=f\"CH3 FOV1: Vessel mask\",\n",
    "     xlim=fov1_xlim, ylim=fov1_ylim, xlim2=fov1_xlim, ylim2=fov1_ylim,\n",
    "     axis=False)\n",
    "\n",
    "\n",
    "# FOV1\n",
    "show(image=input_image, title=\"CH3 FOV1: Input image\",\n",
    "     image2=input_image, title2=\"CH3 FOV1: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch3, contour_alpha=0.45,\n",
    "     xlim=fov1_xlim, ylim=fov1_ylim, xlim2=fov1_xlim, ylim2=fov1_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV2\n",
    "show(image=input_image, title=\"CH3 FOV2: Input image\",\n",
    "     image2=input_image, title2=\"CH3 FOV2: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch3, contour_alpha=0.45,\n",
    "     xlim=fov2_xlim, ylim=fov2_ylim, xlim2=fov2_xlim, ylim2=fov2_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV3\n",
    "show(image=input_image, title=\"CH3 FOV3: Input image\",\n",
    "     image2=input_image, title2=\"CH3 FOV3: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch3, contour_alpha=0.45,\n",
    "     xlim=fov3_xlim, ylim=fov3_ylim, xlim2=fov3_xlim, ylim2=fov3_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV4\n",
    "show(image=input_image, title=\"CH3 FOV4: Input image\",\n",
    "     image2=input_image, title2=\"CH3 FOV4: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch3, contour_alpha=0.45,\n",
    "     xlim=fov4_xlim, ylim=fov4_ylim, xlim2=fov4_xlim, ylim2=fov4_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV5\n",
    "show(image=input_image, title=\"CH3 FOV5: Input image\",\n",
    "     image2=input_image, title2=\"CH3 FOV5: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch3, contour_alpha=0.45,\n",
    "     xlim=fov5_xlim, ylim=fov5_ylim, xlim2=fov5_xlim, ylim2=fov5_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# FOV6\n",
    "show(image=input_image, title=\"CH3 FOV6: Input image\",\n",
    "     image2=input_image, title2=\"CH3 FOV6: Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch3, contour_alpha=0.45,\n",
    "     xlim=fov6_xlim, ylim=fov6_ylim, xlim2=fov6_xlim, ylim2=fov6_ylim,\n",
    "     axis=False)\n",
    "\n",
    "# Full section\n",
    "show(image=thresholded_vessels_ch3, title=\"CH3: Vessel segmentation\",\n",
    "     image2=thresholded_vessels_ch2, title2=\"CH2: Vessel segmentation\",\n",
    "     figsize=(20, 10), axis=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_mask = np.zeros(curr_ch1.shape)\n",
    "remove_mask[2000:5000, 1000:3000] = 1\n",
    "remove_mask = remove_mask.astype(bool)\n",
    "remove_mask = np.invert(remove_mask)\n",
    "\n",
    "thresholded_vessels_ch1 = thresholded_vessels_ch1 * remove_mask\n",
    "thresholded_vessels_ch2 = thresholded_vessels_ch2 * remove_mask\n",
    "thresholded_vessels_ch3 = thresholded_vessels_ch3 * remove_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_ch0 = thresholded_vessels_ch1\n",
    "thresholded_ch1 = thresholded_vessels_ch2\n",
    "thresholded_ch2 = thresholded_vessels_ch3\n",
    "\n",
    "thresh_ch0_flat = thresholded_ch0.flatten()\n",
    "thresh_ch1_flat = thresholded_ch1.flatten()\n",
    "thresh_ch2_flat = thresholded_ch2.flatten()\n",
    "\n",
    "# Compute the metrics ch1 and ch2\n",
    "dice_score = dice_coefficient(thresholded_ch0, thresholded_ch1)  \n",
    "iou_score = iou(thresholded_ch0, thresholded_ch1)  # Strongly penalizes over-segmentation and under-segmentation\n",
    "precision_score = precision(thresholded_ch0, thresholded_ch1) \n",
    "recall_score = recall(thresholded_ch0, thresholded_ch1)\n",
    "ssim_score = ssim(thresholded_ch0, thresholded_ch1)\n",
    "mse_score = mean_squared_error(thresholded_ch0, thresholded_ch1)\n",
    "hamming_distance = hamming(thresh_ch0_flat, thresh_ch1_flat)\n",
    "rand_score = rand_index(thresholded_ch0, thresholded_ch1)  # Measures how close points are clustered together\n",
    "\n",
    "\n",
    "#print(\"Beta:\", BETA)\n",
    "print(\"\\nMetrics for CH1 and CH2\")\n",
    "print(\"Beta1:\", beta1, \"Beta2:\", beta2)\n",
    "print(\"Thresh1:\", THRESH, \"Thresh2:\", THRESH2)\n",
    "print(\"Dice coefficient:\", dice_score)\n",
    "print(\"IoU score:\", iou_score)\n",
    "print(\"Precision score:\", precision_score)\n",
    "print(\"Recall score:\", recall_score)\n",
    "print(\"SSIM score:\", ssim_score)\n",
    "print(\"MSE score:\", mse_score)\n",
    "print(\"Hamming distance:\", hamming_distance)\n",
    "print(\"Rand index:\", rand_score)\n",
    "\n",
    "# Compute the metrics ch1 and ch3\n",
    "dice_score = dice_coefficient(thresholded_ch0, thresholded_ch2)  \n",
    "iou_score = iou(thresholded_ch0, thresholded_ch2)  # Strongly penalizes over-segmentation and under-segmentation\n",
    "precision_score = precision(thresholded_ch0, thresholded_ch2) \n",
    "recall_score = recall(thresholded_ch0, thresholded_ch2)\n",
    "ssim_score = ssim(thresholded_ch0, thresholded_ch2)\n",
    "mse_score = mean_squared_error(thresholded_ch0, thresholded_ch2)\n",
    "hamming_distance = hamming(thresh_ch0_flat, thresh_ch2_flat)\n",
    "rand_score = rand_index(thresholded_ch0, thresholded_ch2)  # Measures how close points are clustered together\n",
    "\n",
    "print(\"\\nMetrics for CH1 and CH3\")\n",
    "print(\"Beta1:\", beta1, \"Beta3:\", beta3)\n",
    "print(\"Thresh1:\", THRESH,  \"Thresh3:\", THRESH3)\n",
    "print(\"Dice coefficient:\", dice_score)\n",
    "print(\"IoU score:\", iou_score)\n",
    "print(\"Precision score:\", precision_score)\n",
    "print(\"Recall score:\", recall_score)\n",
    "print(\"SSIM score:\", ssim_score)\n",
    "print(\"MSE score:\", mse_score)\n",
    "print(\"Hamming distance:\", hamming_distance)\n",
    "print(\"Rand index:\", rand_score)\n",
    "\n",
    "# Compute the metrics ch2 and ch3\n",
    "dice_score = dice_coefficient(thresholded_ch1, thresholded_ch2)  \n",
    "iou_score = iou(thresholded_ch1, thresholded_ch2)  # Strongly penalizes over-segmentation and under-segmentation\n",
    "precision_score = precision(thresholded_ch1, thresholded_ch2) \n",
    "recall_score = recall(thresholded_ch1, thresholded_ch2)\n",
    "ssim_score = ssim(thresholded_ch1, thresholded_ch2)\n",
    "mse_score = mean_squared_error(thresholded_ch1, thresholded_ch2)\n",
    "hamming_distance = hamming(thresh_ch1_flat, thresh_ch2_flat)\n",
    "rand_score = rand_index(thresholded_ch1, thresholded_ch2)  # Measures how close points are clustered together\n",
    "\n",
    "print(\"\\nMetrics for CH2 and CH3\")\n",
    "print(\"Beta2:\", beta2, \"Beta3:\", beta3)\n",
    "print(\"Thresh2:\", THRESH2, \"Thresh3:\", THRESH3)\n",
    "print(\"Dice coefficient:\", dice_score)\n",
    "print(\"IoU score:\", iou_score)\n",
    "print(\"Precision score:\", precision_score)\n",
    "print(\"Recall score:\", recall_score)\n",
    "print(\"SSIM score:\", ssim_score)\n",
    "print(\"MSE score:\", mse_score)\n",
    "print(\"Hamming distance:\", hamming_distance)\n",
    "print(\"Rand index:\", rand_score)\n",
    "\n",
    "\"\"\"\n",
    "# Write the solutions to a CSV file\n",
    "csv_filename = 'stats_enhanced_M13.csv'\n",
    "\n",
    "# Write to rows\n",
    "rows = [[\"Index\", \"Dice coefficient\", \"IoU score\", \"Precision\", \"Recall\", \"SSIM\", \"MSE\", \"Hamming distance\", \"Rand index\"]]\n",
    "rows.append([IDX, dice_score, iou_score, precision_score, recall_score, ssim_score, mse_score, hamming_distance, rand_score])\n",
    "\n",
    "#with open(csv_filename, mode='w', newline='') as file:\n",
    "#    writer = csv.writer(file)\n",
    "#    writer.writerows(rows)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_test(idx, t1=None, t3=None):\n",
    "    print()\n",
    "    print()\n",
    "    IDX = idx\n",
    "    \n",
    "    THRESH2 = 3000  # 3000\n",
    "    THRESH3 = 600  # 1000\n",
    "\n",
    "    if IDX == 0:\n",
    "        THRESH = 7500  # 7500\n",
    "        max_value = 20000  # 20000\n",
    "        THRESH3 = 600\n",
    "    elif IDX == 1:\n",
    "        THRESH = 6000  # 6000\n",
    "        max_value = 20000  # 20000\n",
    "        THRESH3 = 850\n",
    "    elif IDX == 2:\n",
    "        THRESH = 6000  # 6000\n",
    "        max_value = 20000  # 20000\n",
    "    elif IDX == 3:\n",
    "        THRESH = 6000  # 6000\n",
    "        max_value = 20000  # 20000\n",
    "    elif IDX == 4:\n",
    "        THRESH = 7500  # 7500\n",
    "        THRESH2 = 4000 # 4000\n",
    "        max_value = 20000  # 20000\n",
    "    max_value3 = 2000\n",
    "\n",
    "    if t3 is not None:\n",
    "        THRESH3 = t3\n",
    "    if t1 is not None:\n",
    "        THRESH = t1\n",
    "        \n",
    "    # Load the image channels\n",
    "    curr_ch1, curr_ch2, curr_ch3 = load_3_channels(filepath, IDX)\n",
    "    curr_ch1 = curr_ch1.astype(np.float32)\n",
    "    curr_ch2 = curr_ch2.astype(np.float32)\n",
    "    curr_ch3 = curr_ch3.astype(np.float32)\n",
    "\n",
    "\n",
    "    # Ch1 settings\n",
    "    gamma_ch1 = 2  # You can adjust this value to control the contrast enhancement\n",
    "    contrast_alpha_ch1 = 0.00525  # Try 0.0225 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "    # Ch2 settings\n",
    "    gamma_ch2 = 2  # You can adjust this value to control the contrast enhancement\n",
    "    contrast_alpha_ch2 = 0.0125  # Try 0.125 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "    # Ch3 settings\n",
    "    gamma_ch3 = 2  # You can adjust this value to control the contrast enhancement\n",
    "    contrast_alpha_ch3 = 0.0425  # Try 0.125 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "\n",
    "    # No change\n",
    "    contrast_ch1 = curr_ch1\n",
    "    contrast_ch2 = curr_ch2\n",
    "    contrast_ch3 = curr_ch3\n",
    "\n",
    "\n",
    "    cc_ch1 = auto_contrast(contrast_ch1, alpha=contrast_alpha_ch1)\n",
    "    cc_ch2 = auto_contrast(contrast_ch2, alpha=contrast_alpha_ch2)\n",
    "    cc_ch3 = auto_contrast(contrast_ch3, alpha=contrast_alpha_ch3)\n",
    "\n",
    "\n",
    "    bg_alpha = 0.25  # 0.5\n",
    "    bg_mask = auto_contrast(curr_ch1, alpha=bg_alpha)  # 7\n",
    "    bg_mask = get_brain_mask(bg_mask, area_threshold=25000)  # 255 default ch0, 150 for ch1\n",
    "\n",
    "    #show(cc_ch1, bg_mask, title=f\"Section {IDX} ch1 contrast\", axis=True)\n",
    "    #show(cc_ch2, bg_mask, title=f\"Section {IDX} ch2 contrast\", axis=True)\n",
    "    #show(cc_ch3, bg_mask, title=f\"Section {IDX} ch3 contrast\", axis=True)\n",
    "\n",
    "    # Setup FOVs\n",
    "    fovs = [ \n",
    "    # xlim,             ylim\n",
    "    ( (4000, 5000),     (4000, 5000) ),\n",
    "    ( (2000, 3000),     (2000, 4000) ),\n",
    "    ( (2000, 4000),     (4000, 6000) ),\n",
    "    ( (5000, 6000),     (2000, 4000) ),\n",
    "    ( (5000, 6000),     (1000, 2000) ),\n",
    "    ( (5000, 6000),     (4000, 5000) ),\n",
    "    ]\n",
    "\n",
    "    fov1_xlim, fov1_ylim = fovs[0][0], fovs[0][1][::-1]\n",
    "    fov2_xlim, fov2_ylim = fovs[1][0], fovs[1][1][::-1]\n",
    "    fov3_xlim, fov3_ylim = fovs[2][0], fovs[2][1][::-1]\n",
    "    fov4_xlim, fov4_ylim = fovs[3][0], fovs[3][1][::-1]\n",
    "    fov5_xlim, fov5_ylim = fovs[4][0], fovs[4][1][::-1]\n",
    "    fov6_xlim, fov6_ylim = fovs[5][0], fovs[5][1][::-1]\n",
    "\n",
    "    # Create a threshold mask for the image\n",
    "    curr_ch1_median = ndimage.median_filter(curr_ch1.copy(), size=5)\n",
    "    curr_ch2_median = ndimage.median_filter(curr_ch2.copy(), size=5)  # Repeat for ch2\n",
    "    curr_ch3_median = ndimage.median_filter(curr_ch3.copy(), size=5)  # Repeat for ch2\n",
    "\n",
    "    # Create auto contrast brightened images\n",
    "    auto_ch1 = auto_contrast(curr_ch1, alpha=contrast_alpha_ch1)\n",
    "    auto_ch2 = auto_contrast(curr_ch2, alpha=contrast_alpha_ch2)\n",
    "    auto_ch3 = auto_contrast(curr_ch3, alpha=contrast_alpha_ch3)\n",
    "    auto_ch1_median = ndimage.median_filter(auto_ch1.copy(), size=5) # 5\n",
    "    auto_ch2_median = ndimage.median_filter(auto_ch2.copy(), size=5)\n",
    "    auto_ch3_median = ndimage.median_filter(auto_ch3.copy(), size=5)\n",
    "\n",
    "    # Ch1 settings\n",
    "    gamma_ch1 = 2  # You can adjust this value to control the contrast enhancement\n",
    "    contrast_alpha_ch1 = 0.00525  # Try 0.0225 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "    # Ch2 settings\n",
    "    gamma_ch2 = 2  # You can adjust this value to control the contrast enhancement\n",
    "    contrast_alpha_ch2 = 0.0125  # Try 0.125 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "    # Ch3 settings\n",
    "    gamma_ch3 = 2  # You can adjust this value to control the contrast enhancement\n",
    "    contrast_alpha_ch3 = 0.0425  # Try 0.125 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Create contrast enhanced images\n",
    "    cc_ch1 = gamma_correction(curr_ch1, gamma=gamma_ch1)\n",
    "    cc_ch1 = auto_contrast(cc_ch1, alpha=contrast_alpha_ch1)\n",
    "    cc_ch1_alt = gamma_correction(curr_ch1_median, gamma=gamma_ch1, max_value=max_value)\n",
    "\n",
    "    cc_ch2 = gamma_correction(curr_ch2, gamma=gamma_ch2)\n",
    "    cc_ch2 = auto_contrast(cc_ch2, alpha=contrast_alpha_ch2)\n",
    "\n",
    "    cc_ch3 = gamma_correction(curr_ch3, gamma=gamma_ch3)\n",
    "    cc_ch3 = auto_contrast(cc_ch3, alpha=contrast_alpha_ch3)\n",
    "    cc_ch3_alt = gamma_correction(curr_ch3_median, gamma=gamma_ch3, max_value=max_value3)\n",
    "\n",
    "\n",
    "    print(f\"\\nThreshold for ch1: {THRESH}\")\n",
    "    print(f\"Threshold for ch2: {THRESH2}\")\n",
    "    print(f\"Threshold for ch3: {THRESH3}\")\n",
    "\n",
    "\n",
    "    curr_ch1_thresh = cc_ch1_alt.copy() > THRESH\n",
    "    curr_ch1_thresh[curr_ch1_thresh != 0] = 1\n",
    "    curr_ch1_thresh = curr_ch1_thresh.astype(bool)\n",
    "\n",
    "    curr_ch2_thresh = curr_ch2_median.copy() > THRESH2\n",
    "    curr_ch2_thresh[curr_ch2_thresh != 0] = 1\n",
    "    curr_ch2_thresh = curr_ch2_thresh.astype(bool)\n",
    "\n",
    "    curr_ch3_thresh = cc_ch3_alt.copy() > THRESH3\n",
    "    curr_ch3_thresh[curr_ch3_thresh != 0] = 1\n",
    "    curr_ch3_thresh = curr_ch3_thresh.astype(bool)\n",
    "\n",
    "\n",
    "\n",
    "    # Parameters for vessel detection\n",
    "    sigma_minimum = 1.0  # Range of scales in which MultiScaleHessianBasedMeasureImageFilter will search for vessels\n",
    "    sigma_maximum = 10.0  # 10\n",
    "    number_of_sigma_steps = 10  # 10 Number of scales to search for vessels\n",
    "\n",
    "    # Parameters for post-processing\n",
    "    thresh = 230  # Threshold for binarization, 230 and 25 and 15\n",
    "    min_size = 100  # Minimum size of objects to keep 100\n",
    "    area_threshold = 2000 # Minimum area of holes to keep\n",
    "    smoothing = 1  # Smoothing factor for closing, 3\n",
    "\n",
    "    #############################################################\n",
    "\n",
    "    # Alternative: load image in memory\n",
    "    input_image = auto_ch1_median * bg_mask\n",
    "    #input_image = cc_ch1_alt * bg_mask\n",
    "    input_image = input_image.astype(np.float32)\n",
    "    input_image *= 255.0\n",
    "\n",
    "    #show(input_image, title=\"CH1: Input image\", axis=False)\n",
    "\n",
    "    # Print statistics\n",
    "    #print(\"Input image type:\", input_image.dtype)\n",
    "    #print(\"Input image min:\", input_image.min())\n",
    "    #print(\"Input image max:\", input_image.max())\n",
    "\n",
    "    # Run the vessel detection\n",
    "    segmented_vessels_array = detect_vessels(input_image, sigma_minimum, sigma_maximum, number_of_sigma_steps)\n",
    "\n",
    "    # Process the thresholded vessels\n",
    "    thresholded_vessels_ch1 = process_vessels(segmented_vessels_array, thresh=thresh, min_size=min_size, area_threshold=area_threshold, smoothing=smoothing)\n",
    "    thresholded_vessels_ch1 = thresholded_vessels_ch1 * bg_mask #* curr_ch1_thresh\n",
    "\n",
    "    # Print statistics\n",
    "    #print(\"Vesselness image statistics:\")\n",
    "    #print(\"Shape:\", segmented_vessels_array.shape)\n",
    "    #print(\"Min:\", segmented_vessels_array.min())\n",
    "    #print(\"Max:\", segmented_vessels_array.max())\n",
    "    #print(\"Mean:\", segmented_vessels_array.mean())\n",
    "    #print(\"Median:\", np.median(segmented_vessels_array))\n",
    "    #print(\"Std:\", segmented_vessels_array.std())\n",
    "\n",
    "\n",
    "    # Parameters for vessel detection\n",
    "    sigma_minimum = 1.0  # Range of scales in which MultiScaleHessianBasedMeasureImageFilter will search for vessels\n",
    "    sigma_maximum = 10.0  # 10\n",
    "    number_of_sigma_steps = 10  # 10 Number of scales to search for vessels\n",
    "\n",
    "    # Parameters for post-processing\n",
    "    thresh = 230  # Threshold for binarization, 230\n",
    "    min_size = 100  # Minimum size of objects to keep\n",
    "    area_threshold = 2000 # Minimum area of holes to keep\n",
    "    smoothing = 1  # Smoothing factor for closing, 3\n",
    "\n",
    "    #############################################################\n",
    "\n",
    "    # Alternative: load image in memory\n",
    "    input_image = auto_ch2_median * bg_mask\n",
    "    input_image = input_image.astype(np.float32)\n",
    "    input_image *= 255.0\n",
    "\n",
    "    #show(input_image, title=\"CH2: Input image\", axis=False)\n",
    "\n",
    "    # Print statistics\n",
    "    #print(\"Input image type:\", input_image.dtype)\n",
    "    #print(\"Input image min:\", input_image.min())\n",
    "    #print(\"Input image max:\", input_image.max())\n",
    "\n",
    "    # Run the vessel detection\n",
    "    segmented_vessels_array = detect_vessels(input_image, sigma_minimum, sigma_maximum, number_of_sigma_steps)\n",
    "\n",
    "    # Process the thresholded vessels\n",
    "    thresholded_vessels_ch2 = process_vessels(segmented_vessels_array, thresh=thresh, min_size=min_size, area_threshold=area_threshold, smoothing=smoothing)\n",
    "    thresholded_vessels_ch2 = thresholded_vessels_ch2 * bg_mask * curr_ch2_thresh\n",
    "\n",
    "\n",
    "    #############################################################\n",
    "\n",
    "    # Parameters for vessel detection\n",
    "    sigma_minimum = 1.0  # Range of scales in which MultiScaleHessianBasedMeasureImageFilter will search for vessels\n",
    "    sigma_maximum = 10.0  # 10\n",
    "    number_of_sigma_steps = 10  # 10 Number of scales to search for vessels\n",
    "\n",
    "    # Parameters for post-processing\n",
    "    thresh = 230  # Threshold for binarization, 230 and 25 and 15\n",
    "    min_size = 100  # Minimum size of objects to keep 100\n",
    "    area_threshold = 2000 # Minimum area of holes to keep\n",
    "    smoothing = 1  # Smoothing factor for closing, 3\n",
    "\n",
    "    #############################################################\n",
    "\n",
    "    # Alternative: load image in memory\n",
    "    input_image = auto_ch3_median * bg_mask\n",
    "    #input_image = cc_ch1_alt * bg_mask\n",
    "    input_image = input_image.astype(np.float32)\n",
    "    input_image *= 255.0\n",
    "\n",
    "    #show(input_image, title=\"CH3: Input image\", axis=False)\n",
    "\n",
    "    # Print statistics\n",
    "    #print(\"Input image type:\", input_image.dtype)\n",
    "    #print(\"Input image min:\", input_image.min())\n",
    "    #print(\"Input image max:\", input_image.max())\n",
    "\n",
    "    # Run the vessel detection\n",
    "    segmented_vessels_array = detect_vessels(input_image, sigma_minimum, sigma_maximum, number_of_sigma_steps)\n",
    "\n",
    "    # Process the thresholded vessels\n",
    "    thresholded_vessels_ch3 = process_vessels(segmented_vessels_array, thresh=thresh, min_size=min_size, area_threshold=area_threshold, smoothing=smoothing)\n",
    "    thresholded_vessels_ch3 = thresholded_vessels_ch3 * bg_mask #* curr_ch3_thresh\n",
    "\n",
    "    # Print statistics\n",
    "\n",
    "    thresholded_ch0 = thresholded_vessels_ch1\n",
    "    thresholded_ch1 = thresholded_vessels_ch2\n",
    "    thresholded_ch2 = thresholded_vessels_ch3\n",
    "\n",
    "    thresh_ch0_flat = thresholded_ch0.flatten()\n",
    "    thresh_ch1_flat = thresholded_ch1.flatten()\n",
    "    thresh_ch2_flat = thresholded_ch2.flatten()\n",
    "\n",
    "    # Compute the metrics ch1 and ch2\n",
    "    dice_score = dice_coefficient(thresholded_ch0, thresholded_ch1)  \n",
    "    iou_score = iou(thresholded_ch0, thresholded_ch1)  # Strongly penalizes over-segmentation and under-segmentation\n",
    "    precision_score = precision(thresholded_ch0, thresholded_ch1) \n",
    "    recall_score = recall(thresholded_ch0, thresholded_ch1)\n",
    "    ssim_score = ssim(thresholded_ch0, thresholded_ch1)\n",
    "    mse_score = mean_squared_error(thresholded_ch0, thresholded_ch1)\n",
    "    hamming_distance = hamming(thresh_ch0_flat, thresh_ch1_flat)\n",
    "    rand_score = rand_index(thresholded_ch0, thresholded_ch1)  # Measures how close points are clustered together\n",
    "    \n",
    "    print(\"\\nSlice index:\", IDX)\n",
    "    if t3 is not None:\n",
    "        print(\"Thresh3:\", THRESH3)\n",
    "    if t1 is not None:\n",
    "        print(\"Thresh1:\", THRESH)\n",
    "    print()\n",
    "\n",
    "    #print(\"Beta:\", BETA)\n",
    "    print(\"\\nMetrics for CH1 and CH2\")\n",
    "    print(\"Thresh1:\", THRESH, \"Thresh2:\", THRESH2)\n",
    "    print(\"Dice coefficient:\", dice_score)\n",
    "    print(\"IoU score:\", iou_score)\n",
    "    print(\"Precision score:\", precision_score)\n",
    "    print(\"Recall score:\", recall_score)\n",
    "    print(\"SSIM score:\", ssim_score)\n",
    "    print(\"MSE score:\", mse_score)\n",
    "    print(\"Hamming distance:\", hamming_distance)\n",
    "    print(\"Rand index:\", rand_score)\n",
    "\n",
    "    # Compute the metrics ch1 and ch3\n",
    "    dice_score = dice_coefficient(thresholded_ch0, thresholded_ch2)  \n",
    "    iou_score = iou(thresholded_ch0, thresholded_ch2)  # Strongly penalizes over-segmentation and under-segmentation\n",
    "    precision_score = precision(thresholded_ch0, thresholded_ch2) \n",
    "    recall_score = recall(thresholded_ch0, thresholded_ch2)\n",
    "    ssim_score = ssim(thresholded_ch0, thresholded_ch2)\n",
    "    mse_score = mean_squared_error(thresholded_ch0, thresholded_ch2)\n",
    "    hamming_distance = hamming(thresh_ch0_flat, thresh_ch2_flat)\n",
    "    rand_score = rand_index(thresholded_ch0, thresholded_ch2)  # Measures how close points are clustered together\n",
    "\n",
    "    print(\"\\nMetrics for CH1 and CH3\")\n",
    "    print(\"Thresh1:\", THRESH,  \"Thresh3:\", THRESH3)\n",
    "    print(\"Dice coefficient:\", dice_score)\n",
    "    print(\"IoU score:\", iou_score)\n",
    "    print(\"Precision score:\", precision_score)\n",
    "    print(\"Recall score:\", recall_score)\n",
    "    print(\"SSIM score:\", ssim_score)\n",
    "    print(\"MSE score:\", mse_score)\n",
    "    print(\"Hamming distance:\", hamming_distance)\n",
    "    print(\"Rand index:\", rand_score)\n",
    "\n",
    "    # Compute the metrics ch2 and ch3\n",
    "    dice_score = dice_coefficient(thresholded_ch1, thresholded_ch2)  \n",
    "    iou_score = iou(thresholded_ch1, thresholded_ch2)  # Strongly penalizes over-segmentation and under-segmentation\n",
    "    precision_score = precision(thresholded_ch1, thresholded_ch2) \n",
    "    recall_score = recall(thresholded_ch1, thresholded_ch2)\n",
    "    ssim_score = ssim(thresholded_ch1, thresholded_ch2)\n",
    "    mse_score = mean_squared_error(thresholded_ch1, thresholded_ch2)\n",
    "    hamming_distance = hamming(thresh_ch1_flat, thresh_ch2_flat)\n",
    "    rand_score = rand_index(thresholded_ch1, thresholded_ch2)  # Measures how close points are clustered together\n",
    "\n",
    "    print(\"\\nMetrics for CH2 and CH3\")\n",
    "    print(\"Thresh2:\", THRESH2, \"Thresh3:\", THRESH3)\n",
    "    print(\"Dice coefficient:\", dice_score)\n",
    "    print(\"IoU score:\", iou_score)\n",
    "    print(\"Precision score:\", precision_score)\n",
    "    print(\"Recall score:\", recall_score)\n",
    "    print(\"SSIM score:\", ssim_score)\n",
    "    print(\"MSE score:\", mse_score)\n",
    "    print(\"Hamming distance:\", hamming_distance)\n",
    "    print(\"Rand index:\", rand_score)\n",
    "    print()\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run without mask for ch1 beta = 0.5\n",
    "filepath = \"/media/data/u01/Fig3/M13/*/*.tif\"\n",
    "#IDX = 1\n",
    "\n",
    "print(\"Channel 1\")\n",
    "\n",
    "for i in range(0, 5):\n",
    "    print()\n",
    "    print(\"Doing slice:\", i)\n",
    "    print()\n",
    "    run_test(i, t1=0)\n",
    "    \n",
    "print(\"Channel 3\")\n",
    "    \n",
    "# Run for ch 3\n",
    "for i in range(0, 5):\n",
    "    print()\n",
    "    print(\"Doing slice:\", i)\n",
    "    print()\n",
    "    run_test(i, t3=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run without mask for ch1\n",
    "filepath = \"/media/data/u01/Fig3/M13/*/*.tif\"\n",
    "#IDX = 1\n",
    "\n",
    "print(\"Channel 1\")\n",
    "\n",
    "for i in range(0, 5):\n",
    "    print()\n",
    "    print(\"Doing slice:\", i)\n",
    "    print()\n",
    "    run_test(i, t1=0)\n",
    "    \n",
    "print(\"Channel 3\")\n",
    "    \n",
    "# Run for ch 3\n",
    "for i in range(0, 5):\n",
    "    print()\n",
    "    print(\"Doing slice:\", i)\n",
    "    print()\n",
    "    run_test(i, t3=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/media/data/u01/Fig3/M13/*/*.tif\"\n",
    "#IDX = 1\n",
    "THRESH1LIST = [4000, 5000, 6000, 6500, 7000, 7500, 8000, 8500, 9000]\n",
    "\n",
    "for i in range(0, 5):\n",
    "    print()\n",
    "    print(\"Doing slice:\", i)\n",
    "    print()\n",
    "    for t in THRESH1LIST:\n",
    "        run_test(i, t1=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/media/data/u01/Fig3/M13/*/*.tif\"\n",
    "#IDX = 1\n",
    "THRESH3LIST = [200, 300, 400, 500, 600, 750, 850, 1000]\n",
    "\n",
    "for i in range(0, 5):\n",
    "    print()\n",
    "    print(\"Doing slice:\", i)\n",
    "    print()\n",
    "    for t in THRESH3LIST:\n",
    "        run_test(i, t3=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold method (batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data_path = \"/media/data/u01/Fig3/M13/*/*.tif\"\n",
    "output_ch1_path = \"/media/data/u01/lightsheet/quant-fig3/M13 run 2/segmentation/ch1/\"\n",
    "output_ch2_path = \"/media/data/u01/lightsheet/quant-fig3/M13 run 2/segmentation/ch2/\"\n",
    "output_ch3_path = \"/media/data/u01/lightsheet/quant-fig3/M13 run 2/segmentation/ch3/\"\n",
    "output_csv_ch1_ch2_path = \"/media/data/u01/lightsheet/quant-fig3/M13 run 2/stats_enhanced2_ch1_ch2.csv\"\n",
    "output_csv_ch1_ch3_path = \"/media/data/u01/lightsheet/quant-fig3/M13 run 2/stats_enhanced2_ch1_ch3.csv\"\n",
    "output_csv_ch2_ch3_path = \"/media/data/u01/lightsheet/quant-fig3/M13 run 2/stats_enhanced2_ch2_ch3.csv\"\n",
    "\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# Parameters for vessel detection\n",
    "sigma_minimum = 1.0  # Range of scales in which MultiScaleHessianBasedMeasureImageFilter will search for vessels\n",
    "sigma_maximum = 10.0  # 10\n",
    "number_of_sigma_steps = 10  # 10 Number of scales to search for vessels\n",
    "\n",
    "# Parameters for post-processing\n",
    "thresh1 = 230  # Threshold for binarization, 230 (ch1)\n",
    "thresh2 = 230  # Threshold for binarization, 230 (ch2)\n",
    "min_size1 = 100  # Minimum size of objects to keep (ch1)\n",
    "min_size2 = 100  # Minimum size of objects to keep (ch2)\n",
    "area_threshold = 2000 # Minimum area of holes to keep\n",
    "smoothing = 1  # Smoothing factor for closing, 3\n",
    "\n",
    "# Read all tif files in the folder\n",
    "data_files = sorted(glob.glob(data_path))\n",
    "num_slices = len(data_files) // 3\n",
    "rows_ch1_ch2 = [[\"Index\", \"Dice coefficient\", \"IoU score\", \"Precision\", \"Recall\", \"SSIM\", \"MSE\", \"Hamming distance\", \"Rand index\"]]\n",
    "rows_ch1_ch3 = [[\"Index\", \"Dice coefficient\", \"IoU score\", \"Precision\", \"Recall\", \"SSIM\", \"MSE\", \"Hamming distance\", \"Rand index\"]]\n",
    "rows_ch2_ch3 = [[\"Index\", \"Dice coefficient\", \"IoU score\", \"Precision\", \"Recall\", \"SSIM\", \"MSE\", \"Hamming distance\", \"Rand index\"]]\n",
    "\n",
    "# Load the image channels\n",
    "for i in tqdm(range(num_slices)):\n",
    "    curr_ch1, curr_ch2, curr_ch3 = load_3_channels(data_path, i)\n",
    "    curr_ch1 = curr_ch1.astype(np.float32)\n",
    "    curr_ch2 = curr_ch2.astype(np.float32)\n",
    "    curr_ch3 = curr_ch3.astype(np.float32)\n",
    "    \n",
    "    gamma_ch1 = 2  # You can adjust this value to control the contrast enhancement\n",
    "    contrast_alpha_ch1 = 0.00525  # Try 0.0225 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "    # Ch2 settings\n",
    "    gamma_ch2 = 2  # You can adjust this value to control the contrast enhancement\n",
    "    contrast_alpha_ch2 = 0.0125  # Try 0.125 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "    # Ch3 settings\n",
    "    gamma_ch3 = 2  # You can adjust this value to control the contrast enhancement\n",
    "    contrast_alpha_ch3 = 0.0425  # Try 0.125 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "    THRESH = 4000   # 4000 for all of channel 1\n",
    "    THRESH2 = 3000  # 3000 for all of channel 2\n",
    "    THRESH3 = None\n",
    "    max_value = 20000\n",
    "    max_value3 = 2000\n",
    "\n",
    "    beta1 = 0.5  # Use beta=0.5 for all of ch1\n",
    "    beta2 = 1.0  # Use beta=1.0 for all of ch2\n",
    "    beta3 = None # Swap between 0.5 and 1.0\n",
    "\n",
    "    # Index by index basis\n",
    "    if i == 0:\n",
    "        THRESH = 7500\n",
    "        \n",
    "        THRESH3 = 400\n",
    "        beta3 = 1.0\n",
    "    elif i == 1:\n",
    "        THRESH = 5000\n",
    "        \n",
    "        THRESH3 = 750\n",
    "        beta3 = 0.5\n",
    "    elif i == 2:\n",
    "        THRESH = 5000  # 5000\n",
    "        \n",
    "        THRESH3 = 750\n",
    "        beta3 = 0.5\n",
    "    elif i == 3:\n",
    "        THRESH = 5500  # 5000\n",
    "        \n",
    "        THRESH3 = 750\n",
    "        beta3 = 0.5\n",
    "    elif i == 4:\n",
    "        THRESH = 7000\n",
    "        \n",
    "        THRESH2 = 4000 # Specific to this index\n",
    "        \n",
    "        THRESH3 = 1000\n",
    "        beta3 = 0.5\n",
    "    \n",
    "    # Create a threshold mask for the image\n",
    "    curr_ch1_median = ndimage.median_filter(curr_ch1.copy(), size=5)\n",
    "    curr_ch2_median = ndimage.median_filter(curr_ch2.copy(), size=5)  # Repeat for ch2\n",
    "    curr_ch3_median = ndimage.median_filter(curr_ch3.copy(), size=5)  # Repeat for ch2\n",
    "    \n",
    "    cc_ch1_alt = gamma_correction(curr_ch1_median, gamma=gamma_ch1, max_value=max_value)\n",
    "    #cc_ch3_alt = gamma_correction(curr_ch3_median, gamma=gamma_ch3, max_value=50000)\n",
    "    cc_ch3_alt = gamma_correction(curr_ch3_median, gamma=gamma_ch3, max_value=max_value3)\n",
    "\n",
    "    curr_ch1_thresh = cc_ch1_alt.copy() > THRESH\n",
    "    curr_ch1_thresh[curr_ch1_thresh != 0] = 1\n",
    "    curr_ch1_thresh = curr_ch1_thresh.astype(bool)\n",
    "    \n",
    "    curr_ch2_thresh = curr_ch2_median.copy() > THRESH2\n",
    "    curr_ch2_thresh[curr_ch2_thresh != 0] = 1\n",
    "    curr_ch2_thresh = curr_ch2_thresh.astype(bool)\n",
    "    \n",
    "    curr_ch3_thresh = cc_ch3_alt.copy() > THRESH3\n",
    "    curr_ch3_thresh[curr_ch3_thresh != 0] = 1\n",
    "    curr_ch3_thresh = curr_ch3_thresh.astype(bool)\n",
    "\n",
    "    auto_ch1 = auto_contrast(curr_ch1, alpha=contrast_alpha_ch1)\n",
    "    auto_ch2 = auto_contrast(curr_ch2, alpha=contrast_alpha_ch2)\n",
    "    auto_ch3 = auto_contrast(curr_ch3, alpha=contrast_alpha_ch3)\n",
    "    auto_ch1_median = ndimage.median_filter(auto_ch1.copy(), size=5)\n",
    "    auto_ch2_median = ndimage.median_filter(auto_ch2.copy(), size=5)\n",
    "    auto_ch3_median = ndimage.median_filter(auto_ch3.copy(), size=5)\n",
    "\n",
    "\n",
    "    bg_alpha = 0.25  #\n",
    "    bg_mask = auto_contrast(curr_ch1, alpha=bg_alpha)  # \n",
    "    bg_mask = get_brain_mask(bg_mask, area_threshold=25000)  # 255 default ch0, 150 for ch1\n",
    "    \n",
    "    input_ch1 = auto_ch1_median * bg_mask\n",
    "    input_ch1 = input_ch1.astype(np.float32)\n",
    "    input_ch1 *= 255.0\n",
    "        \n",
    "    input_ch2 = auto_ch2_median * bg_mask\n",
    "    input_ch2 = input_ch2.astype(np.float32)\n",
    "    input_ch2 *= 255.0\n",
    "    \n",
    "    input_ch3 = auto_ch3_median * bg_mask\n",
    "    input_ch3 = input_ch3.astype(np.float32)\n",
    "    input_ch3 *= 255.0\n",
    "\n",
    "\n",
    "    # Run the vessel detection\n",
    "    segmented_vessels_ch1 = detect_vessels(input_ch1, sigma_minimum, sigma_maximum, number_of_sigma_steps, beta=beta1)\n",
    "    segmented_vessels_ch2 = detect_vessels(input_ch2, sigma_minimum, sigma_maximum, number_of_sigma_steps, beta=beta2)\n",
    "    segmented_vessels_ch3 = detect_vessels(input_ch3, sigma_minimum, sigma_maximum, number_of_sigma_steps, beta=beta3)\n",
    "\n",
    "    # Process the thresholded vessels\n",
    "    thresholded_vessels_ch1 = process_vessels(segmented_vessels_ch1, thresh=thresh1, min_size=min_size1, area_threshold=area_threshold, smoothing=smoothing)\n",
    "    thresholded_vessels_ch2 = process_vessels(segmented_vessels_ch2, thresh=thresh2, min_size=min_size2, area_threshold=area_threshold, smoothing=smoothing)\n",
    "    thresholded_vessels_ch3 = process_vessels(segmented_vessels_ch3, thresh=thresh1, min_size=min_size1, area_threshold=area_threshold, smoothing=smoothing)\n",
    "\n",
    "\n",
    "    thresholded_vessels_ch1 = thresholded_vessels_ch1 * bg_mask * curr_ch1_thresh\n",
    "    thresholded_vessels_ch2 = thresholded_vessels_ch2 * bg_mask * curr_ch2_thresh\n",
    "    thresholded_vessels_ch3 = thresholded_vessels_ch3 * bg_mask * curr_ch3_thresh\n",
    "\n",
    "    \n",
    "    # Save to file\n",
    "    sitk_ch1 = sitk.GetImageFromArray(thresholded_vessels_ch1.astype(np.uint8))  # Ch1\n",
    "    output_ch1_file = output_ch1_path + f\"ch1_seg_{str(i).zfill(4)}.tif\"\n",
    "    sitk.WriteImage(sitk_ch1, output_ch1_file)\n",
    "    sitk_ch2 = sitk.GetImageFromArray(thresholded_vessels_ch2.astype(np.uint8))  # Ch1\n",
    "    output_ch2_file = output_ch2_path + f\"ch2_seg_{str(i).zfill(4)}.tif\"\n",
    "    sitk.WriteImage(sitk_ch2, output_ch2_file)\n",
    "    sitk_ch3 = sitk.GetImageFromArray(thresholded_vessels_ch3.astype(np.uint8))  # Ch1\n",
    "    output_ch3_file = output_ch3_path + f\"ch3_seg_{str(i).zfill(4)}.tif\"\n",
    "    sitk.WriteImage(sitk_ch3, output_ch3_file)\n",
    "    \n",
    "    # Compute statistics between ch1 and ch2\n",
    "    thresh_ch1_flat = thresholded_vessels_ch1.flatten()\n",
    "    thresh_ch2_flat = thresholded_vessels_ch2.flatten()\n",
    "    thresh_ch3_flat = thresholded_vessels_ch3.flatten()\n",
    "    \n",
    "    # Ch1 to ch2\n",
    "    dice_score = dice_coefficient(thresholded_vessels_ch1, thresholded_vessels_ch2)  \n",
    "    iou_score = iou(thresholded_vessels_ch1, thresholded_vessels_ch2)  # Strongly penalizes over-segmentation and under-segmentation\n",
    "    precision_score = precision(thresholded_vessels_ch1, thresholded_vessels_ch2) \n",
    "    recall_score = recall(thresholded_vessels_ch1, thresholded_vessels_ch2)\n",
    "    ssim_score = ssim(thresholded_vessels_ch1, thresholded_vessels_ch2)\n",
    "    mse_score = mean_squared_error(thresholded_vessels_ch1, thresholded_vessels_ch2)\n",
    "    hamming_distance = hamming(thresh_ch1_flat, thresh_ch2_flat)\n",
    "    rand_score = rand_index(thresholded_vessels_ch1, thresholded_vessels_ch2)  # Measures how close points are clustered together\n",
    "    rows_ch1_ch2.append([i, dice_score, iou_score, precision_score, recall_score, ssim_score, mse_score, hamming_distance, rand_score])\n",
    "    print(\"ch1-ch2:\", rows_ch1_ch2[i + 1])\n",
    "    \n",
    "    # Ch1 to ch3\n",
    "    dice_score = dice_coefficient(thresholded_vessels_ch1, thresholded_vessels_ch3)  \n",
    "    iou_score = iou(thresholded_vessels_ch1, thresholded_vessels_ch3)  # Strongly penalizes over-segmentation and under-segmentation\n",
    "    precision_score = precision(thresholded_vessels_ch1, thresholded_vessels_ch3) \n",
    "    recall_score = recall(thresholded_vessels_ch1, thresholded_vessels_ch3)\n",
    "    ssim_score = ssim(thresholded_vessels_ch1, thresholded_vessels_ch3)\n",
    "    mse_score = mean_squared_error(thresholded_vessels_ch1, thresholded_vessels_ch3)\n",
    "    hamming_distance = hamming(thresh_ch1_flat, thresh_ch3_flat)\n",
    "    rand_score = rand_index(thresholded_vessels_ch1, thresholded_vessels_ch3)  # Measures how close points are clustered together\n",
    "    rows_ch1_ch3.append([i, dice_score, iou_score, precision_score, recall_score, ssim_score, mse_score, hamming_distance, rand_score])\n",
    "    print(\"ch1-ch3:\", rows_ch1_ch3[i + 1])\n",
    "    \n",
    "    # Ch2 to ch3\n",
    "    dice_score = dice_coefficient(thresholded_vessels_ch2, thresholded_vessels_ch3)  \n",
    "    iou_score = iou(thresholded_vessels_ch2, thresholded_vessels_ch3)  # Strongly penalizes over-segmentation and under-segmentation\n",
    "    precision_score = precision(thresholded_vessels_ch2, thresholded_vessels_ch3) \n",
    "    recall_score = recall(thresholded_vessels_ch2, thresholded_vessels_ch3)\n",
    "    ssim_score = ssim(thresholded_vessels_ch2, thresholded_vessels_ch3)\n",
    "    mse_score = mean_squared_error(thresholded_vessels_ch2, thresholded_vessels_ch3)\n",
    "    hamming_distance = hamming(thresh_ch2_flat, thresh_ch3_flat)\n",
    "    rand_score = rand_index(thresholded_vessels_ch2, thresholded_vessels_ch3)  # Measures how close points are clustered together\n",
    "    rows_ch2_ch3.append([i, dice_score, iou_score, precision_score, recall_score, ssim_score, mse_score, hamming_distance, rand_score])\n",
    "    print(\"ch2-ch3:\", rows_ch2_ch3[i + 1])\n",
    "\n",
    "with open(output_csv_ch1_ch2_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows_ch1_ch2)\n",
    "    \n",
    "with open(output_csv_ch2_ch3_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows_ch2_ch3)\n",
    "    \n",
    "with open(output_csv_ch1_ch3_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows_ch1_ch3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tissuecyte",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
