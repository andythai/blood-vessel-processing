{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Standard imports\n",
    "import glob\n",
    "\n",
    "# 3rd party imports\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from pprint import pprint\n",
    "import SimpleITK as sitk\n",
    "sitk.ProcessObject_SetGlobalWarningDisplay(False)\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for IO operations\n",
    "def load_channels(filepath: str, idx: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load the image channels from the given filepath.\n",
    "    \n",
    "    Args:\n",
    "        filepath: str, path to the image\n",
    "        idx: int, index of the image to load\n",
    "        \n",
    "    Returns:\n",
    "        channels: np.ndarray, image channels\n",
    "    \"\"\"\n",
    "    filepaths = sorted(glob.glob(filepath))\n",
    "    print(f\"Found {int(len(filepaths)/2)} slices\")\n",
    "    pprint(filepaths)\n",
    "    \n",
    "    # Load the image\n",
    "    file_idx = idx * 2  # Multiply by 2 because we have 2 channels and they're stored in pairs\n",
    "    curr_img = (read_tif(filepaths[file_idx]), read_tif(filepaths[file_idx + 1]))\n",
    "    print(\"\\nCh1:\", filepaths[file_idx])\n",
    "    print(\"Ch2:\", filepaths[file_idx + 1])\n",
    "    curr_ch1 = curr_img[0]\n",
    "    curr_ch2 = curr_img[1]\n",
    "\n",
    "    # Check image stats\n",
    "    print(f\"\\nChannel shape: {curr_ch1.shape}\")\n",
    "    print(f\"Channel dtype: {curr_ch1.dtype}\")\n",
    "    print(f\"Channel 1 min: {curr_ch1.min()}\")\n",
    "    print(f\"Channel 1 max: {curr_ch1.max()}\")\n",
    "    print(f\"Channel 1 mean: {curr_ch1.mean()}\")\n",
    "    \n",
    "    return curr_ch1, curr_ch2\n",
    "\n",
    "\n",
    "def read_tif(filepath):\n",
    "    \"\"\"\n",
    "    Read tiff files using SimpleITK\n",
    "    \n",
    "    Args:\n",
    "        filepath: str, path to tiff file\n",
    "        \n",
    "    Returns:\n",
    "        image: np.ndarray, tiff image\n",
    "    \"\"\"\n",
    "    image = sitk.ReadImage(filepath)\n",
    "    image = sitk.GetArrayFromImage(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def auto_contrast(data: np.ndarray, alpha: float = None, beta: float = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocess tiff files to automatically adjust brightness and contrast.\n",
    "    https://stackoverflow.com/questions/56905592/automatic-contrast-and-brightness-adjustment-of-a-color-photo-of-a-sheet-of-pape\n",
    "    \"\"\"\n",
    "    if not alpha:\n",
    "        alpha = np.iinfo(data.dtype).max / (np.max(data) - np.min(data))\n",
    "    if not beta:\n",
    "        beta = -np.min(data) * alpha\n",
    "    img = cv2.convertScaleAbs(data.copy(), alpha=alpha, beta=beta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def gamma_correction(image: np.ndarray, gamma: float=2.0, min_value=None, max_value=None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply gamma correction to the image.\n",
    "    \n",
    "    Args:\n",
    "        image: np.ndarray, input image\n",
    "        gamma: float, gamma value\n",
    "        \n",
    "    Returns:\n",
    "        image_enhanced: np.ndarray, gamma corrected image\n",
    "    \"\"\"\n",
    "    if min_value is not None:\n",
    "        image = image.copy()\n",
    "        image[image < min_value] = 0\n",
    "    if max_value is None:\n",
    "        max_value = image.max()\n",
    "    else:\n",
    "        image = image.copy()\n",
    "        image[image > max_value] = max_value\n",
    "    # Normalize the image to the range [0, 1]\n",
    "    image_normalized = image / max_value\n",
    "    # Apply the exponential transformation\n",
    "    image_enhanced = np.power(image_normalized, gamma)\n",
    "    # Rescale the image back to the original intensity range\n",
    "    image_enhanced = image_enhanced * max_value\n",
    "    return image_enhanced\n",
    "\n",
    "\n",
    "def save_figure(image, filename, contours=None):\n",
    "    \"\"\"\n",
    "    Save figure to disk.\n",
    "    \n",
    "    Args:\n",
    "        image: np.ndarray, input image\n",
    "        filename: str, path to save the image\n",
    "        contours: np.ndarray, contours to overlay on the image\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    if contours is not None:\n",
    "        plt.contour(contours, colors='red', linewidths=0.15, alpha=0.35)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(filename, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Saved figure to {filename}\")\n",
    "    \n",
    "    \n",
    "def show(image: np.ndarray, contour: np.ndarray = None,\n",
    "         image2: np.ndarray = None, contour2: np.ndarray = None, contour_alpha: float = 0.75,\n",
    "         title: str = \"\", title2: str = \"\", \n",
    "         xlim: tuple[int, int] = None, ylim: tuple[int, int] = None,\n",
    "         xlim2: tuple[int, int] = None, ylim2: tuple[int, int] = None,\n",
    "         axis: bool = True,\n",
    "         figsize: tuple[int, int] = (10, 10)):\n",
    "    \"\"\"\n",
    "    Display the image.\n",
    "    \n",
    "    Args:\n",
    "        image: np.ndarray, input image\n",
    "        title: str, title of the image\n",
    "    \"\"\"\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    # If there are two images, display them side by side\n",
    "    if image2 is not None:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(title)\n",
    "        if contour is not None:\n",
    "            plt.contour(contour, colors='red', linewidths=0.5, alpha=contour_alpha)\n",
    "        if xlim is not None:\n",
    "            plt.xlim(xlim)\n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim)\n",
    "        plt.axis(axis)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(image2, cmap='gray')\n",
    "        plt.title(title2)\n",
    "        if contour2 is not None:\n",
    "            plt.contour(contour2, colors='red', linewidths=0.5, alpha=contour_alpha)\n",
    "        if xlim2 is not None:\n",
    "            plt.xlim(xlim2)\n",
    "        if ylim2 is not None:\n",
    "            plt.ylim(ylim2)\n",
    "        plt.axis(axis)\n",
    "    # If there is only one image, display it\n",
    "    else:\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(title)\n",
    "        if contour is not None:\n",
    "            plt.contour(contour, colors='red', linewidths=0.5, alpha=contour_alpha)\n",
    "        if xlim is not None:\n",
    "            plt.xlim(xlim)\n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim)\n",
    "        plt.axis(axis)\n",
    "    plt.show()\n",
    "    f.clear()\n",
    "    plt.close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for vessel detection\n",
    "import itk\n",
    "import numpy as np\n",
    "from skimage.morphology import remove_small_objects, binary_closing, disk, remove_small_holes\n",
    "\n",
    "# Parameters for vessel detection\n",
    "ALPHA = 0.5  # Default 0.5\n",
    "BETA = 0.5  # Default 1\n",
    "GAMMA = 5.0  # Default 5\n",
    "\n",
    "def detect_vessels(input_image: np.ndarray, min_sigma: float=1.0, max_sigma: float=10.0, num_steps: int=10):\n",
    "    \"\"\"\n",
    "    Use the Hessian-based vesselness filter to detect vessels in the image.\n",
    "    \n",
    "    Args:\n",
    "        input_image: np.ndarray, input image\n",
    "        min_sigma: float, minimum sigma value\n",
    "        max_sigma: float, maximum sigma value\n",
    "        num_steps: int, number of steps\n",
    "        \n",
    "    Returns:\n",
    "        segmented_vessels_array: np.ndarray, segmented vessels\n",
    "    \"\"\"\n",
    "    # Run ITK\n",
    "    input_image = itk.image_from_array(input_image)\n",
    "    #input_image = itk.imread(input_image, itk.F)\n",
    "\n",
    "    ImageType = type(input_image)\n",
    "    Dimension = input_image.GetImageDimension()\n",
    "    HessianPixelType = itk.SymmetricSecondRankTensor[itk.D, Dimension]\n",
    "    HessianImageType = itk.Image[HessianPixelType, Dimension]\n",
    "\n",
    "    objectness_filter = itk.HessianToObjectnessMeasureImageFilter[\n",
    "        HessianImageType, ImageType\n",
    "    ].New()\n",
    "    objectness_filter.SetBrightObject(False)  # Set to True if the structures are bright on a dark background\n",
    "    objectness_filter.SetScaleObjectnessMeasure(False)  # Set to True to scale the objectness measure by the scale\n",
    "    objectness_filter.SetAlpha(ALPHA)  # Sensitivity to blob-like structures\n",
    "                                     # Set/Get Alpha, the weight corresponding to R_A \n",
    "                                     # (the ratio of the smallest eigenvalue that has to be large to the larger ones). \n",
    "                                     # Smaller values lead to increased sensitivity to the object dimensionality.\n",
    "    objectness_filter.SetBeta(BETA)   # Sensitivity to plate-like structures - 1.0 default\n",
    "                                     # Set/Get Beta, the weight corresponding to R_B \n",
    "                                     # (the ratio of the largest eigenvalue that has to be small to the larger ones). \n",
    "                                     # Smaller values lead to increased sensitivity to the object dimensionality.\n",
    "    objectness_filter.SetGamma(GAMMA)  # Sensitivity to noise - 5.0 default\n",
    "                                     # Set/Get Gamma, the weight corresponding to S \n",
    "                                     # (the Frobenius norm of the Hessian matrix, or second-order structureness)\n",
    "\n",
    "    multi_scale_filter = itk.MultiScaleHessianBasedMeasureImageFilter[\n",
    "        ImageType, HessianImageType, ImageType\n",
    "    ].New()\n",
    "    multi_scale_filter.SetInput(input_image)\n",
    "    multi_scale_filter.SetHessianToMeasureFilter(objectness_filter)\n",
    "    multi_scale_filter.SetSigmaStepMethodToLogarithmic()\n",
    "    multi_scale_filter.SetSigmaMinimum(min_sigma)\n",
    "    multi_scale_filter.SetSigmaMaximum(max_sigma)\n",
    "    multi_scale_filter.SetNumberOfSigmaSteps(num_steps)\n",
    "\n",
    "    OutputPixelType = itk.UC\n",
    "    OutputImageType = itk.Image[OutputPixelType, Dimension]\n",
    "\n",
    "    rescale_filter = itk.RescaleIntensityImageFilter[ImageType, OutputImageType].New()\n",
    "    rescale_filter.SetInput(multi_scale_filter)\n",
    "    rescale_filter.Update()\n",
    "\n",
    "    # Get numpy array\n",
    "    segmented_vessels = rescale_filter.GetOutput()\n",
    "    segmented_vessels_array = itk.array_view_from_image(segmented_vessels)\n",
    "    segmented_vessels_array = np.asarray(segmented_vessels_array, dtype=np.float32)\n",
    "    return segmented_vessels_array\n",
    "\n",
    "\n",
    "def process_vessels(vessel_image: np.ndarray, thresh: int, min_size: int=10, area_threshold: float=2000, smoothing: int=3):\n",
    "    \"\"\"\n",
    "    Process the thresholded vessels.\n",
    "    \n",
    "    Args:\n",
    "        vessel_image: np.ndarray, input image\n",
    "        thresh: int, threshold value\n",
    "        min_size: int, minimum size\n",
    "        area_threshold: float, area threshold\n",
    "        smoothing: int, smoothing factor\n",
    "        \n",
    "    Returns:\n",
    "        thresholded_vessels: np.ndarray, thresholded vessels\n",
    "    \"\"\"\n",
    "    # Process the thresholded vessels\n",
    "    thresholded_vessels = vessel_image > thresh\n",
    "    thresholded_vessels = np.invert(thresholded_vessels)\n",
    "\n",
    "    # Get rid of small objects\n",
    "    thresholded_vessels = remove_small_objects(thresholded_vessels, min_size=min_size)\n",
    "    thresholded_vessels = remove_small_holes(thresholded_vessels, area_threshold=area_threshold)\n",
    "\n",
    "    # Smoothen edges\n",
    "    thresholded_vessels = binary_closing(thresholded_vessels, footprint=disk(smoothing))\n",
    "    \n",
    "    return thresholded_vessels\n",
    "\n",
    "\n",
    "def get_brain_mask(brain_image, area_threshold=300000, min_size=10000):\n",
    "    \"\"\"\n",
    "    Get the mask of the brain from the image (run before contrast enhancement).\n",
    "    \n",
    "    Args:\n",
    "        brain_image: np.ndarray, input image\n",
    "        thresh: int, threshold value\n",
    "        area_threshold: int, area threshold\n",
    "        \n",
    "    Returns:\n",
    "        mask: np.ndarray, mask of the brain\n",
    "    \"\"\"\n",
    "    _, mask = cv2.threshold(brain_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_TRIANGLE)\n",
    "    mask = remove_small_holes(mask.astype(bool), area_threshold=area_threshold)\n",
    "    mask = remove_small_objects(mask, min_size=min_size)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for evaluation\n",
    "import csv\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error\n",
    "from scipy.spatial.distance import hamming\n",
    "\n",
    "def dice_coefficient(binary_image1, binary_image2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the Dice coefficient between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - dice: Dice coefficient.\n",
    "    \"\"\"\n",
    "    intersection = np.sum(binary_image1 * binary_image2)\n",
    "    size1 = np.sum(binary_image1)\n",
    "    size2 = np.sum(binary_image2)\n",
    "    \n",
    "    dice = (2. * intersection + epsilon) / (size1 + size2 + epsilon)\n",
    "    return dice\n",
    "\n",
    "\n",
    "def iou(binary_image1, binary_image2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the Intersection over Union (IoU) between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - iou: IoU.\n",
    "    \"\"\"\n",
    "    intersection = np.sum(binary_image1 * binary_image2)\n",
    "    union = np.sum(binary_image1 + binary_image2)\n",
    "    \n",
    "    if union == 0:\n",
    "        iou = 1.0\n",
    "    \n",
    "    iou = (intersection + epsilon) / (union + epsilon)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def precision(binary_image1, binary_image2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the precision between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - precision: Precision.\n",
    "    \"\"\"\n",
    "    true_positives = np.sum(binary_image1 * binary_image2)\n",
    "    false_positives = np.sum(binary_image1 * (1 - binary_image2))\n",
    "    \n",
    "    precision = (true_positives) / (true_positives + false_positives + epsilon)\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(binary_image1, binary_image2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the recall between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - recall: Recall.\n",
    "    \"\"\"\n",
    "    true_positives = np.sum(binary_image1 * binary_image2)\n",
    "    false_negatives = np.sum((1 - binary_image1) * binary_image2)\n",
    "    \n",
    "    recall = true_positives / (true_positives + false_negatives + epsilon)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def rand_index(binary_image1, binary_image2):\n",
    "    \"\"\"\n",
    "    Compute the Rand index between two binary images.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_image1: First binary image (numpy array).\n",
    "    - binary_image2: Second binary image (numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - rand_index: Rand index.\n",
    "    \"\"\"\n",
    "    true_positives = np.sum(binary_image1 * binary_image2)\n",
    "    false_positives = np.sum(binary_image1 * (1 - binary_image2))\n",
    "    false_negatives = np.sum((1 - binary_image1) * binary_image2)\n",
    "    true_negatives = np.sum((1 - binary_image1) * (1 - binary_image2))\n",
    "    \n",
    "    rand_index = (true_positives + true_negatives) / (true_positives + false_positives + false_negatives + true_negatives)\n",
    "    return rand_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import scipy.ndimage\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "def n4_bias_correction(img, bg_mask, shrink_factor: float=15, show: bool=False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    N4 bias correction for the input image.\n",
    "    \n",
    "    Parameters:\n",
    "    - img: The input image to correct.\n",
    "    - alpha: The alpha value for contrast adjustment.\n",
    "    - shrink_factor: The shrink factor for downsampling the image for bias correction.\n",
    "    - show: Whether to show the intermediate results.\n",
    "    \n",
    "    Returns:\n",
    "    - corrected_image_full_resolution: The bias corrected image.\n",
    "    \"\"\"\n",
    "    # Get contrast image for mask\n",
    "    #contrast_img = auto_contrast(img, alpha=alpha)\n",
    "    \n",
    "    # Create the brain tissue mask\n",
    "    #mask_img = sitk.GetImageFromArray(contrast_img)\n",
    "    #mask_img = sitk.RescaleIntensity(mask_img, 0, 255)\n",
    "    #mask_img = sitk.LiThreshold(mask_img, 0, 1)\n",
    "    bg_mask = bg_mask.astype(np.uint8)\n",
    "    mask_img = sitk.GetImageFromArray(bg_mask)\n",
    "    mask_img = sitk.LiThreshold(mask_img, 0, 1)\n",
    "\n",
    "    # Use the raw image and convert it to float32\n",
    "    raw_img = sitk.GetImageFromArray(img.copy())\n",
    "    raw_img = sitk.Cast(raw_img, sitk.sitkFloat32)\n",
    "\n",
    "    # Downsample it for bias correction\n",
    "    inputImage = raw_img\n",
    "    if shrink_factor > 1:\n",
    "        inputImage = sitk.Shrink( raw_img, [ shrink_factor ] * raw_img.GetDimension() ) #2\n",
    "        maskImage = sitk.Shrink( mask_img, [ shrink_factor ] * inputImage.GetDimension() ) #3\n",
    "\n",
    "    # Run bias correction\n",
    "    start_time = time.time()\n",
    "    bias_corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    corrected = bias_corrector.Execute(inputImage, maskImage)\n",
    "    \n",
    "    # Apply bias correction to full resolution image\n",
    "    log_bias_field = bias_corrector.GetLogBiasFieldAsImage(raw_img)\n",
    "    corrected_image_full_resolution = raw_img / sitk.Exp(log_bias_field)\n",
    "    end_time = time.time()\n",
    "    corrected_image_full_resolution = sitk.GetArrayFromImage(corrected_image_full_resolution)\n",
    "    \n",
    "    # Show the process if True\n",
    "    if show:\n",
    "        print(f\"Time taken for bias correction: {end_time - start_time:.2f} seconds\")\n",
    "        \n",
    "        # Show the brain tissue mask\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(sitk.GetArrayFromImage(mask_img), cmap='gray')\n",
    "        plt.title(f\"Full resolution brain mask\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(sitk.GetArrayFromImage(maskImage), cmap='gray')\n",
    "        plt.title(f\"Downsampled brain mask (shrink factor={shrink_factor})\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Show the log bias field\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(sitk.GetArrayFromImage(log_bias_field))\n",
    "        plt.colorbar()\n",
    "        plt.title(f\"Log bias field\")\n",
    "        plt.show()\n",
    "\n",
    "        # Show the corrected bias field image\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f\"Original raw image\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(corrected_image_full_resolution, cmap='gray')\n",
    "        plt.title(f\"Corrected bias raw image\")\n",
    "        plt.show()\n",
    "\n",
    "        # Increase the contrast of the corrected image and show side-by-side\n",
    "        preview_alpha = 0.25\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        contrast_comparison = auto_contrast(img, alpha=preview_alpha)\n",
    "        plt.imshow(contrast_comparison, cmap='gray')\n",
    "        plt.title(f\"Original contrast image (alpha={preview_alpha})\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        corrected_bias_contrast = auto_contrast(corrected_image_full_resolution, alpha=preview_alpha)\n",
    "        plt.imshow(corrected_bias_contrast, cmap='gray')\n",
    "        plt.title(f\"Corrected bias contrast image (alpha={preview_alpha})\")\n",
    "        plt.show()\n",
    "        \n",
    "    return corrected_image_full_resolution\n",
    "\n",
    "\n",
    "def preprocess_image(img, alpha: float=1, shrink_factor: float=15, \n",
    "                     median_filter_size: int=5, gaussian_sigma: float=0.2, \n",
    "                     show: bool=False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocess the image using N4 bias correction and filtering.\n",
    "    \n",
    "    Parameters:\n",
    "    - img: The input image to preprocess.\n",
    "    - alpha: The alpha value for contrast adjustment.\n",
    "    - shrink_factor: The shrink factor for downsampling the image for bias correction.\n",
    "    - median_filter_size: The size of the median filter to apply.\n",
    "    - gaussian_sigma: The sigma value for the Gaussian filter to apply.\n",
    "    - show: Whether to show the intermediate results.\n",
    "    \n",
    "    Returns:\n",
    "    - corrected_img: The preprocessed image.\n",
    "    \"\"\"\n",
    "    corrected_bias_img = n4_bias_correction(img, alpha=alpha, shrink_factor=shrink_factor, show=show)\n",
    "\n",
    "    # Run median filter\n",
    "    median_filtered_img = median_filter(corrected_bias_img.copy(), size=median_filter_size)\n",
    "\n",
    "    # Run gaussian filter\n",
    "    gaussian_filtered_img = scipy.ndimage.gaussian_filter(median_filtered_img.copy(), sigma=gaussian_sigma)\n",
    "\n",
    "    #if show:\n",
    "    #    get_stats(img, title=\"Original image stats:\")\n",
    "    #    get_stats(corrected_bias_img, title=\"N4 bias corrected image stats:\")\n",
    "    #    get_stats(median_filtered_img, title=\"Median filtered image stats:\")\n",
    "    #    get_stats(gaussian_filtered_img, title=\"Gaussian filtered image stats:\")\n",
    "        \n",
    "    corrected_img = gaussian_filtered_img        \n",
    "    return corrected_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IO parameters\n",
    "filepath = \"/media/data/u01/Fig2025/Supple-4a-M1/*/*.tif\"\n",
    "IDX = 2\n",
    "\n",
    "# Load the image channels\n",
    "curr_ch1, curr_ch2 = load_channels(filepath, IDX)\n",
    "curr_ch1 = curr_ch1.astype(np.float32)\n",
    "curr_ch2 = curr_ch2.astype(np.float32)\n",
    "\n",
    "# Swap because ch1 is ground truth\n",
    "temp_ch = curr_ch2.copy()\n",
    "curr_ch2 = curr_ch1.copy()\n",
    "curr_ch1 = temp_ch.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply processing on the images and retrieve background mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ch1 settings\n",
    "gamma_ch1 = 2  # You can adjust this value to control the contrast enhancement\n",
    "contrast_alpha_ch1 = 0.02  # Try 0.15 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "# Ch1 settings\n",
    "gamma_ch2 = 2  # You can adjust this value to control the contrast enhancement\n",
    "contrast_alpha_ch2 = 0.02  # Try 0.15 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "\n",
    "# No change\n",
    "contrast_ch1 = curr_ch1\n",
    "contrast_ch2 = curr_ch2\n",
    "\n",
    "cc_ch1 = auto_contrast(contrast_ch1, alpha=contrast_alpha_ch1)\n",
    "cc_ch2 = auto_contrast(contrast_ch2, alpha=contrast_alpha_ch2)\n",
    "\n",
    "# Compute the original image contrast\n",
    "#contrast_ch0 = gamma_correction(curr_ch0, gamma=gamma_ch0)\n",
    "#contrast_ch0 = auto_contrast(contrast_ch0, alpha=contrast_alpha_ch0)\n",
    "#contrast_ch1 = gamma_correction(curr_ch1, gamma=gamma_ch1)\n",
    "#contrast_ch1 = auto_contrast(contrast_ch1, alpha=contrast_alpha_ch1)\n",
    "#contrast_ch2 = gamma_correction(curr_ch2, gamma=gamma_ch2)\n",
    "#contrast_ch2 = auto_contrast(contrast_ch2, alpha=contrast_alpha_ch2)\n",
    "\n",
    "#bg_mask = gamma_correction(curr_ch0, gamma=gamma_ch0)\n",
    "if IDX == 99999: \n",
    "    bg_alpha = 0.1\n",
    "else:\n",
    "    bg_alpha = 99\n",
    "bg_mask = auto_contrast(curr_ch1, alpha=bg_alpha)  # 7\n",
    "bg_mask = get_brain_mask(bg_mask, area_threshold=25000)  # 255 default ch0, 150 for ch1\n",
    "\n",
    "show(cc_ch1, bg_mask, title=f\"Section {IDX} ch1 contrast\", axis=True)\n",
    "show(cc_ch2, bg_mask, title=f\"Section {IDX} ch3 contrast\", axis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold for CH1 and CH3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run N4 bias correction\n",
    "curr_ch1 = n4_bias_correction(curr_ch1, bg_mask, shrink_factor=15, show=True)\n",
    "curr_ch2 = n4_bias_correction(curr_ch2, bg_mask, shrink_factor=15, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a threshold mask for the image\n",
    "curr_ch1_median = ndimage.median_filter(curr_ch1.copy(), size=5)\n",
    "curr_ch2_median = ndimage.median_filter(curr_ch2.copy(), size=5)  # Repeat for ch2\n",
    "\n",
    "# Create auto contrast brightened images\n",
    "auto_ch1 = auto_contrast(curr_ch1, alpha=0.02)\n",
    "auto_ch2 = auto_contrast(curr_ch2, alpha=0.02)\n",
    "auto_ch1_median = ndimage.median_filter(auto_ch1.copy(), size=5) # 5\n",
    "auto_ch2_median = ndimage.median_filter(auto_ch2.copy(), size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gamma test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ch1 settings\n",
    "gamma_ch1 = 2  # You can adjust this value to control the contrast enhancement\n",
    "contrast_alpha_ch1 = 0.02 # 2\n",
    "\n",
    "# Ch2 settings\n",
    "gamma_ch2 = 2  # You can adjust this value to control the contrast enhancement\n",
    "contrast_alpha_ch2 = 0.02  # Try 0.15 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "THRESH2 = 3000  # 700\n",
    "\n",
    "if IDX == 0:\n",
    "     THRESH = 3200  # 6000\n",
    "     #max_value = 1000  # 12000\n",
    "elif IDX == 1:\n",
    "     THRESH = 3200  # 6000\n",
    "     THRESH2 = 2800\n",
    "     #max_value = 2500  # 12000\n",
    "elif IDX == 2:\n",
    "     THRESH = 3200  # 6000\n",
    "     THRESH2 = 3400\n",
    "\n",
    "# Create contrast enhanced images\n",
    "cc_ch1 = gamma_correction(curr_ch1, gamma=gamma_ch1)\n",
    "cc_ch1 = auto_contrast(cc_ch1, alpha=contrast_alpha_ch1)\n",
    "#cc_ch1_alt = gamma_correction(curr_ch1_median, gamma=gamma_ch1, max_value=max_value)\n",
    "#print(\"Max value:\", cc_ch1_alt.max())\n",
    "#print(\"Median value:\", np.median(cc_ch1_alt))\n",
    "#cc_ch1_alt = auto_contrast(cc_ch1_alt, alpha=contrast_alpha_ch1)\n",
    "cc_ch2 = gamma_correction(curr_ch2, gamma=gamma_ch2)\n",
    "cc_ch2 = auto_contrast(cc_ch2, alpha=contrast_alpha_ch2)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Threshold for ch3: {THRESH}\")\n",
    "print(f\"Threshold for ch1: {THRESH2}\")\n",
    "curr_ch1_thresh = curr_ch1_median.copy() > THRESH\n",
    "curr_ch1_thresh[curr_ch1_thresh != 0] = 1\n",
    "curr_ch1_thresh = curr_ch1_thresh.astype(bool)\n",
    "\n",
    "curr_ch2_thresh = curr_ch2_median.copy() > THRESH2\n",
    "curr_ch2_thresh[curr_ch2_thresh != 0] = 1\n",
    "curr_ch2_thresh = curr_ch2_thresh.astype(bool)\n",
    "\n",
    "##########################################################\n",
    "# FULL SECTION\n",
    "##########################################################\n",
    "\n",
    "show(image=cc_ch1, title=f\"Full section {IDX} ch3 contrast\", \n",
    "     image2=cc_ch2, title2=f\"Full section {IDX} ch1 contrast\",\n",
    "     figsize=(20, 10), axis=True)\n",
    "\n",
    "show(image=auto_ch1, title=f\"Full section {IDX} ch3 brightened\", \n",
    "     image2=auto_ch2, title2=f\"Full section {IDX} ch1 brightened\",\n",
    "     figsize=(20, 10), axis=True)\n",
    "\n",
    "show(image=auto_ch1, title=f\"Full section {IDX} ch3 brightened ctr\", \n",
    "     contour=curr_ch1_thresh,\n",
    "     image2=auto_ch2, title2=f\"Full section {IDX} ch1 brightened ctr\",\n",
    "     contour2=curr_ch2_thresh,\n",
    "     figsize=(20, 10), axis=True)\n",
    "\n",
    "show(image=curr_ch1_thresh, title=f\"Full section {IDX} ch3 thresholded\", \n",
    "     image2=curr_ch2_thresh, title2=f\"Full section {IDX} ch1 thresholded\",\n",
    "     figsize=(20, 10), axis=True)\n",
    "\n",
    "#thresholded_vessels_ch1 = curr_ch1_thresh\n",
    "#thresholded_vessels_ch2 = curr_ch2_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hessian Filter\n",
    "https://examples.itk.org/src/nonunit/review/segmentbloodvesselswithmultiscalehessianbasedmeasure/documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANNEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for vessel detection\n",
    "sigma_minimum = 1.0  # Range of scales in which MultiScaleHessianBasedMeasureImageFilter will search for vessels\n",
    "sigma_maximum = 10.0  # 10\n",
    "number_of_sigma_steps = 10  # 10 Number of scales to search for vessels\n",
    "\n",
    "# Parameters for post-processing\n",
    "thresh = 230  # 100 Threshold for binarization, 230 and 25 and 15\n",
    "min_size = 100  # Minimum size of objects to keep 100\n",
    "area_threshold = 2000 # Minimum area of holes to keep\n",
    "smoothing = 1  # Smoothing factor for closing, 3\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# Alternative: load image in memory\n",
    "input_image = auto_ch1_median * bg_mask\n",
    "#input_image = cc_ch1_alt * bg_mask\n",
    "input_image = input_image.astype(np.float32)\n",
    "input_image *= 255.0\n",
    "\n",
    "show(input_image, title=\"CH1: Input image\", axis=False)\n",
    "\n",
    "# Print statistics\n",
    "print(\"Input image type:\", input_image.dtype)\n",
    "print(\"Input image min:\", input_image.min())\n",
    "print(\"Input image max:\", input_image.max())\n",
    "\n",
    "# Run the vessel detection\n",
    "segmented_vessels_array = detect_vessels(input_image, sigma_minimum, sigma_maximum, number_of_sigma_steps)\n",
    "\n",
    "# Process the thresholded vessels\n",
    "thresholded_vessels_ch1 = process_vessels(segmented_vessels_array, thresh=thresh, min_size=min_size, area_threshold=area_threshold, smoothing=smoothing)\n",
    "thresholded_vessels_ch1 = thresholded_vessels_ch1 * bg_mask * curr_ch1_thresh\n",
    "\n",
    "# Print statistics\n",
    "print(\"Vesselness image statistics:\")\n",
    "print(\"Shape:\", segmented_vessels_array.shape)\n",
    "print(\"Min:\", segmented_vessels_array.min())\n",
    "print(\"Max:\", segmented_vessels_array.max())\n",
    "print(\"Mean:\", segmented_vessels_array.mean())\n",
    "print(\"Median:\", np.median(segmented_vessels_array))\n",
    "#print(\"Std:\", segmented_vessels_array.std())\n",
    "\n",
    "print(\"CHANNEL 1\")\n",
    "\n",
    "# Plot the raw vesselness image\n",
    "show(image=segmented_vessels_array, title=f\"CH1: Vesselness image\",\n",
    "     image2=thresholded_vessels_ch1, title2=f\"CH1: Vessel mask\",\n",
    "     axis=False)\n",
    "\n",
    "# Show the results\n",
    "show(image=input_image, title=\"CH1: Input image\",\n",
    "     image2=input_image, title2=\"Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch1, contour_alpha=0.45,\n",
    "     figsize=(20, 10),\n",
    "     axis=False)\n",
    "\n",
    "# Plot the raw vesselness image FOV1\n",
    "show(image=segmented_vessels_array, title=f\"CH1 FOV1: Vesselness image\",\n",
    "     image2=thresholded_vessels_ch1, title2=f\"CH1 FOV1: Vessel mask\",\n",
    "     axis=False)\n",
    "\n",
    "# Full section\n",
    "show(image=thresholded_vessels_ch1, title=\"CH1: Vessel segmentation\",\n",
    "     image2=curr_ch2_thresh, title2=\"CH2: Thresholded vessels\",\n",
    "     figsize=(20, 10), axis=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANNEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for vessel detection\n",
    "sigma_minimum = 1.0  # Range of scales in which MultiScaleHessianBasedMeasureImageFilter will search for vessels\n",
    "sigma_maximum = 10.0  # 10\n",
    "number_of_sigma_steps = 10  # 10 Number of scales to search for vessels\n",
    "\n",
    "# Parameters for post-processing\n",
    "thresh = 230  # Threshold for binarization, 230\n",
    "min_size = 100  # Minimum size of objects to keep\n",
    "area_threshold = 2000 # Minimum area of holes to keep\n",
    "smoothing = 1  # Smoothing factor for closing, 3\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# Alternative: load image in memory\n",
    "input_image = auto_ch2_median * bg_mask\n",
    "input_image = input_image.astype(np.float32)\n",
    "input_image *= 255.0\n",
    "\n",
    "show(input_image, title=\"CH2: Input image\", axis=False)\n",
    "\n",
    "# Print statistics\n",
    "print(\"Input image type:\", input_image.dtype)\n",
    "print(\"Input image min:\", input_image.min())\n",
    "print(\"Input image max:\", input_image.max())\n",
    "\n",
    "# Run the vessel detection\n",
    "segmented_vessels_array = detect_vessels(input_image, sigma_minimum, sigma_maximum, number_of_sigma_steps)\n",
    "\n",
    "# Process the thresholded vessels\n",
    "thresholded_vessels_ch2 = process_vessels(segmented_vessels_array, thresh=thresh, min_size=min_size, area_threshold=area_threshold, smoothing=smoothing)\n",
    "thresholded_vessels_ch2 = thresholded_vessels_ch2 * bg_mask * curr_ch2_thresh\n",
    "\n",
    "# Print statistics\n",
    "print(\"Vesselness image statistics:\")\n",
    "print(\"Shape:\", segmented_vessels_array.shape)\n",
    "print(\"Min:\", segmented_vessels_array.min())\n",
    "print(\"Max:\", segmented_vessels_array.max())\n",
    "print(\"Mean:\", segmented_vessels_array.mean())\n",
    "print(\"Median:\", np.median(segmented_vessels_array))\n",
    "#print(\"Std:\", segmented_vessels_array.std())\n",
    "\n",
    "print(\"CHANNEL 2\")\n",
    "\n",
    "# Plot the raw vesselness image\n",
    "show(image=segmented_vessels_array, title=f\"CH2: Vesselness image\",\n",
    "     image2=thresholded_vessels_ch2, title2=f\"CH2: Vessel mask\",\n",
    "     axis=False)\n",
    "\n",
    "# Show the results\n",
    "show(image=input_image, title=\"CH2: Input image\",\n",
    "     image2=input_image, title2=\"Vessel mask contours over input image\",\n",
    "     contour2=thresholded_vessels_ch2, contour_alpha=0.45,\n",
    "     figsize=(20, 10),\n",
    "     axis=False)\n",
    "\n",
    "# Plot the raw vesselness image FOV1\n",
    "show(image=segmented_vessels_array, title=f\"CH2 FOV1: Vesselness image\",\n",
    "     image2=thresholded_vessels_ch2, title2=f\"CH2 FOV1: Vessel mask\",\n",
    "     axis=False)\n",
    "\n",
    "# Full section\n",
    "show(image=thresholded_vessels_ch1, title=\"CH1: Vessel segmentation\",\n",
    "     image2=thresholded_vessels_ch2, title2=\"CH2: Vessel segmentation\",\n",
    "     figsize=(10, 10), axis=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_ch0 = thresholded_vessels_ch1\n",
    "thresholded_ch1 = thresholded_vessels_ch2\n",
    "\n",
    "# Compute the metrics\n",
    "dice_score = dice_coefficient(thresholded_ch0, thresholded_ch1)  \n",
    "iou_score = iou(thresholded_ch0, thresholded_ch1)  # Strongly penalizes over-segmentation and under-segmentation\n",
    "precision_score = precision(thresholded_ch0, thresholded_ch1) \n",
    "recall_score = recall(thresholded_ch0, thresholded_ch1)\n",
    "ssim_score = ssim(thresholded_ch0, thresholded_ch1)\n",
    "mse_score = mean_squared_error(thresholded_ch0, thresholded_ch1)\n",
    "thresh_ch0_flat = thresholded_ch0.flatten()\n",
    "thresh_ch1_flat = thresholded_ch1.flatten()\n",
    "hamming_distance = hamming(thresh_ch0_flat, thresh_ch1_flat)\n",
    "rand_score = rand_index(thresholded_ch0, thresholded_ch1)  # Measures how close points are clustered together\n",
    "\n",
    "precision2_score = precision(thresholded_ch1, thresholded_ch0)\n",
    "recall2_score = recall(thresholded_ch1, thresholded_ch0)\n",
    "\n",
    "print(\"idx =\", IDX)\n",
    "print(\"beta =\", BETA)\n",
    "print(\"thresh1 =\", THRESH)\n",
    "print(\"thresh2 =\", THRESH2)\n",
    "#print(\"max_value =\", max_value)\n",
    "print(\"Dice coefficient:\", dice_score)\n",
    "print(\"IoU score:\", iou_score)\n",
    "print(\"Precision score:\", precision_score)\n",
    "print(\"Recall score:\", recall_score)\n",
    "print(\"SSIM score:\", ssim_score)\n",
    "print(\"MSE score:\", mse_score)\n",
    "print(\"Hamming distance:\", hamming_distance)\n",
    "print(\"Rand index:\", rand_score)\n",
    "\n",
    "print(\"Precision score 2:\", precision2_score)\n",
    "print(\"Recall score 2:\", recall2_score)\n",
    "\n",
    "# Write the solutions to a CSV file\n",
    "#csv_filename = 'stats_enhanced_M46.csv'\n",
    "\n",
    "# Write to rows\n",
    "#rows = [[\"Index\", \"Dice coefficient\", \"IoU score\", \"Precision\", \"Recall\", \"SSIM\", \"MSE\", \"Hamming distance\", \"Rand index\"]]\n",
    "#rows.append([IDX, dice_score, iou_score, precision_score, recall_score, ssim_score, mse_score, hamming_distance, rand_score])\n",
    "\n",
    "#with open(csv_filename, mode='w', newline='') as file:\n",
    "#    writer = csv.writer(file)\n",
    "#    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the whole thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold method (batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data_path = \"/media/data/u01/Fig2025/Supple-4a-M1/*/*.tif\"\n",
    "output_ch1_path = \"/media/data/u01/Fig2025/quant-fig2025/Supple-4a-M1/segmentation/ch3/\"\n",
    "output_ch2_path = \"/media/data/u01/Fig2025/quant-fig2025/Supple-4a-M1/segmentation/ch1/\"\n",
    "output_csv_ch1_ch2_path = \"/media/data/u01/Fig2025/quant-fig2025/Supple-4a-M1/stats_enhanced2_ch3_ch1.csv\"\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# Parameters for vessel detection\n",
    "sigma_minimum = 1.0  # Range of scales in which MultiScaleHessianBasedMeasureImageFilter will search for vessels\n",
    "sigma_maximum = 10.0  # 10\n",
    "number_of_sigma_steps = 10  # 10 Number of scales to search for vessels\n",
    "\n",
    "# Parameters for post-processing\n",
    "thresh1 = 230  # Threshold for binarization, 230 (ch1)\n",
    "thresh2 = 230  # Threshold for binarization, 230 (ch2)\n",
    "min_size1 = 100  # Minimum size of objects to keep (ch1)\n",
    "min_size2 = 100  # Minimum size of objects to keep (ch2)\n",
    "area_threshold = 2000 # Minimum area of holes to keep\n",
    "smoothing = 1  # Smoothing factor for closing, 3\n",
    "\n",
    "# Read all tif files in the folder\n",
    "data_files = sorted(glob.glob(data_path))\n",
    "num_slices = len(data_files) // 2\n",
    "rows_ch1_ch2 = [[\"Index\", \"Dice coefficient\", \"IoU score\", \"Precision\", \"Recall\", \"SSIM\", \"MSE\", \"Hamming distance\", \"Rand index\"]]\n",
    "\n",
    "# Load the image channels\n",
    "for i in tqdm(range(num_slices)):\n",
    "    curr_ch1, curr_ch2 = load_channels(data_path, i)\n",
    "    curr_ch1 = curr_ch1.astype(np.float32)\n",
    "    curr_ch2 = curr_ch2.astype(np.float32)\n",
    "    \n",
    "    # Swap because ch1 is ground truth\n",
    "    temp_ch = curr_ch2.copy()\n",
    "    curr_ch2 = curr_ch1.copy()\n",
    "    curr_ch1 = temp_ch.copy()\n",
    "        \n",
    "    # Ch1 settings\n",
    "    gamma_ch1 = 2  # You can adjust this value to control the contrast enhancement\n",
    "    contrast_alpha_ch1 = 0.02 # 2\n",
    "\n",
    "    # Ch2 settings\n",
    "    gamma_ch2 = 2  # You can adjust this value to control the contrast enhancement\n",
    "    contrast_alpha_ch2 = 0.02  # Try 0.15 You can adjust this value to control the brightness enhancement 0.5 default\n",
    "\n",
    "    THRESH2 = 3000  # 700\n",
    "\n",
    "    if i == 0:\n",
    "        THRESH = 3200  # 6000\n",
    "    elif i == 1:\n",
    "        THRESH = 3200  # 6000\n",
    "        THRESH2 = 2800\n",
    "    elif i == 2:\n",
    "        THRESH = 3200  # 6000\n",
    "        THRESH2 = 3400\n",
    "            \n",
    "    # Run N4 bias correction\n",
    "    bg_alpha = 99\n",
    "    \n",
    "    bg_mask = auto_contrast(curr_ch1, alpha=bg_alpha)\n",
    "    bg_mask = get_brain_mask(bg_mask, area_threshold=25000)  # 255 default ch0, 150 for ch1\n",
    "    \n",
    "    curr_ch1 = n4_bias_correction(curr_ch1, bg_mask, shrink_factor=15, show=False)\n",
    "\n",
    "    \n",
    "    # Create a threshold mask for the image\n",
    "    curr_ch1_median = ndimage.median_filter(curr_ch1.copy(), size=5)\n",
    "    curr_ch2_median = ndimage.median_filter(curr_ch2.copy(), size=5)  # Repeat for ch2\n",
    "    \n",
    "    #cc_ch1_alt = gamma_correction(curr_ch1_median, gamma=gamma_ch1, max_value=max_value)\n",
    "\n",
    "    curr_ch1_thresh = curr_ch1_median.copy() > THRESH\n",
    "    curr_ch1_thresh[curr_ch1_thresh != 0] = 1\n",
    "    curr_ch1_thresh = curr_ch1_thresh.astype(bool)\n",
    "    \n",
    "    curr_ch2_thresh = curr_ch2_median.copy() > THRESH2\n",
    "    curr_ch2_thresh[curr_ch2_thresh != 0] = 1\n",
    "    curr_ch2_thresh = curr_ch2_thresh.astype(bool)\n",
    "\n",
    "    auto_ch1 = auto_contrast(curr_ch1, alpha=contrast_alpha_ch1)\n",
    "    auto_ch2 = auto_contrast(curr_ch2, alpha=contrast_alpha_ch2)\n",
    "    auto_ch1_median = ndimage.median_filter(auto_ch1.copy(), size=5)\n",
    "    auto_ch2_median = ndimage.median_filter(auto_ch2.copy(), size=5)\n",
    "\n",
    "\n",
    "    input_ch1 = auto_ch1_median * bg_mask\n",
    "    input_ch1 = input_ch1.astype(np.float32)\n",
    "    input_ch1 *= 255.0\n",
    "        \n",
    "    input_ch2 = auto_ch2_median * bg_mask\n",
    "    input_ch2 = input_ch2.astype(np.float32)\n",
    "    input_ch2 *= 255.0\n",
    "\n",
    "\n",
    "    # Run the vessel detection\n",
    "    segmented_vessels_ch1 = detect_vessels(input_ch1, sigma_minimum, sigma_maximum, number_of_sigma_steps)\n",
    "    segmented_vessels_ch2 = detect_vessels(input_ch2, sigma_minimum, sigma_maximum, number_of_sigma_steps)\n",
    "\n",
    "    # Process the thresholded vessels\n",
    "    thresholded_vessels_ch1 = process_vessels(segmented_vessels_ch1, thresh=thresh1, min_size=min_size1, area_threshold=area_threshold, smoothing=smoothing)\n",
    "    thresholded_vessels_ch2 = process_vessels(segmented_vessels_ch2, thresh=thresh2, min_size=min_size2, area_threshold=area_threshold, smoothing=smoothing)\n",
    "\n",
    "    thresholded_vessels_ch1 = thresholded_vessels_ch1 * bg_mask * curr_ch1_thresh\n",
    "    thresholded_vessels_ch2 = thresholded_vessels_ch2 * bg_mask * curr_ch2_thresh\n",
    "    \n",
    "    # Save to file\n",
    "    sitk_ch1 = sitk.GetImageFromArray(thresholded_vessels_ch1.astype(np.uint8))  # Ch1\n",
    "    output_ch1_file = output_ch1_path + f\"ch3_seg_{str(i).zfill(4)}.tif\"\n",
    "    sitk.WriteImage(sitk_ch1, output_ch1_file)\n",
    "    sitk_ch2 = sitk.GetImageFromArray(thresholded_vessels_ch2.astype(np.uint8))  # Ch1\n",
    "    output_ch2_file = output_ch2_path + f\"ch1_seg_{str(i).zfill(4)}.tif\"\n",
    "    sitk.WriteImage(sitk_ch2, output_ch2_file)\n",
    "    \n",
    "    # Compute statistics between ch1 and ch2\n",
    "    thresh_ch1_flat = thresholded_vessels_ch1.flatten()\n",
    "    thresh_ch2_flat = thresholded_vessels_ch2.flatten()\n",
    "    dice_score = dice_coefficient(thresholded_vessels_ch1, thresholded_vessels_ch2)  \n",
    "    iou_score = iou(thresholded_vessels_ch1, thresholded_vessels_ch2)  # Strongly penalizes over-segmentation and under-segmentation\n",
    "    precision_score = precision(thresholded_vessels_ch1, thresholded_vessels_ch2) \n",
    "    recall_score = recall(thresholded_vessels_ch1, thresholded_vessels_ch2)\n",
    "    ssim_score = ssim(thresholded_vessels_ch1, thresholded_vessels_ch2)\n",
    "    mse_score = mean_squared_error(thresholded_vessels_ch1, thresholded_vessels_ch2)\n",
    "    hamming_distance = hamming(thresh_ch1_flat, thresh_ch2_flat)\n",
    "    rand_score = rand_index(thresholded_vessels_ch1, thresholded_vessels_ch2)  # Measures how close points are clustered together\n",
    "    rows_ch1_ch2.append([i, dice_score, iou_score, precision_score, recall_score, ssim_score, mse_score, hamming_distance, rand_score])\n",
    "    print(\"ch1-ch2:\", rows_ch1_ch2[i + 1])\n",
    "\n",
    "with open(output_csv_ch1_ch2_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows_ch1_ch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tissuecyte",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
